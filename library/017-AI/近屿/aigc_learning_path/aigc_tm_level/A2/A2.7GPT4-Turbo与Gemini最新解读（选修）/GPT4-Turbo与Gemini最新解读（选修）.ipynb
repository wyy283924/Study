{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85ee2d40-1aa3-499b-b32d-95ba0771d98b",
   "metadata": {},
   "source": [
    "# 💡 GPT4-Turbo与Gemini最新解读 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7348e5-9690-4390-bed8-939cd2a6916e",
   "metadata": {},
   "source": [
    "通过本课程的学习，你将学会一下知识\n",
    "\n",
    "1. 了解<span style=\"color: red;\">GPT-4V和Gemini</span>如何结合传统的文本处理能力与处理视觉（如图像、视频）和其他感官输入的能力。\n",
    "1. 掌握如何设计有效的提示来引导模型完成特定任务。\n",
    "3. 探索GPT-4V和Gemini可能已经具备的新能力，进行实际的应用和开发。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e050d8ec",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "source": [
    "## 一、GPT-4V和Gemini的基本介绍\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99d682c",
   "metadata": {},
   "source": [
    "<span style=\"color: red;\">GPT-4V</span>是GPT-4的一个特化版本，专注于视觉任务。集成了图像理解能力，使其能够处理和解释视觉数据。\n",
    "\n",
    "<video src=\"videos/gpt4.mp4\" controls=\"controls\" width=800px style=\"margin-left: 0px\"></video>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c2db51",
   "metadata": {},
   "source": [
    "<span style=\"color: red;\">Gemini</span>：Google开发的最新MLLM，专为多模态任务设计。表现出卓越的视觉理解和推理能力，是GPT-4V的强有力竞争者。\n",
    "\n",
    "目前Gemini用作的比较的版本是Gemini pro，其还有nano和ultra版本，视频展示据透露为ultra版本的Gemini\n",
    "\n",
    "<video src=\"videos/gemini.mp4\" controls=\"controls\" width=800px style=\"margin-left: 0px\"></video>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391302b1-a2cf-4e76-b0d2-844ed587c677",
   "metadata": {},
   "source": [
    "## 二、技术架构"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057fa8b6",
   "metadata": {},
   "source": [
    "#### **2.1 GPT-4 的体系架构**\n",
    "\n",
    "\n",
    "1. <span style=\"color: red;\">专家混合（Mixture of Experts，简写为 MoE）架构</span>\n",
    "\n",
    "想象一下，组织一个团队来解决各种各样的问题。你会希望这个团队里有各种领域的专家，每个人都擅长解决特定类型的问题。在神经网络的世界里，MoE架构就是创建了一个“超级团队”，其中包括16个“专家模型”，每个模型都是解决特定问题的高手。每个专家都很大，有1110亿个参数，这些参数可以理解为专家的“知识点”，使得整个团队有将近1.76万亿个知识点。在解决问题时，网络会确定哪个专家最适合当前的任务，并将任务指派给他们，就像选择最合适的人来解答问题。\n",
    "\n",
    "<img src=\"images/GPT-4 的体系结构.jpg\" style=\"margin-left: 0px\" width=\"400px\">\n",
    "\n",
    "这张图片展示了一个简化的<span style=\"color:blue;\">神经网络架构图</span>，特别是一个基于<span style=\"color:green;\">transformer</span>的模型层，图片中有两个主要部分：\n",
    "\n",
    "- 左边“<span style=\"color:red;\">MoE MIPs</span>”，代表<span style=\"color:red;\">混合专家模型的多任务积极推理路径</span>（Mixture of Experts Multiple Inference Paths）。\n",
    "- 右边是一个展开的视图，标记为“<span style=\"color:red;\">MIP 0</span>”到“<span style=\"color:red;\">MIP 15</span>”，代表不同的推理路径或专家。\n",
    "\n",
    "\n",
    "2. 并行策略\n",
    "\n",
    "\n",
    "总计使用约 3125 台机器（25000 张 A100）进行训练。其中 batch size 为 60M token，seq_len 为 8k\n",
    "\n",
    "<img src=\"images/GPT-4并行策略.jpg\" style=\"margin-left: 0px\" width=\"400px\">\n",
    "\n",
    "\n",
    "每个专家都精通某个特定领域，协作以提供增强的结果\n",
    "\n",
    "<img src=\"images/MoE 模型进行并行训练.pic.jpg\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "\n",
    "想象我们有一个团队，里面有三位专家（E1、E2、E3），每位专家都非常擅长解决特定类型的问题。这就像我们有三个脑力工作者，每个人都在他们的专业领域内工作，提供他们的建议或解决方案，这些建议或解决方案在这里被称为隐藏状态（h1、h2、h3）。\n",
    "\n",
    "现在，我们需要一个团队领导来决定，当面对一个具体问题时，应该重视哪位专家的意见。这就是门控单元（G1、G2、G3）的作用。每个门控单元都有两项任务：一是听取对应专家的建议，二是查看一个控制信号（这个信号可能来自问题本身或是整个网络的其他部分），然后决定给专家的建议多少权重（也就是加权系数a）。这就像团队领导要决定在最终决策中，给每位专家的意见多少分量。\n",
    "\n",
    "门控单元做出决定后，我们就把所有专家的建议按照各自的权重加起来，形成一个综合意见（输出y）。这个过程很像一个委员会会议，每个人都发表了意见，但最终的决策会考虑到谁的意见最重要。\n",
    "\n",
    "最后，我们还有一个大脑图，它将所有专家的建议和对应的权重信息汇总起来（hall），这就好比是会议记录，它详细记载了每个专家的意见和他们的意见在最终决策中的分量。\n",
    "\n",
    "所以，在这个神经网络架构中，每个“专家”都是专门处理特定类型信息的系统，而“门控单元”则是用来决定在给定的问题中，哪些专家的建议最为重要。这样，网络就可以更加灵活地适应不同的问题，给出最好的解决方案。\n",
    "\n",
    "\n",
    "#### **2.2 Gemini 的体系架构**\n",
    "\n",
    "我们将Gemini模型作为一个超级多才多艺的“魔术师”。这个魔术师可以听懂人类的语言（文本输入），看懂图片（图像输入），听声音（音频输入），甚至看视频（视频输入）。这个魔术师不仅多才多艺，而且还有一个超大的“魔术箱”（Transformer单元），能够把这些不同的输入变换成他想要的任何东西。\n",
    "\n",
    "现在，当有人向这位魔术师提出要求时，他会用他的魔术箱来理解并处理这些请求。例如，如果你给他一段文字和一张图片，他不仅能理解文字的意思，还能看懂图片的内容。然后，他会用他的魔术箱来创造一些东西作为回应。这可能是一段新的文字（文本解码器），也可能是一张图片（图像解码器）。\n",
    "\n",
    "1. Gemini 模型是基于 Transformer Decoder构建\n",
    "\n",
    "2. Gemini 是类似 GPT 的 Decoder-only 预测 next token prediction的模式\n",
    "\n",
    "3. 经过训练以支持 32k 的上下文长度，采用高效的注意机制\n",
    "\n",
    "这就像我们在计算机世界中有一个全能的助手，它能理解和处理多种信息，并且给出多种形式的回应。\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"images/gemini 体系结构.jpg\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "\n",
    "\n",
    "AlphaCode 2是基于这位全能魔术师（Gemini模型）的一个特别版本，专门设计来解决编程比赛中的难题。\n",
    "\n",
    "<img src=\"images/a.pic.jpg\" style=\"margin-left: 0px\" width=\"800px\">\n",
    "\n",
    "\n",
    "1. **多个策略模型**：这就好像我们的魔术师不只有一个变魔术的方法，而是有多种方法来解决问题。每种方法都像一个小助手，专门负责解决特定类型的问题。\n",
    "\n",
    "2. **采样机制**：这个魔术师在展示魔术之前会先尝试很多不同的方法，来确保他找到最好的一个。这就像他有一个试验箱，里面充满了各种可能的解决方案。\n",
    "\n",
    "3. **过滤机制**：这位魔术师非常聪明，他会丢掉那些不好的或不合适的魔术方法，只留下最好的那些。这就像他有一个筛子，能筛出不符合要求的解决方案。\n",
    "\n",
    "4. **聚类算法**：他还会把那些类似的解决方案放在一起，这样他就不会重复同样的魔术。这有点像整理魔术道具，把相似的放在一起，更容易找到最合适的。\n",
    "\n",
    "5. **评分模型**：最后，这位魔术师会表演他认为最好的魔术。他会根据魔术的表现、观众的反应和其他标准来给每个魔术打分。就像在比赛中，评委会根据表演的不同方面来评分一样。\n",
    "\n",
    "这样，我们的编程魔术师就能在编程比赛中选择最好的解决方案，给观众带来惊喜。这个神奇的过程就是AlphaCode 2的工作方式，它是一个能够处理编程问题并找到最佳解决方案的智能系统。\n",
    "\n",
    "\n",
    "\n",
    "**注意**：Gemini最开始的时候就用的是<span style=\"color: red;\">多模态数据同时训练</span>，而GPT-4更像是不同模态训练好了，进行<span style=\"color: red;\">散装合并</span>。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85424a6",
   "metadata": {},
   "source": [
    "## **三、 GPT4-V相关技术**\n",
    "\n",
    "\n",
    "#### **3.1 GPT-4V 的训练时支持的输入模式**\n",
    "\n",
    "GPT-4V 支持多种训练输入模式，这些模式使其能够处理不同类型的数据。\n",
    "\n",
    "| 输入模式 | 描述 | 应用案例 |\n",
    "|----------|------|----------|\n",
    "| **<span style=\"color:green\">文本输入</span>** | GPT-4V 可以执行各种语言和编码任务，处理<span style=\"color:red\">纯文本输入</span>。 | 语言翻译、文本生成等 |\n",
    "| **<span style=\"color:green\">单个图文对</span>** | GPT-4V 可以接受<span style=\"color:red\">单个图像-文本对</span>或单个图像作为输入，执行各种视觉和视觉-语言任务。 | 图像识别、物体定位、图像字幕、视觉问题回答等 |\n",
    "| **<span style=\"color:green\">交错图文对</span>** | GPT-4V 能够灵活处理交错的图像-文本输入，这包括图像为中心的输入或文本为中心的输入，以及二者的均衡混合。 | 计算多个收据图像上的总税款、混合图文内容分析等 |\n",
    "\n",
    "\n",
    "<img src=\"images/发票信息.png\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "\n",
    "左边是两张**收据的照片**和一段关于**GPT-4如何分析收据上税额**的文本。文本说明GPT-4能够从不同收据上识别和计算出**税额**。\n",
    "\n",
    "右边是一张桌子上有两瓶**啤酒**的照片和一张**菜单**的照片，以及一段文本，说明GPT-4根据菜单上的价格分析出两瓶啤酒的**总费用**。整个图片的目的是为了展示GPT-4可以处理**多图像输入**并**交织图像与文本输入**进行详细讨论。\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "#### **3.2 GPT-4V的工作模式和提示技术**\n",
    "\n",
    "<span style=\"color:green\">GPT-4V</span> 的强大之处在于其对文本指令的深入理解和遵循，以及处理多种复杂输入模式的能力。\n",
    "\n",
    "##### 3.2.1. <span style=\"color:purple\">文本指令的遵循</span>：\n",
    "   - **限制性提示**：<span style=\"color:red\">让 GPT-4V 以特定格式回应</span>，例如“以Json格式返回…”或“用Markdown语法写出…”。\n",
    "   - **要求良好表现**：<span style=\"color:red\">明确地要求 GPT-4V 有良好的表现</span>，即“你是一个…专家”。\n",
    "   \n",
    "   <img src=\"images/限制性提示.png\" style=\"margin-left: 0px\" width=\"650px\">\n",
    "\n",
    "\n",
    "这张图片展示了**GPT-4模型**如何在**限制性提示**下处理图像中的文本信息，并以**JSON格式**返回信息。图中包含三个示例：\n",
    "\n",
    "1. **Arizona驾驶证**：GPT-4正确识别了驾驶证上的信息，并以JSON格式返回了详细数据。\n",
    "\n",
    "2. **California驾驶证**：模型同样识别了信息，并返回了包括EXP、ISS、SEX等在内的详细数据。\n",
    "\n",
    "3. **美国永久居民身份证**：模型在这里犯了一些错误，这些错误在图片中以**红色**高亮显示。\n",
    "\n",
    "GPT-4在处理有限制性提示的情境下，展现了强大的图像内文本识别与信息提取能力，但仍可能存在错误，需要进一步的验证和校正。\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### 3.2.2. <span style=\"color:purple\">视觉指向和视觉指针提示</span>：\n",
    "   - GPT-4V 在理解<span style=\"color:red\">视觉指向方面的强项</span>，特别是直接在图像上绘制的视觉指针。介绍了“视觉指针提示”，通过编辑图像的像素来指定目标。\n",
    "   <img src=\"images/视觉指向方面的强项.png\" style=\"margin-left: 0px\" width=\"650px\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "这张图片展示了在多模态交互中“视觉指向”不同的模式。\n",
    "\n",
    "1. **坐标（Coordinate）**：展示了一个坐标轴和一个包含数值的方框，指示了一个特定的位置。\n",
    "2. **裁剪框（Crop Box）**：通过一个矩形框来裁剪出图片中的一个区域。\n",
    "3. **箭头（Arrow）**：使用箭头指向图片中的特定物体。\n",
    "4. **框（Box）**：在图片中的目标物体周围画了一个矩形框来突出显示。\n",
    "5. **圈（Circle）**：用一个圆圈来标记图片中的物体。\n",
    "6. **手绘（HandDrawing）**：通过自由手绘来标记图片中的物体。\n",
    "\n",
    "每种模式都通过对同一张海滩酒吧场景的图片进行操作来演示。这些模式可以帮助用户在视觉数据上进行精确的指示和交互，比如在进行图像编辑或者数据标注的时候。\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "##### 3.2.3. <span style=\"color:purple\">视觉+文本提示</span>：\n",
    "   - GPT-4V 在处理多模态输入方面的<span style=\"color:red\">灵活性和通用性</span>。\n",
    "\n",
    "   与现有的多模态模型相比，GPT-4V能够处理各种格式的图像和文本输入，并且没有严格的格式要求。这使得GPT-4V能够更有效地理解多模态指令，适应未见过的任务。此外，与传统的指令跟随模式和在上下文中的少量示例学习相比，GPT-4V还支持更灵活的输入格式和更有效的任务演示方式。\n",
    "   \n",
    "   <img src=\"images/多样性.png\" style=\"margin-left: 0px\" width=\"650px\">\n",
    "   <img src=\"images/多样性2.png\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "##### 3.2.4. <span style=\"color:purple\">上下文中的少样本学习</span>：\n",
    "   - 少样本学习在多模态大语言模型中的应用和重要性。这种方法通过提供相同格式的示例来“教”模型执行新任务，但在此次测试中，为了遵循测试基准，其使用受到限制。\n",
    "\n",
    "   <img src=\"images/少样本学习.png\" style=\"margin-left: 0px\" width=\"400px\">\n",
    "   <img src=\"images/少样本学习2.png\" style=\"margin-left: 0px\" width=\"400px\">\n",
    "   <img src=\"images/少样本学习3.png\" style=\"margin-left: 0px\" width=\"500px\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "提供的图片是GPT-4对速度计读数的识别能力的展示。分别为**零样本**（Zero-shot）、**零样本逐步思考**（Zero-shot think step-by-step）、**一次样本**（1-shot）和**两次样本**（2-shot）的学习情境。\n",
    "\n",
    "在**零样本**情境下，GPT-4给出了初步的估计。随着提示中步骤性描述的增加，GPT-4的预测变得更为精确。在**一次样本**情境下，GPT-4能够给出接近的读数，但在某些情况下仍有误差。最后，在**两次样本**情境下，GPT-4展示了对速度计读数的准确识别。\n",
    "\n",
    "**结论**：\n",
    "\n",
    "GPT-4展示了在不同的学习情境下对于复杂任务（如读取速度计）的适应性。\n",
    "\n",
    "随着更多的样本和详细步骤的提示，GPT-4能够更准确地识别和解释图像中的信息。\n",
    "\n",
    "这表明了GPT-4在处理视觉任务时，可以通过学习上下文提示来提高其性能。\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### 本章总结\n",
    "\n",
    "GPT-4V 能够处理包括纯文本、图片和它们的组合在内的各种数据类型。不同的训练模式让它可以完成从语言翻译到图像描述的多样任务。\n",
    "\n",
    "- 在**零样本**情况下，GPT-4V 能够给出一个基本的答案。\n",
    "- 当提供**逐步指导**时，它能更细致地分析信息。\n",
    "- 通过**一次或两次样本**的指令，GPT-4V的表现会更精确。\n",
    "\n",
    "这意味着，通过给予GPT-4V适当的指示和例子，我们可以提高它在特定任务上的表现。简而言之，GPT-4V就像一个学习能力很强的学生，能通过例子快速学习新事物，并且能够利用它的多模态能力去理解和解释复杂的信息。无论是读取速度表还是解决视觉谜题，只要正确地引导，GPT-4V都能给出准确的答案。这表明，即使是复杂的视觉任务，只要我们提供清晰的步骤和背景信息，GPT-4V也能够很好地完成。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668e3a5b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## **四、 Gemini相关概述**\n",
    "\n",
    "\n",
    "#### **4.1 Gemini 家族模型概览**\n",
    "\n",
    "<span style=\"color:green\">谷歌</span>推出了新系列多模态模型——<span style=\"color:purple\">Gemini家族</span>，包括 Ultra, Pro, Nano（1.5B Nano-1，3.25B Nano-2）三种尺寸。\n",
    "\n",
    "- Gemini Ultra 在32个benchmarks中实现了30个sota。\n",
    "- 在MMLU中，甚至达到了<span style=\"color:red\">人类专家的性能</span>。\n",
    "- AlphaCode 团队基于Gemini构建出AlphaCode2，在 Codeforces 竞技编程平台的参赛者中名列前 15%，与名列前 50%的前代产品相比有了很大提高。\n",
    "\n",
    "| 模型大小 | 模型描述 |\n",
    "|----------|----------|\n",
    "| **Ultra** | 最强大的模型，提供了包括推理和多模态任务在内的广泛复杂任务上的最先进性能。在TPU加速器上可高效扩展，得益于Gemini架构。 |\n",
    "| **Pro** | 在成本和延迟方面进行了性能优化的模型，提供了广泛任务上的显著性能。展现了强大的推理性能和多模态功能。 |\n",
    "| **Nano** | 最高效的模型，设计用于设备上运行。Nano-1拥有1.8B参数，Nano-2拥有3.25B参数，针对低端和高端内存设备。通过从更大的Gemini模型中提炼进行训练，并进行了4位量化以提供最佳性能。 \n",
    "\n",
    "**结论**：**Gemini 1.0模型家族**提供了不同规模和性能的模型，以满足从高效的设备端运行到强大的推理和多模态任务处理的各种应用需求。\n",
    "\n",
    "\n",
    "\n",
    "#### **4.2 Gemini 推理示例**\n",
    "\n",
    "<img src=\"images/首个.jpg\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "图片中展示了一个物理问题的解答验证过程。左侧是一个学生对于滑雪者下坡问题的解答，右侧是gemini的个解答。\n",
    "\n",
    "\n",
    "**学生的解答包括以下要点**：\n",
    "- 问题描述：滑雪者从40米高、80米长的斜坡滑下。\n",
    "- 解答方法：学生尝试应用能量守恒定律，但错误地使用了斜坡长度来计算势能。\n",
    "- 得出的速度为：`v = √(2gL) = 39.6 m/s`。\n",
    "\n",
    "**gemini的回应**：\n",
    "- 指出学生应使用高度而非长度来计算势能。\n",
    "- 正确方法：用高度计算势能，并将其转化为动能求解速度。\n",
    "- 正确答案：`v = √(2gH) = 28.01 m/s`。\n",
    "\n",
    "**结论**：\n",
    "gemini不仅纠正了学生的错误，还提供了详细的正确解题步骤，并使用LaTeX格式准确展示了计算过程和结果。\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "#### **4.3 预训练数据集**\n",
    "\n",
    "\n",
    "<div style=\"font-family: Arial, sans-serif;\">\n",
    "  \n",
    "  <p>\n",
    "    <strong style=\"color: #228B22;\">预训练数据集</strong>涵盖了丰富的来源，包括网络文档、书籍、代码，以及图像、音频和视频数据。\n",
    "  </p>\n",
    "  <p>\n",
    "    <strong style=\"color: #228B22;\">Tokenizer</strong>选择了<strong style=\"color: #8B4513;\">SentencePiece tokenizer</strong>，这在处理大规模训练语料库时能够提升推断词汇量，并显著提高模型性\n",
    "\n",
    "能。Gemini模型尤其擅长处理<strong style=\"color: #8B4513;\">非拉丁文脚本</strong>，例如汉语，这对提升模型整体质量及训练和推理速度大有裨益。\n",
    "  </p>\n",
    "  \n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5936819-e086-439c-822e-72ba4478c814",
   "metadata": {},
   "source": [
    "## **五 Gemini Pro - GPT-4V 的评测对比**\n",
    "\n",
    "\n",
    "#### **5.1. 定量测试**\n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    <h3>多模态大语言模型评测基准 - MME 概览</h3>\n",
    "    <p>MME评测基准专为多模态大语言模型设计，覆盖感知和认知任务，包括目标存在性判断、物体计数、位置关系、颜色判断等。</p>\n",
    "</div>\n",
    "\n",
    "<h4>评测结果</h4>\n",
    "<table class=\"table table-bordered\">\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>模型</th>\n",
    "            <th>得分</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td>Gemini Pro</td>\n",
    "            <td><span style=\"color: red;\">1933.4</span></td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>GPT-4V</td>\n",
    "            <td>1926.6</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"images/F106.pic.jpg\" style=\"margin-left: 0px\" width=\"400px\"></td>\n",
    "        <td><img src=\"images/结果2.jpg\" style=\"margin-right: 0px\" width=\"600px\"></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "图片对比了三个模型在MME基准的14个子任务上的表现。这些子任务涉及多种多模态任务，如名人识别、场景检测、地标识别、艺术品识别、常识推理、文本翻译、光学字符识别（OCR）、数值计算、存在性判断、代码推理、位置判断、颜色识别、海报识别和计数等。\n",
    "\n",
    "**分析**：\n",
    "- 图中展示了三个模型：Sphinx（橙色线），GPT-4V（蓝色线），以及Gemini（绿色线）。\n",
    "- GPT-4V在名人识别任务上拒绝回答，因此得分为零。\n",
    "- Gemini和GPT-4V在位置识别子任务上表现不佳，这可能表明两个模型对空间信息不敏感。\n",
    "- Sphinx在感知任务上的表现与Gemini和GPT-4V相当或甚至更好，这可能是因为Sphinx在训练中更注重感知，例如对象检测。\n",
    "- 相比之下，Sphinx在认知子任务上，包括常识推理、数值计算、文本翻译和代码推理方面，远远落后于Gemini和GPT-4V。\n",
    "\n",
    "**结论**：\n",
    "可以看出，不同的模型在不同子任务上的表现差异显著。虽然某些模型在感知任务上表现出色，但在需要高级认知处理的任务上可能表现不佳。这强调了在开发和评估多模态模型时，平衡感知和认知能力的重要性。\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "右图是一张表格，每个模型在不同的子任务上得分不同。\n",
    "\n",
    "- **模型**:\n",
    "  - **Sphinx**: 在**感知**任务中表现较好。\n",
    "  - **GPT-4V**: 在**认知**任务中整体表现优秀。\n",
    "  - **Gemini**: 表现相对均衡，但在大部分任务中未能获得最高分。\n",
    "\n",
    "- **性能评估指标**:\n",
    "  - **感知类**: 包括存在性、计数、位置、颜色、OCR、海报、名人、场景、地标和艺术作品。\n",
    "  - **认知类**: 包括常识推理、数值计算、文本翻译和代码推理。\n",
    "\n",
    "- **结论**:\n",
    "  - **Sphinx** 在存在性检测和场景分析方面得分最高。\n",
    "  - **GPT-4V** 在计数、艺术、OCR、常识推理和代码推理方面领先。\n",
    "  - **Gemini** 在颜色识别、OCR任务、文本翻译中得分最高。\n",
    "\n",
    "**注**: 表中最高分数以**粗体**标记。\n",
    "\n",
    "\n",
    "\n",
    "<h4>关键观察</h4>\n",
    "<ul>\n",
    "    <li>GPT-4V 在名人识别任务上得分为 0。</li>\n",
    "    <li>两模型在位置识别上表现不佳。</li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe6fcba",
   "metadata": {},
   "source": [
    "#### 5.2. 基础感知\n",
    "\n",
    "基本感知就是模型像人一样<span style=\"color: red;\">看和理解</span>图片的能力。\n",
    "\n",
    "这包括识别图片中的物体、理解整个场景，以及使用已知的信息来更好地理解图片。\n",
    "具体包括以下细分任务： \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d178efdf",
   "metadata": {},
   "source": [
    "##### **5.2.1 空间关系**：\n",
    "\n",
    "\n",
    "\n",
    "**AI模型空间关系识别分析**\n",
    "\n",
    "在两个空间关系识别的问题中，**Gemini Pro**、**GPT-4V**和**Sphinx**表现出不同程度的识别能力。\n",
    "\n",
    "**问题一：网球与男人的空间关系**\n",
    "- **Gemini Pro**: 回答简洁，指出网球在男人的**左边**。\n",
    "- **GPT-4V**: 提供了更加细致的描述，认为网球在男人的前方并**稍微偏左**。\n",
    "- **Sphinx**: 回答不准确，指出网球在男人的**下方**。\n",
    "\n",
    "**问题二：乔丹左手边的人是谁**\n",
    "- **Gemini Pro**和**GPT-4V**: 均错误识别人是**科比·布莱恩特**。\n",
    "- **Sphinx**: 回答错误，错误地认为左手边的人是**迈克尔·乔丹**。\n",
    "\n",
    "<img src=\"images/2.1.pic.jpg\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "| 模型       | 识别“左”方向的能力 | 学习“左”的概念后的表现 |\n",
    "|------------|------------------|----------------------|\n",
    "| Gemini Pro | 较差             | 未能成功学习         |\n",
    "| GPT-4V     | 较差             | 未能成功学习         |\n",
    "\n",
    "\n",
    "**结论**\n",
    "- 三个模型在空间关系识别任务中都存在不足。**红色**高亮的回答代表错误，而**黄色**高亮的回答显示了模型在执行任务时的不足。\n",
    "- 需要关注模型对细节的理解能力和准确性，特别是在识别具体对象和它们之间关系的能力上。\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178a3a03",
   "metadata": {},
   "source": [
    "##### **5.2.2 物体计数**：\n",
    "\n",
    "这张图片展示了一系列对象计数任务的结果，其中包括对黑鸟、书本、水果、人群和骰子数量的计数。每个任务都由三个AI模型——**Gemini Pro**、**GPT-4V**和**Sphinx**——进行了回答。\n",
    "\n",
    "**对象计数任务分析**\n",
    "\n",
    "- 黑鸟数量计数:\n",
    "  - **Gemini Pro**: 有8只黑鸟。\n",
    "  - **GPT-4V**: 可见8只黑鸟。\n",
    "  - **Sphinx**: 8只黑鸟。\n",
    "\n",
    "- 书本数量计数:\n",
    "  - **Gemini Pro**: 有5本书。\n",
    "  - **GPT-4V**: 图片中有5本书。\n",
    "  - **Sphinx**: 图片中有2本书。（<span style=\"color:red\">错误</span>）\n",
    "\n",
    "- 水果数量计数:\n",
    "  - **Gemini Pro**: 图片中有4个水果。\n",
    "  - **GPT-4V**: 图片中有3个水果。（<span style=\"color:red\">错误</span>）\n",
    "  - **Sphinx**: 有4个水果。\n",
    "\n",
    "- 人数计数:\n",
    "  - **Gemini Pro**: 有41人。\n",
    "  - **GPT-4V**: 图中有30人。（<span style=\"color:red\">错误</span>）\n",
    "  - **Sphinx**: 有100人。（<span style=\"color:red\">错误</span>）\n",
    "\n",
    "- 骰子计数（面朝上的4点）:\n",
    "  - **Gemini Pro**: 有2个骰子。\n",
    "  - **GPT-4V**: 提供的图片中有2个面朝上点数为4的骰子。\n",
    "  - **Sphinx**: 有2个面朝上点数为4的骰子。\n",
    "\n",
    "\n",
    "<img src=\"images/2_1_object.jpg\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "| 样例类型 | 描述 | Gemini Pro的结果 | 正确答案 |\n",
    "|----------|------|----------------|--------|\n",
    "| 简单样例 | 模型在这些样例中表现准确。 | 准确 | 准确 |\n",
    "| 复杂样例 | 模型在这些样例中容易出错。 | 有误差 | 准确 |\n",
    "| NBA球员图片 | 图片中共有42名球员。 | 41人 | 42人 |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**结论**\n",
    "- 在这些对象计数任务中，**Gemini Pro**表现最为准确，正确回答了大部份问题。\n",
    "- **GPT-4V**在大部分任务中也给出了准确回答，但在计数水果时出现了错误。\n",
    "- **Sphinx**在书本和人数计数任务中回答错误，显示其在某些情况下的计数能力较弱。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134958c1",
   "metadata": {},
   "source": [
    "##### **5.2.3 找不同**：\n",
    "\n",
    "\n",
    "这张图片展示了两个“发现差异”任务的结果。每个任务中都有一个左侧的图画和一个右侧的图画，任务是要找出两者之间的差异。\n",
    "\n",
    "**差异发现任务分析**\n",
    "\n",
    "在展示的两个差异发现任务中，识别能力各不相同。\n",
    "\n",
    "**任务一：卡通人物的差异**\n",
    "- **Gemini Pro**: 正确指出左边的男孩拿着篮球，而右边的男孩拿着足球。男孩们的衣服颜色也不同。\n",
    "- **GPT-4V**: 详细描述了两个卡通人物的衣着和他们持有的体育用品是主要差异。\n",
    "- **Sphinx**: 简单地指出了篮球和足球的差异。\n",
    "\n",
    "**任务二：几何图形的差异**\n",
    "- **Gemini Pro**: 指出头部和尾巴的形状不同。\n",
    "- **GPT-4V**: 对左侧和右侧图形的差异进行了详细描述，包括背部的形状（矩形或方形而不是尖锐形状）、面部的抽象性（三角形状的眼睛，没有明确的嘴巴表现）以及右侧图形相对于左侧更加几何化和抽象。\n",
    "- **Sphinx**: 错误地将左侧图画描述为黑白恐龙，右侧图画描述为黑白鱼。\n",
    "\n",
    "\n",
    "<img src=\"images/2_1找不同.jpg\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "| 模型名称   | 实际差异数量 | 模型识别的差异数量 | 模型响应    |\n",
    "|------------|--------------|--------------------|------------|\n",
    "| Gemini Pro | 3            | 5                  | 错误       |\n",
    "| GPT-4V     | 3            | 5                  | 错误       |\n",
    "\n",
    "\n",
    "**结论**\n",
    "- **Gemini Pro**在快速识别明显差异方面表现良好，但可能缺乏GPT-4V的详细性。\n",
    "- **GPT-4V**在描述细节方面表现出较强的能力，但这可能会导致在一些情况下过度解释。\n",
    "- **Sphinx**在这两个任务中表现不佳，需要改进其识别和分析差异的能力。\n",
    "\n",
    "**注意**: 正确的回答被标记为<span style=\"color:green\">绿色</span>，错误的回答被标记为<span style=\"color:red\">红色</span>，表现不足的回答被标记为黄色。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5991b70",
   "metadata": {},
   "source": [
    "##### **5.2.4 视觉错觉**：\n",
    "\n",
    "**视觉错觉识别任务分析**\n",
    "\n",
    "AI模型在两个不同的视觉错觉识别任务中的表现各有不同。\n",
    "\n",
    "**任务一：梨的亮度比较**\n",
    "- **Gemini Pro**: 指出两个梨的亮度相同。\n",
    "- **GPT-4V**: 详细分析了影响亮度的因素，并计划通过分析像素值来决定哪个梨的亮度更高。\n",
    "- **Sphinx**: 错误地指出右边的梨亮度更高。\n",
    "\n",
    "**任务二：树与人的相似性比较**\n",
    "- **Gemini Pro**: 指出上图中的树与下图中的人不相似。\n",
    "- **GPT-4V**: 认为上图中的树与下图中的人有相似之处，从树枝的分布到人体姿势的弯曲，有一定的视觉相似性。\n",
    "- **Sphinx**: 也认为树与人在视觉上不相似。\n",
    "\n",
    "\n",
    "<img src=\"images/2_1视觉误差.jpg\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "| 模型名称   | 两梨实际亮度 | 模型识别的亮度 | 模型响应     |\n",
    "|------------|---------------|----------------|-------------|\n",
    "| Gemini Pro | 相同          | 相同           | 正确        |\n",
    "| GPT-4V     | 相同          | 不同           | 错误（被错觉影响）|\n",
    "\n",
    "\n",
    "\n",
    "**结论**\n",
    "- 在亮度比较的任务中，**Gemini Pro**给出了正确的答案，而**Sphinx**给出了错误的答案。<span style=\"color:green\">GPT-4V</span>提出了一个更为科学的方法来确定答案，虽然没有给出直接答案，但展现了深入分析的能力。\n",
    "- 在树与人的相似性比较任务中，**GPT-4V**展现了对视觉错觉的深刻理解，而**Gemini Pro**和**Sphinx**都没有认出其中的视觉相似性，这可能指出它们在处理类似视觉错觉任务时的局限性。\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a66b01",
   "metadata": {},
   "source": [
    "##### **5.2.5 场景理解**：\n",
    "\n",
    "\n",
    "**图像场景理解分析**\n",
    "\n",
    "**Gemini Pro**\n",
    "- 描述了一个有**玻璃屋顶**的大型购物中心。\n",
    "- 指出购物中心内有许多**戴着口罩**的人群。\n",
    "- 注意到了商场装饰中的红色和金色，以及大量的红色气球。\n",
    "- 提到了中心舞台上有红地毯和大屏幕，以及周围站立的人群。\n",
    "\n",
    "**GPT-4V**\n",
    "- 描述了一个繁忙的多层购物中心，装饰着为某个事件而布置的气球，创造出节日气氛。\n",
    "- 提到了商场中有**麦当劳**等品牌的标志，以及中央区域被一个带有孩童游乐设施的活动空间所占据。\n",
    "- 描述了商场中的人们参与各种活动，有的在观看活动，有的在购物或用餐。\n",
    "- 强调了商场拥有允许自然光照进的玻璃天花板，整体给人一种活泼、家庭友好的环境印象。\n",
    "\n",
    "**Sphinx**\n",
    "- 描述了一个繁忙的商场，并指出了商场中心的人群聚集。\n",
    "- 提到了红色和白色的气球，以及商场中的一些对象和两个手提包的位置。\n",
    "- 指出了商场充满了活力，人们在忙碌的场所中享受购物和社交。\n",
    "\n",
    "<img src=\"images/2_1场景理解.jpg\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "\n",
    "| 模型名称   | 描述细节程度     | 幻觉实例数量 |\n",
    "|------------|------------------|--------------|\n",
    "| Gemini Pro | 一般             | 较多         |\n",
    "| GPT-4V     | 详细             | 较少         |\n",
    "\n",
    "GPT-4V相比于Gemini Pro显示出更优越的性能，提供了更详细的描述，并且产生幻觉的实例也更少。\n",
    "\n",
    "\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "**结论**\n",
    "- **GPT-4V**在描述细节和场景理解方面表现出色，提供了丰富的信息，包括品牌名称和场景活动，展示了高水平的图像理解能力。\n",
    "- **Gemini Pro**和**Sphinx**虽然描述了场景的一些基本元素，但没有像GPT-4V那样详尽。\n",
    "- 这表明在场景理解任务中，不同AI模型的性能可以有显著差异，特别是在细节描述和理解场景的复杂性方面。\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d00991",
   "metadata": {},
   "source": [
    "##### **5.2.6 视频场景理解**：\n",
    "\n",
    "\n",
    "**视频场景理解分析**\n",
    "\n",
    "AI模型在描述一系列视频帧中的室内场景时，显示了它们不同的理解和描述能力。\n",
    "\n",
    "**Gemini Pro**\n",
    "- 描述了一个有**棕色马赛克墙面**、**灰色百叶窗**和灰蓝色椅子的办公室休息室。\n",
    "- 指出了有两张**圆形桌子**，桌上有两台笔记本电脑和一个电话。\n",
    "- 提到了一个木质柜子以及柜台上的**三盆盆栽**和一个电热水壶。\n",
    "- 还描述了柜子前的蓝色椅子和房间角落的灰色椅子，以及休息室旁边的走廊。\n",
    "\n",
    "**GPT-4V**\n",
    "- 描述了三个不同角度的图片，展示了一个现代室内空间，可能位于商业或办公建筑内。\n",
    "- 第一张图片展示了一间配色中性的房间，周围摆放着灰色的椅子和圆桌，地板为抛光石材瓷砖，从头顶的灯具反射光线。\n",
    "- 第二张图片从不同角度展示了更多的木饰面墙壁，有马赛克瓷砖背景墙增添色彩。\n",
    "- 第三张图片提供了房间入口的视角，有一边是木门，另一边是深灰色地毯的走廊。\n",
    "\n",
    "**Sphinx**\n",
    "- 展示了一个宽敞的房间，内有多样的家具和装饰元素，房间里散布着几把椅子，一些靠近桌子。\n",
    "- 房间还特别指出了摆放在不同位置的花瓶和一个具有独特设计的墙面增加了房间的美观性。\n",
    "\n",
    "\n",
    "<img src=\"images/视频场景理解.jpg\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "| 模型名称   | 第一帧描述           | 第二帧描述           | 整合后的场景描述         |\n",
    "|------------|----------------------|----------------------|------------------------|\n",
    "| Gemini Pro | 两张圆桌和一盆植物   | 一张圆桌和三盆植物   | 两张圆桌和三盆植物     |\n",
    "| GPT-4V     | 两张圆桌和一盆植物   | 一张圆桌和三盆植物   | 逐帧描述图像的内容     |\n",
    "| SPHNIX     | 描述不详             | 描述不详             | 没有全面理解图像序列   |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**结论**\n",
    "- **Gemini Pro**准确合并了前两帧的信息，正确描述了场景中有两个圆桌和盆栽。\n",
    "- **GPT-4V**在细节描述和室内设计感知方面表现出较高水平，给出了环境的多角度综合描述。\n",
    "- **Sphinx**虽提供了房间的一般描述，但未能提及视频帧中的具体细节。\n",
    "\n",
    "\n",
    "Gemini Pro能够有效地整合来自不同帧的信息，而GPT-4V则只是逐帧描述，SPHNIX则未能显示出对图像序列的全面理解。请根据实际情况调整表格中的内容。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ebfc0f",
   "metadata": {},
   "source": [
    "##### **5.2.7 常识**：\n",
    "\n",
    "**常识判断任务分析**\n",
    "\n",
    "两个任务测试了AI模型对常识问题的理解能力。\n",
    "\n",
    "**第一个任务：吸烟行为**\n",
    "- **Gemini Pro**和**GPT-4V**均正确指出图片中禁止吸烟的标志，提示在该区域不应吸烟。\n",
    "- **Sphinx**简单地描述了“禁止吸烟”的标志，但没有提供更多的行为指导。\n",
    "\n",
    "**第二个任务：选择合适的服装**\n",
    "- **Gemini Pro**和**GPT-4V**都正确指出，去南极应该穿图中的第二套衣服，因为它提供了必要的保暖。\n",
    "- **Sphinx**错误地指出应该穿图中的第一套衣服，这是一个基本的短袖T恤，不适合极寒的环境。\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"images/常识.jpg\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "<img src=\"images/常识2.jpg\" style=\"margin-left: 0px\" width=\"400px\">\n",
    "\n",
    "| 模型名称   | 社会规范应用 | 物理规律应用 | 备注 |\n",
    "|------------|--------------|--------------|------|\n",
    "| Gemini Pro | <span style=\"color: green;\">良好</span> | <span style=\"color: green;\">良好</span> | 准确选择南极洲寒冷天气的衣物 |\n",
    "| GPT-4V     | <span style=\"color: green;\">良好</span> | <span style=\"color: green;\">良好</span> | 准确选择南极洲寒冷天气的衣物 |\n",
    "| SPHNIX     | <span style=\"color: green;\">良好</span> | <span style=\"color: red;\">较差</span>   | 了解寒冷天气需穿厚衣，但选错衣物 |\n",
    "\n",
    "\n",
    "**结论**\n",
    "- **Gemini Pro**和**GPT-4V**在这两个常识问题上都给出了正确的答案，显示了它们对于常识性知识的良好理解。\n",
    "- **Sphinx**在第二个任务中的错误显示了它在理解环境上还有进步的空间。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8964739c",
   "metadata": {},
   "source": [
    "##### **5.2.8 学科知识**：\n",
    "\n",
    "\n",
    "**科学知识理解任务分析**\n",
    "\n",
    "AI模型在两组科学知识理解任务中的表现各不相同。\n",
    "\n",
    "**第一组任务：地理知识**\n",
    "- **Gemini Pro**和**GPT-4V**正确识别出手指指向的国家是**印度**，并且正确地将其归属于**亚洲**大陆。\n",
    "- **Sphinx**错误地认为手指指向的是**澳大利亚**，并且错误地将其归属于**大洋洲**。\n",
    "\n",
    "**第二组任务：地质地貌知识**\n",
    "- **Gemini Pro**将图片中的地貌错误地描述为**沙漠**，而实际上是由风蚀作用形成的岩石地貌——**雅丹地貌**。\n",
    "- **GPT-4V**提供了详细的描述，正确地识别了地貌为由风蚀作用形成的**雅丹地貌**，它通常出现在沙漠环境中。\n",
    "\n",
    "**第三组任务：物理现象**\n",
    "- **Gemini Pro**准确解释了手和书的图像，说明了图像在镜子中是翻转的，因此虽然看似书在覆盖手，实际上是镜像。\n",
    "- **GPT-4V**则解释了这是由于光线在镜子上的反射，遵循光的反射定律，因此可以看到手的影像。\n",
    "\n",
    "**第四组任务：光学现象**\n",
    "- **Gemini Pro**和**GPT-4V**都正确描述了图像显示的是光的**色散**现象，当光通过棱镜时，会折射并分解成光谱的各个颜色。\n",
    "- **Sphinx**提供了部分正确的信息，但没有准确使用“色散”这一术语来描述光通过棱镜分解成不同颜色的现象。\n",
    "\n",
    "<img src=\"images/学科知识.jpg\" style=\"margin-left: 0px\" width=\"500px\">\n",
    "\n",
    "<img src=\"images/学科知识2.jpg\" style=\"margin-left: 0px\" width=\"450px\">\n",
    "\n",
    "\n",
    "|   | 物理化学 | 历史地理 |\n",
    "|---|----------|----------|\n",
    "| Gemini Pro | <span style=\"color: green;\">良好</span> | <span style=\"color: green;\">良好</span> |\n",
    "| GPT-4V     | <span style=\"color: green;\">良好</span> | <span style=\"color: green;\">良好</span> |\n",
    "\n",
    "\n",
    "**结论**\n",
    "- **Gemini Pro**在地理和物理知识的任务中表现出了准确性，但在识别地质地貌时犯了错误。\n",
    "- **GPT-4V**在所有科学知识任务中都提供了准确和详细的解释，显示了它在处理科学知识方面的强大能力。\n",
    "- **Sphinx**在某些任务中给出了部分正确的回答，但在细节和精确术语的使用上存在不足。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe9adfe",
   "metadata": {},
   "source": [
    "##### **5.2.9 多元文化习俗**：\n",
    "\n",
    "\n",
    "AI模型在描述一张描绘中国传统舞狮的图片时，表现出不同程度的理解能力。\n",
    "\n",
    "**Gemini Pro**\n",
    "- 英文描述：正确识别了图片中的四个人正在进行**舞狮表演**，穿着色彩鲜艳的狮子服装，并且在一个拥有红色屋顶和红灯笼装饰的建筑物前表演。\n",
    "- 中文描述：同样准确地描述了舞狮表演，并用恰当的中文表达了场景内容。\n",
    "\n",
    "**GPT-4V**\n",
    "- 英文描述：也正确地描述了传统的**中国舞狮**，并提到了三种颜色的狮子服装和背后的中国建筑，暗示场景可能是在节庆时刻。\n",
    "- 中文描述：提供了详细的场景描述，并准确使用中文表达了舞狮的文化背景。\n",
    "\n",
    "<img src=\"images/多元文化习俗.jpg\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "|  模型名称 | 理解种族和文化元素 | 多语言能力 |\n",
    "|------------|----------------------|--------------|\n",
    "| Gemini Pro | <span style=\"color: green;\">良好</span> | <span style=\"color: green;\">良好</span> |\n",
    "| GPT-4V     | <span style=\"color: green;\">良好</span> | <span style=\"color: green;\">良好</span> |\n",
    "| SPHNIX     | <span style=\"color: green;\">良好</span> | <span style=\"color: red;\">不具备</span>   |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**结论**\n",
    "- **Gemini Pro**和**GPT-4V**都准确地理解并描述了图片中的文化活动，表现出它们对多元文化习俗的良好理解能力。\n",
    "- 两个模型都能够以英文和中文提供准确的场景描述，显示了它们在语言转换方面的能力。\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efc9e69",
   "metadata": {},
   "source": [
    "##### **5.2.10 世界知识**：\n",
    "\n",
    "\n",
    "\n",
    "**世界知识理解任务分析**\n",
    "\n",
    "**名人识别与描述**\n",
    "- **Gemini Pro**和**GPT-4V**正确识别了两个名人，分别是漫威宇宙中的**Doctor Strange**和著名歌手**Taylor Swift**。\n",
    "- **Sphinx**在识别**Doctor Strange**的任务中出错，错误地将其识别为**Iron Man**。\n",
    "\n",
    "**电影认识与描述**\n",
    "- **Gemini Pro**准确识别了参考的电影，包括《黑暗骑士》和《黑客帝国》，并正确提供了导演和主演信息。\n",
    "- **GPT-4V**在描述电影《黑客帝国》时显示出对科幻电影特征的深刻理解，但在提供具体电影信息时表现出不足。\n",
    "\n",
    "**艺术品识别与描述**\n",
    "- **Gemini Pro**和**GPT-4V**都正确描述了两件中国古代艺术品，分别是青铜器“鼎”和金面具。\n",
    "- **Sphinx**对青铜器的描述不够准确，没有提供详细的历史背景。\n",
    "\n",
    "\n",
    "<img src=\"images/世界知识.jpg\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "<img src=\"images/世界知识2.jpg\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "<img src=\"images/世界知识3.jpg\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "| 任务/模型  | Gemini Pro | GPT-4V | SPHNIX |\n",
    "|------------|------------|--------|--------|\n",
    "| 名人识别 | <span style=\"color: green;\">良好</span> | <span style=\"color: green;\">良好</span> | <span style=\"color: green;\">良好</span> |\n",
    "| 地标识别 | <span style=\"color: green;\">良好</span> | <span style=\"color: green;\">良好</span> | <span style=\"color: green;\">良好</span> |\n",
    "| 标志识别 | <span style=\"color: green;\">良好</span> | <span style=\"color: green;\">良好</span> | <span style=\"color: green;\">良好</span> |\n",
    "| 电影识别 | <span style=\"color: green;\">良好</span> | <span style=\"color: green;\">良好</span> | <span style=\"color: green;\">良好</span> |\n",
    "| 食物识别 | <span style=\"color: green;\">良好</span> | <span style=\"color: green;\">良好</span> | <span style=\"color: green;\">良好</span> |\n",
    "| 植物识别 | <span style=\"color: green;\">良好</span> | <span style=\"color: green;\">良好</span> | <span style=\"color: green;\">良好</span> |\n",
    "| 动物识别 | <span style=\"color: green;\">良好</span> | <span style=\"color: green;\">良好</span> | <span style=\"color: green;\">良好</span> |\n",
    "| 真实人物相关信息回应 | <span style=\"color: red;\">不回应</span> | <span style=\"color: green;\">偶尔回应</span> | <span style=\"color: red;\">不回应</span> |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**结论**\n",
    "\n",
    "- **Gemini Pro**在多数任务中提供了准确的信息，显示出其对各类知识的良好掌握。\n",
    "- **GPT-4V**在理解任务的上下文和提供详细描述方面表现出色，但在特定知识点的准确识别上有时会出现不足。\n",
    "- **Sphinx**在一些任务中提供了部分正确的信息，但在深入理解和细节描述上存在明显的不足。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e452d7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### 5.3. 高级认知\n",
    "\n",
    "\n",
    "*对模型的<span style=\"color: red;\">认知能力</span>进行了全面评估。这些测试不仅考察了<span style=\"color: red;\">模型对视觉内容的理解</span>，还包括了它们在<span style=\"color: red;\">更复杂情况下的思考和问题解决能力</span>*\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### **5.3.1 表格和图表推理**\n",
    "\n",
    "\n",
    "**表格和图表推理任务分析**\n",
    "\n",
    "**Gemini Pro**\n",
    "- 描述了一个比较两个数字`a`和`b`的算法。如果`b`大于`a`，则显示`b`；否则，显示`a`。流程最后结束。\n",
    "\n",
    "**GPT-4V**\n",
    "- 描述了一个决策过程，包括开始、读取值、比较和根据比较结果显示值的步骤。总结说，此流程图读取两个值并显示较大的值。\n",
    "\n",
    "**Sphinx**\n",
    "- 解释了流程图是一个决策制定过程的视觉表示。它由一系列连接的框组成，每个框代表一个决策点或过程步骤。流程图从“开始”框开始，然后是一个“是”判断框，如果`b`大于`a`，则流程会移动到“显示B”框；否则，会移动到“显示A”框。流程图在显示了`a`或`b`之后结束。\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"images/表格和图表推理.jpg\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "**结论**\n",
    "- **Gemini Pro**和**GPT-4V**都正确理解了流程图的逻辑，并准确描述了步骤和结果。这表明它们能够正确执行基于规则的推理任务。\n",
    "- **Sphinx**提供了流程图的概念性解释，虽然正确，但没有**Gemini Pro**和**GPT-4V**那样详细。\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### **5.3.2 代码生成**\n",
    "\n",
    "**Gemini Pro** 和 **GPT-4V** 均提供了LaTeX代码的准确表示。**Sphinx** 没有给出结果。\n",
    "\n",
    "<img src=\"images/代码生成.jpg\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "- **Gemini Pro** 和 **GPT-4V**：都正确提供了LaTeX代码。\n",
    "- **Sphinx**：未给出答案。\n",
    "\n",
    "\n",
    "##### **5.3.3 抽象视觉刺激**\n",
    "\n",
    "\n",
    "**Gemini Pro** 描述了四个形状，但没有提供具体的判断。**GPT-4V** 给出了每个形状的详细解释，并对它们可能代表的内容进行了推理。\n",
    "\n",
    "<img src=\"images/抽象视觉刺激.jpg\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "- **Gemini Pro**：描述了形状，但未明确其代表的内容。\n",
    "- **GPT-4V**：提供了详细的形状解释和推理。\n",
    "\n",
    "\n",
    "##### **5.3.4 韦氏成人智力量表**\n",
    "\n",
    "**Gemini Pro** 和 **GPT-4V** 都通过分析给定的立方体图片来确定字母`b`的对面字母。**Sphinx** 提供了部分正确的信息，但没有展示出完整的推理过程。\n",
    "\n",
    "<img src=\"images/韦氏成人智力量表.jpg\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "- **Gemini Pro** 和 **GPT-4V**：都通过逻辑分析确定了立方体相对面的字母。\n",
    "- **Sphinx**：提供了部分信息，但推理不完整。\n",
    "\n",
    "##### **5.3.5 瑞文推理测验**\n",
    "\n",
    "\n",
    "其中包含了一系列图形，AI模型需要选择哪一个图形\n",
    "最适合填充缺失位置。\n",
    "\n",
    "<img src=\"images/瑞文推理测验.jpg\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "- **Gemini Pro** 使用了一种看似合理的解题策略，它考察了内外圈的环数关系，但这种方法没有找到正确的图形。虽然Gemini Pro观察到每行外圈环数比内圈总环数少一环，但这一规律并不适用于所有行，因此它选择了错误的答案。\n",
    "\n",
    "- **GPT-4V** 考虑了视觉序列和模式识别，特别注意到同心圆的数量随着列的变化而增加，以及圆圈粗细的交替模式。然而，GPT-4V的推理也并未能准确找到缺失图形的正确规律，导致选择了错误的答案。\n",
    "\n",
    "- **Sphinx** 的答案是基于错误的方法得出的，它仅仅根据选项的顺时针位置选择了答案，这种方法忽略了图形之间的逻辑关系，结果也是不正确的。\n",
    "\n",
    "\n",
    "##### **5.3.6 数学问题**\n",
    "\n",
    "\n",
    "图片中的内容是关于矩阵代数的数学问题的解答。\n",
    "\n",
    "**数学问题**\n",
    "要求回答图片中的问题。\n",
    "\n",
    "**提示框**\n",
    "假设 A 和 B 是 3x3 可逆矩阵，它们的逆矩阵分别是：\n",
    "\n",
    "- A 的逆矩阵是一个以 -2、-1、0 为对角线元素的矩阵；\n",
    "- B 的逆矩阵是一个以 1、1、5 为对角线元素的矩阵。\n",
    "\n",
    "**问题是：求 (AB) 的逆矩阵是什么？**\n",
    "给出了四个选项：\n",
    "(a) [2 1 0; 2 1 0; 0 -5 1]\n",
    "(b) [2 1 0; 2 1 0; -10 -5 1]\n",
    "(c) [-2 1 0; 0 5 1]\n",
    "(d) [-2 1 0; -10 5 1]\n",
    "\n",
    "**下面的部分列出了不同的答案提供者**：\n",
    "- **Gemini Pro** 选择了 (d) [-2 1 0; -10 5 1]。\n",
    "- **GPT-4V** 也指出 (AB) 的逆矩阵的答案是 (d)。\n",
    "- **SPHINX** 讨论了矩阵可逆性的条件和计算逆矩阵的方法。\n",
    "\n",
    "<img src=\"images/数学问题.jpg\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "**结论**：\n",
    "\n",
    "根据图片中提供的信息和矩阵理论，我们可以得出结论，正确答案很可能是 (d) \\[-2 1 0; -10 5 1\\]。这也得到了答案提供者 **Gemini Pro** 和 **GPT-4V** 的支持。然而，为了验证这个结论，我们需要进行实际的矩阵计算，即计算 B^-1 A^-1 来确定 (AB)^-1 的确切值。\n",
    "\n",
    "##### **5.3.7 物理问题**\n",
    "\n",
    "**物理问题**\n",
    "提示用户根据学生已经解决的物理问题来补充解答。建议用户使用LaTeX格式来表示数学公式，并指出由于问题没有给出特定的物理量值，所以结果只应包含数学量 F。\n",
    "\n",
    "问题描述了一个线电荷问题，其中一条长度为 L 的均匀分布电荷的直线，总电荷量为 Q。要求找到线末端 a 点位置的电荷 q 上的力 F。\n",
    "\n",
    "\n",
    "<img src=\"images/物理问题.jpg\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "\n",
    "**Gemini Pro**\n",
    "描述了如何通过积分来计算总力 F，并得出了总力的表达式。\n",
    "\n",
    "**GPT-4V**\n",
    "对电路问题进行了分析，首先计算出总电阻，然后应用欧姆定律解决问题，并得出结论电流 I 为 2A。同时，指出 R_0 和 R_rheostat 电阻并联时，流过 R_0 的电流为 1A。\n",
    "\n",
    "**SPHINX**\n",
    "提到电流正在通过电阻器，所以流过电阻器的答案是肯定的。\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e5ba3f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### **5.4. 挑战性视觉任务**\n",
    "\n",
    "##### **5.4.1 目标检测**\n",
    "\n",
    "这张图片展示了一个关于**图像处理**的文档截图，重点讨论了**目标检测**任务。在图像中，有三个不同的系统给出了它们的检测结果：\n",
    "\n",
    "<img src=\"images/目标检测.jpg\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "- **Gemini Pro**：提供了**两辆车**和**五个人**的位置，并以`(x1, y1, x2, y2)`的格式给出了具体的坐标，其中`(x1, y1)`是边界框的左上角坐标，而`(x2, y2)`是右下角的坐标。\n",
    "- **GPT-4V**：表示无法直接提供边界框或任何形式的标注，并建议使用如**OpenCV**或**机器学习框架**等计算机视觉库来编程实现目标检测。\n",
    "- **SPHINX**：声称图像中有11个对象，包括两辆SUV和其他物体，给出了一系列的坐标，但是，没有完整地列出所有对象的信息。\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### **5.4.2 指称表达式理解**\n",
    "\n",
    "- **目的**：识别并标记图片中由自然语言描述指定的对象。\n",
    "- **图片内容**：包含两只小狗的草地背景图片。\n",
    "\n",
    "<img src=\"images/指称表达式理解.jpg\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "**GPT-4V**\n",
    "- **结果**：给出了边界框标记\n",
    "- **分析**：GPT-4V将边界放置在了黑色小狗身上。\n",
    "\n",
    "**Gemini Pro**\n",
    "- **结果**：提供了边界框的具体坐标。\n",
    "- **坐标值**：\n",
    "  - xmin: 430\n",
    "  - ymin: 260\n",
    "  - xmax: 640\n",
    "  - ymax: 480\n",
    "\n",
    "**SPHINX**\n",
    "- **结果**：以百分比形式提供边界框坐标。\n",
    "- **百分比坐标**：[0.44,0.26,0.91,0.80]\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "##### **5.4.3 短语定位**\n",
    "\n",
    "- **任务要求**：根据短语 \"斑马和犀牛在车旁边\"，在图像中标记所有名词的边界框。\n",
    "\n",
    "<img src=\"images/短语定位.jpg\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "**Gemini Pro**\n",
    "- **边界框坐标值**：\n",
    "  - 斑马: `[400, 450, 500, 550]`\n",
    "  - 犀牛: `[650, 300, 800, 450]`\n",
    "  - 车: `[100, 300, 300, 450]`\n",
    "- **评价**：有两个边界框超出了界限，剩余的也不正确。\n",
    "\n",
    "**GPT-4V**\n",
    "- **边界框坐标值**：\n",
    "  - 斑马: `[(236, 230), (318, 330)]`\n",
    "  - 犀牛: `[(510, 255), (590, 340)]`\n",
    "  - 车: `[(400, 180), (500, 270)]`\n",
    "- **评价**：只有斑马的边界框接近准确。\n",
    "\n",
    "**SPHINX**\n",
    "- **边界框坐标值**：一个包含所有对象的边界框 `[0.09, 0.73, 0.31, 0.75]`\n",
    "- **评价**：未能理解指令，只提供了一个边界框。\n",
    "\n",
    "**结论**\n",
    "三个模型在执行短语定位任务时均显示出不同程度的不足。正确的边界框标记对于图像内容理解至关重要，尤其是在自然语言处理与视觉数据结合的场景中。\n",
    "\n",
    "\n",
    "\n",
    "##### **5.4.4 视频动作识别**\n",
    "\n",
    "- **任务要求**：描述图片中的人物在做什么，并提供尽可能多的信息。\n",
    "\n",
    "<img src=\"images/视频动作识别.jpg\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "\n",
    "**Gemini Pro**\n",
    "- **描述**：确认人物为<span style=\"color:blue\">迈克尔·杰克逊</span>，并指出他在<span style=\"color:green\">跳舞</span>。\n",
    "- **服装描述**：黑色西装、白衬衫、黑领带、黑帽子、黑鞋和红手套。\n",
    "- **团队协作**：与其他穿着相同的舞者一起以协调的方式跳舞。\n",
    "\n",
    "**GPT-4V**\n",
    "- **描述**：人物似乎在进行一种光滑、滑行式的<span style=\"color:green\">舞蹈表演</span>。\n",
    "- **服装描述**：黑色软呢帽、黑西装、白衬衫、领带和黑色便鞋，以及标志性的红色手套。\n",
    "- **表演分析**：动作和服装暗示这可能是对<span style=\"color:blue\">流行文化中著名表演的致敬</span>或再现。\n",
    "\n",
    "**SPHINX**\n",
    "- **描述**：人物正在<span style=\"color:red\">舞台上</span>。\n",
    "\n",
    "**结论**\n",
    "在视频动作识别任务中，各系统在描述动作和理解背景上的精确度和深度各不相同。正确识别动作对于视频内容的分析和理解至关重要，尤其是在与<span style=\"color:blue\">流行文化</span>相关的内容识别上。\n",
    "\n",
    "\n",
    "\n",
    "##### **5.4.5 视觉故事生成**\n",
    "\n",
    "这张图片是关于**视觉故事生成**（Visual Story Generation）的界面截图。任务提示要求根据提供的四幅连环漫画创建一个与视觉内容相符、尽可能丰富的故事。\n",
    "\n",
    "<img src=\"images/视觉故事生成.jpg\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "\n",
    "截图中展示了两个不同系统——Gemini Pro和GPT-4V——以及一个名为SPHINX的系统对该任务的回答：\n",
    "\n",
    "1. **Gemini Pro** 创作了一个名叫John的人物的故事，他在一个安静的早晨醒来，经历了一个关于迟到的噩梦。John匆忙出门上班，但最终还是迟到了，并向老板道歉。第二天，他设定了更早的闹钟，准时醒来，开始了正确的一天。\n",
    "2. **GPT-4V** 创作的故事包含了幽默感，描述了现代生活的斗争，特别是在家工作时遇到的混乱和意外。故事的四个部分分别描述了被闹钟吵醒、交通堵塞、咖啡洒了一地以及最后的转折点——角色实际上是在家中工作。\n",
    "3. **SPHINX** 的故事讲述了John因为睡过头而在家匆忙开始工作的情况。在他开始工作后不久，他意识到自己并不孤单，他的女儿和她的朋友在看着他。故事以John疲惫地在沙发上睡着，对自己成功地在家工作感到满意结束。\n",
    "\n",
    "\n",
    "结论是，Gemini Pro在创建与漫画内容相符的连贯故事方面表现出色，而GPT-4V虽提供了准确的每个漫画的描述，却没有形成一个连贯的故事。SPHINX生成的故事与漫画的相关性较弱。\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2b5a72",
   "metadata": {},
   "source": [
    "\n",
    "#### **5.5. 专家能力**\n",
    "\n",
    "\n",
    "##### **5.5.1 自动驾驶**\n",
    "\n",
    "这张图片是自动驾驶领域中关于**驾驶意图理解**（Driving Intentions）的界面截图，任务提示要求描述从驾驶者视角看到的观察结果以及接下来的驾驶意图。\n",
    "\n",
    "<img src=\"images/自动驾驶.jpg\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "1. **Gemini Pro** 描述它是夜晚，正在一条每个方向有单车道的道路上驾驶，有一盏路灯在远处。描述中提到了正在接近的斑马线，以及有一个行人正在过街，需要为了行人而停车。\n",
    "2. **GPT-4V** 提供了更详细的观察，包括路面的照明情况、道路标记、交通、行人、标志以及速度建议。GPT-4V建议在接近行人过街和公交站的地方减速，并准备停车。\n",
    "3. **SPHINX** 描述了在夜间驾驶时看到前方有一辆车，并且有几盏路灯照亮了道路。SPHINX计划在行人过街前停车，并继续其旅程，同时遵循交通规则，并对任何潜在危险保持警惕。\n",
    "\n",
    "\n",
    "\n",
    "##### **5.5.2 缺陷检测**\n",
    "\n",
    "\n",
    "这张图片是关于**缺陷检测**（Defect Detection）的界面截图，任务提示要求详细说明图片中是否有任何异常。\n",
    "\n",
    "<img src=\"images/缺陷检测.jpg\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "\n",
    "1. **Gemini Pro** 系统指出螺丝似乎是断裂的。\n",
    "2. **SPHINX** 系统描述这是一张金属螺丝的黑白照片，并指出螺丝看起来扭曲了，这对于螺丝来说是不常见的形状。\n",
    "3. **GPT-4V** 系统提供了一个更详细的分析，指出了螺丝的多个异常点，包括螺纹模式不一致、轴部设计不典型、头部损坏、材质磨损和可能的制造缺陷。\n",
    "\n",
    "结论是，GPT-4V在识别螺丝上的缺陷方面提供了最全面和详细的分析。\n",
    "\n",
    "##### **5.5.3 医疗诊断**\n",
    "\n",
    "这张图片是关于**医疗图像理解**（Medical Image Understanding）的界面截图，任务提示是作为放射科专业人员，需要基于提供的X射线胸片生成一个放射学报告。\n",
    "\n",
    "1. **GPT-4V** 提供了一个详细的放射学报告，包括患者的ID、检查方式、检查日期、临床历史以及技术细节。在报告的“发现”部分，提到了肺部呈现弥散的网格状图案，心影增大，可能提示心包积液，肺血管结构不清晰可能表示有小的胸腔积液或胸膜增厚。在“印象”部分，建议进行心脏超声和CT胸部进一步详细评估肺部情况。\n",
    "2. **Gemini Pro** 生成了一个更简洁的报告，指出存在胸腔大量积液，心脏未增大，肺实质清晰，以及大血管无异常。\n",
    "3. **SPHINX** 的印象部分重复了患者的侧位X线图显示出肩膀和肋骨笼清晰且定义良好，未发现骨折或脱位迹象。\n",
    "\n",
    "\n",
    "<img src=\"images/医疗诊断.jpg\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "结论是，GPT-4V在医疗图像理解和放射学报告撰写方面表现出较高的准确性和专业性。\n",
    "\n",
    "\n",
    "##### **5.5.4 经济分析**\n",
    "\n",
    "\n",
    "这张图片是关于**经济分析**（Economic Analysis）的界面截图，任务提示是分析Google股票价格的历史趋势图，并预测在Google发布其最新的大型多模态模型Gemini之后，12月7日Google股票的潜在价格变动。\n",
    "\n",
    "\n",
    "1. **Gemini Pro** 预测Google的股价在12月7日因发布Gemini而可能上涨，因为投资者可能对这款新产品及其产生收益的潜力感到乐观。\n",
    "2. **SPHINX** 表示无法预测Google股票的未来价格走势，因为股市受多种因素影响，如市场趋势、经济指标和公司新闻等，强调进行深入研究和分析在做出任何投资决策前是重要的。\n",
    "3. **GPT-4V** 解释说，作为一个由OpenAI开发的AI，它没有预测未来股价或市场动向的能力，因为这些被广泛的因素影响，不仅仅是产品发布，即便是像发布大型多模态模型这样重大的事件。\n",
    "\n",
    "<img src=\"images/经济分析.jpg\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "\n",
    "在预测股价方面，必须考虑广泛的市场因素和投资者情绪，而不仅仅是单一事件的影响。\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Gemini vs GPT-4V 结论\n",
    "\n",
    "鉴于其卓越的多模态推理能力，Gemini 确实是 GPT-4V 的有力挑战者。在大多数情况下，与 GPT-4V 相比，Gemini 的回答准确性具有竞争力，并展示了不同的回答风格和偏好。GPT-4V 倾向于生成对感知任务更详细的描述，并为认知任务提供深入的分析和逐步的中间推理，而 Gemini 更喜欢对答案提供直接而简洁的回应，这有助于用户快速找到相关信息。\n",
    "\n",
    "除此以外，两个模型也存在一定的共性问题，比如空间感知能力不强，复杂 OCR 和抽象视觉理解不理想，推理过程可能存在不自洽结果，对提示设计的鲁棒性不足。可以看到，Gemini 和 GPT-4V 在很多情况下仍然陷入困境，显示出通向通用多模态大模型的漫长道路。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b6a2f9-b5a2-40f0-8b1d-a2c151e9529b",
   "metadata": {},
   "source": [
    "## **六 CMU评测：关于Gemini 造假风波！！！**\n",
    "\n",
    "网友扒出Gemini Ultra在测评时用了很多小动作，疑似“胜之不武”！存在刻意刷榜、夸大性能的嫌疑，演示视频也被扒出是“合成造假”.\n",
    "\n",
    "\n",
    "卡耐基梅隆大学的学者进行了深入探讨，测试包括<span style=\"color:blue\">推理</span>、<span style=\"color:blue\">基于知识的问题回答</span>、<span style=\"color:blue\">数学问题解决</span>\n",
    "\n",
    "\n",
    "**谷歌Gemini模型与OpenAI GPT模型的对比**\n",
    "\n",
    "这里不逐一进行分析，我们每个测试方面给出测试结果。有兴趣的伙伴参照论文\n",
    "\n",
    "https://arxiv.org/abs/2312.11444\n",
    "\n",
    "以及对比Gemini的评测报告\n",
    "\n",
    "https://storage.googleapis.com/deepmind-media/images/gemini_1_report.pdf\n",
    "\n",
    "\n",
    "| 模型版本     | 描述                                               | 性能对比                          | 争议点                                                    |\n",
    "|------------|----------------------------------------------------|---------------------------------|-----------------------------------------------------------|\n",
    "| Gemini Ultra | 谷歌史上功能最强大、最通用的多模态模型             | 超越GPT-4（<span style=\"color:red\">有争议</span>）       | 使用<span style=\"color:orange\">不正当手段</span>进行测评   |\n",
    "| Gemini Pro   | 适用于各种任务的最佳模型                           | 与GPT-3.5相当（<span style=\"color:red\">有争议</span>）   | 性能被<span style=\"color:orange\">夸大</span>              |\n",
    "| Gemini Nano  | 最高效的设备端任务模型                             | -                               | -                                                         |\n",
    "| GPT-3.5 Turbo | OpenAI的高性能语言模型                             | 在评估任务中优于Gemini Pro     | -                                                         |\n",
    "| GPT-4 Turbo   | OpenAI的最新、最先进的语言模型                     | Gemini Ultra未能超越            | -                                                         |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### 6.1. 基于知识的问答 (MMLU)\n",
    "\n",
    "- **数据集**：MMLU, 总共14,042个测试样本\n",
    "- **测试方法**：5-shot下使用标准提示和<span style=\"color:blue\">思维链提示</span>\n",
    "- **结果**：\n",
    "  - Gemini Pro的准确率低于<span style=\"color:orange\">GPT 3.5Turbo</span>，远低于<span style=\"color:red\">GPT 4 Turbo</span>\n",
    "  - 思维链引导性能无显著差异，表明Gemini在知识问答任务上不能显著受益于更强的推理导向提示\n",
    "\n",
    "- **偏见分析**：\n",
    "  - Gemini倾向于选择答案\"D\"，而GPT模型选择分布更均衡\n",
    "  - 表示Gemini在多选题解决方案上可能未经过调整，存在答案排序偏见\n",
    "\n",
    "- **性能探讨**：\n",
    "  - Gemini在特定任务上表现不佳，可能由于过强的内容过滤机制\n",
    "  - 在moral_scenarios和human_sexuality任务的API响应率分别为85%和28%\n",
    "  - 基本数学推理任务，如formal_logic和elementary_mathematics表现较差\n",
    "\n",
    "##### 6.2. 通用推理 (BIG-Bench Hard)\n",
    "\n",
    "- **数据集**：BIG-Bench Hard, 27个不同的推理任务\n",
    "- **结果**：\n",
    "  - Gemini Pro整体准确率略低于<span style=\"color:orange\">GPT 3.5 Turbo</span>，远低于<span style=\"color:red\">GPT 4 Turbo</span>\n",
    "  - 在长问题、复杂问题上表现不佳，GPT模型显示更高的鲁棒性\n",
    "  - 物品状态跟踪任务中，Gemini表现欠佳\n",
    "\n",
    "- **优势科目**：\n",
    "  - 需要世界知识的任务\n",
    "  - 操作符号堆栈任务\n",
    "  - 按字母顺序排序单词的任务\n",
    "  - 解析表格的任务中表现优于<span style=\"color:orange\">GPT 3.5 Turbo</span>\n",
    "\n",
    "\n",
    "\n",
    "##### 6.3. 数学推理能力\n",
    "\n",
    "- **数据集表现**：在四项数学推理数据集中，`Gemini Pro` 的准确率略低于 `GPT 3.5 Turbo`。\n",
    "- **多位数答案准确性**：`GPT 3.5 Turbo` 在多位数数学问题上显示出更高的鲁棒性，而 `Gemini Pro` 的性能随位数增加而下降。\n",
    "\n",
    "##### 6.4. 代码生成能力\n",
    "\n",
    "- **数据集表现**：\n",
    "  - `HumanEval` 和 `ODEX` 数据集测试表明，`Gemini Pro` 的性能低于 `GPT 3.5 Turbo` 且远低于 `GPT 4 Turbo`。\n",
    "  - 在代码生成能力方面，`Gemini` 仍有改进空间。\n",
    "- **解长度与性能关系**：\n",
    "  - 短解长度（<100）：`Gemini Pro` 能与 `GPT 3.5` 相匹敌。\n",
    "  - 长解长度：随着任务难度增加，`Gemini Pro` 性能大幅落后。\n",
    "\n",
    "##### 6.5. 第三方库使用表现\n",
    "\n",
    "- **特定库性能**：\n",
    "  - 使用 `mock`、`pandas`、`numpy`、`datetime` 等库时，`Gemini Pro` 表现不及 `GPT 3.5`。\n",
    "  - 在 `matplotlib` 案例中，`Gemini Pro` 性能超过了 `GPT 3.5` 和 `GPT 4`，特别在绘图可视化任务上展现出了更强的能力。\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### 6.6. 机器翻译性能比较\n",
    "\n",
    "使用FLORES-200机器翻译基准测试进行了以下比较：\n",
    "\n",
    "- **参与者**:\n",
    "  - OpenAI的GPT 4 Turbo\n",
    "  - OpenAI的GPT 3.5 Turbo\n",
    "  - Google的Gemini Pro\n",
    "  - 开源机器翻译模型NLLB-MoE\n",
    "  - 谷歌翻译\n",
    "\n",
    "- **测试结果**:\n",
    "  - GPT 4 Turbo在多语言模型中表现出色，尤其在低资源语言中。\n",
    "  - Gemini Pro在8种语言上优于GPT 3.5 Turbo和GPT 4 Turbo，并在4种语言上表现出最佳性能。\n",
    "  - 然而，Gemini Pro表现出<span style=\"color:orange\">\"Blocked Response\"</span>错误，影响了总体得分。\n",
    "\n",
    "##### 6.7. 网络导航代理任务性能比较\n",
    "在WebArena基于执行的模拟环境中，任务包括：\n",
    "\n",
    "- 信息搜索\n",
    "- 站点导航\n",
    "- 内容和配置操作\n",
    "\n",
    "- **测试结果**:\n",
    "  - Gemini-Pro的整体表现略逊于GPT-3.5-Turbo。\n",
    "  - Gemini-Pro在带UA提示的情况下表现更好，成功率为7.09%。\n",
    "\n",
    "- **特定网站表现**:\n",
    "  - 在gitlab和map上，Gemini-Pro不如GPT-3.5-Turbo。\n",
    "  - 在shopping admin、reddit和shopping网站上，Gemini-Pro与GPT-3.5-Turbo接近。\n",
    "  - 在多网站任务上，Gemini-Pro优于GPT-3.5-Turbo，表明其在复杂子任务中表现更佳。\n",
    "\n",
    "- **任务可实现性预测**:\n",
    "  - 在UA提示下，Gemini-Pro将80.6%的任务预测为不可实现，GPT-3.5-Turbo为47.7%，而实际数据集中只有4.4%的任务不可实现。\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "通过以上多个任务的比拼，总结如下：\n",
    "\n",
    "Gemini Pro在模型大小和类型上与 GPT 3.5 Turbo 相当，但在某些任务表现略逊于GPT 3.5 Turbo。\n",
    "\n",
    "Gemini Pro相比其他模型存在一些短板，比如在多项选择题中存在回答顺序的偏见、推理步骤较短、由于内容过滤机制严格导致的响应失败等问题。\n",
    "\n",
    "当然也有优势：在特别长而复杂的推理任务上，Gemini表现更佳，且在未经筛选的多语种任务上也表现出出色的能力，而GPT 3.5 Turbo则稍逊一筹。\n",
    "值得一提的是，以上的结论截至到2023年12月19日，且依赖于作者选择的具体提示和生成参数。随着模型和系统的升级，结果随时会发生变化。另外Gemini是一个多模态模型,但是在这个论文中,只关注Gemini在语言理解、生成和翻译 能力上的表现，多模态能力还有待深入探索。\n",
    "\n",
    "\n",
    "\n",
    "| 性能维度     | Gemini Pro 表现                      | GPT 3.5 Turbo 表现                 | 备注                               |\n",
    "|--------------|-------------------------------------|------------------------------------|-----------------------------------|\n",
    "| 模型规模     | 与GPT 3.5 Turbo相当                  | -                                  | -                                 |\n",
    "| 任务表现     | 在某些任务上略逊一筹                 | 在多数任务上表现更优               | -                                 |\n",
    "| 短板         | - 回答顺序偏见<br>- 推理步骤较短<br>- 响应失败 | -                                  | <span style=\"color:orange\">内容过滤机制较严格</span> |\n",
    "| 长复杂推理任务 | 表现更佳                             | 较为一般                            | -                                 |\n",
    "| 多语种任务   | 出色的能力                           | 稍逊一筹                           | -                                 |\n",
    "| 更新可能性   | 结果可能随模型升级而变化             | 结果可能随模型升级而变化           | 截至2023年12月19日                |\n",
    "| 多模态能力   | 待深入探索                           | -                                  | 本论文未深入探索                  |\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bf5bae",
   "metadata": {},
   "source": [
    "## **七、结论**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5130fe2-df4b-4211-be1f-11bf688df9d2",
   "metadata": {},
   "source": [
    "**Gemini**具有优越的多模态推理能力，在大多数情况下，Gemini比GPT-4V更准确，并且表现出不同的回答风格和偏好。\n",
    "\n",
    "GPT-4V 和 Gemini 的对比：\n",
    "\n",
    "1. 差异：\n",
    "\n",
    "   - GPT-4V：在处理感知任务时，GPT-4V倾向于生成更详细的描述，并在认知任务中提供深入分析和逐步的中间推理。\n",
    "\n",
    "   - Gemini：相比之下，Gemini 更倾向于直接且简洁地回应问题，帮助用户迅速定位相关信息。在图像中的视觉元素更多时，GPT-4V在细致的感知优势变得更加明显，能更准确地识别视觉细节。然而，GPT-4V可能因隐私顾虑而拒绝回答与名人相关的话题或者在某些超出范围的问题上预测自己的限制而不作尝试。在一些特定的视觉和专家级任务中，Gemini通常表现出更广泛的知识学习和泛化能力，表明其在各种领域的适用性更好。\n",
    "\n",
    "2. 共同问题：\n",
    "\n",
    "   - 空间感知能力：在确定物体的相对位置方面，两个模型都不够熟练。\n",
    "\n",
    "   - OCR和抽象视觉理解：两者在解读图表中的数字和字符时可能会出错，对某些几何形状和抽象归纳能力的理解也有困难。\n",
    "\n",
    "   - 逻辑自洽性：在处理一些科学问题或是“是或否”类型的问题时，它们偶尔会提供与最终答案不一致或相反的中间推理步骤。\n",
    "\n",
    "   - 对提示设计的鲁棒性：不同的问题提示方式可能会导致 GPT-4V 和 Gemini 产生相反的答案，影响输出稳定性，并阻碍它们的进一步应用。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cc0fbd-86b9-4fdc-b8f0-b6b0b1238775",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>展望：</b>总的来说，这两个模型在许多情况下仍然存在挑战，显示出通用多模态大型语言模型发展的长远道路。\n",
    "Gemini目前只发布了pro版本，让我们一起期待能与GPT 4一较高下的Gemini Ultra版本发布吧。\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 大模型的API及Plugins调用\n",
    "\n",
    "- 一、大语言模型性能评估与比较*\n",
    "    - 主流模型性能比较\n",
    "    - 重要领域能力对比\n",
    "    - 信息抽取任务在各个模型上的比较\n",
    "- 二、使用Python调用各类大语言模型的API***\n",
    "    - 百度文心一言\n",
    "    - 星火大语言模型\n",
    "    - OpenAI\n",
    "    - 使用OneApi统一调用\n",
    "    - 使用硅基流动API调用大语言模型\n",
    "- 三、Prompt 工程初探**\n",
    "    - 简单prompt设计\n",
    "    - 组件式prompt设计\n",
    "- 四、大模型额外能力调用***\n",
    "    - 函数调用\n",
    "    - Assistant API\n",
    "\n",
    "本节课将介绍如何使用Python调用各类大语言模型的API，以及大模型人工智能中的提示工程。首先，我们将学习如何使用Python调用各类大语言模型的API，包括百度文心一言、星火大语言模型以及OpenAI的多个版本。我们还将学习如何使用OneApi统一调用这些API，以简化开发流程并提高效率。\n",
    "\n",
    "接下来，我们将探讨提示工程的基本原理和技巧。我们将介绍Prompt的概念，并讨论如何设计和构建有效的提示。我们还将探讨提示工程的应用场景，包括文本生成、问题回答等领域。通过一些实际的应用案例，我们将展示提示工程在实际项目中的应用。\n",
    "\n",
    "最后，我们将探讨插件和函数调用的概念。我们将介绍插件的原理和使用方法，并讨论插件的应用场景和案例。\n",
    "\n",
    "通过本节课的学习，您将了解到如何使用Python调用各类大语言模型的API，掌握提示工程的基本原理和技巧，并了解插件和函数调用的概念及其应用。这些知识和技能将帮助您更好地应用大模型人工智能，提升项目的效果和效率。\n",
    "\n",
    "对于**学习AI产品经理**的同学，你们将了解到不同大语言模型的性能特点和优势，以及如何根据业务需求选择合适的模型。通过学习Prompt工程和大模型额外能力的调用，你们将能够更好地规划和设计AI产品，提升产品的用户体验和竞争力。\n",
    "\n",
    "在开启本项课程之前，你需要掌握以下知识：\n",
    "\n",
    "1. 了解简单的 Python 语法\n",
    "2. 能够看懂简单的英文\n",
    "3. 拥有大语言模型的使用途径，包括但不限于 OpenAI，各类 OpenAI 代理网站的账号，星火大语言模型的账号，百度文心一言的账号等，我们的教学平台也提供了教材必要的交互代理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## 一、大型语言模型性能评估与比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: sparkdesk-api in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (1.5.0)\n",
      "Requirement already satisfied: websocket-client in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (1.7.0)\n",
      "Collecting websocket-client (from -r requirements.txt (line 2))\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/34/db/b10e48aa8fff7407e67470363eac595018441cf32d5e1001567a7aeba5d2/websocket_client-1.9.0-py3-none-any.whl (82 kB)\n",
      "Requirement already satisfied: openai in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (2.3.0)\n",
      "Collecting openai (from -r requirements.txt (line 3))\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/25/66/22cfe4b695b5fd042931b32c67d685e867bfd169ebf46036b95b57314c33/openai-2.7.2-py3-none-any.whl (1.0 MB)\n",
      "Requirement already satisfied: markdown-it-py in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (3.0.0)\n",
      "Collecting markdown-it-py (from -r requirements.txt (line 4))\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/94/54/e7d793b573f298e1c9013b8c4dade17d481164aa517d1d7148619c2cedbf/markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Requirement already satisfied: faiss-cpu in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (1.7.4)\n",
      "Collecting faiss-cpu (from -r requirements.txt (line 5))\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/f4/0f/02d5d2ae8b53e5629cb03fbd871bbbfbbd647ffc3d09393b34f6347072d7/faiss_cpu-1.12.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.4 MB)\n",
      "Requirement already satisfied: langchain in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (0.3.13)\n",
      "Collecting langchain (from -r requirements.txt (line 6))\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/e1/4f/2603973fb3b74c717335703851a45914bc9794fbfaeb4ff74f7f08ecf5e8/langchain-1.0.5-py3-none-any.whl (93 kB)\n",
      "Requirement already satisfied: pymupdf in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (1.23.25)\n",
      "Collecting pymupdf (from -r requirements.txt (line 7))\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/ec/d7/a6f0e03a117fa2ad79c4b898203bb212b17804f92558a6a339298faca7bb/pymupdf-1.26.6.tar.gz (84.3 MB)\n",
      "  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mPreparing metadata \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[95 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m setup.py:218:<module>(): ### Starting.\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>(): os.getcwd()='/tmp/pip-install-gqfz_ldt/pymupdf_180fa2e8eacd48b0b4f92744fa13649b'\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>(): platform.machine()='x86_64'\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>(): platform.platform()='Linux-4.15.0-213-generic-x86_64-with-glibc2.27'\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>(): platform.python_implementation()='CPython'\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>(): platform.python_version()='3.10.12'\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>(): platform.system()='Linux'\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>(): platform.uname()=uname_result(system='Linux', node='VM-0-7-ubuntu', release='4.15.0-213-generic', version='#224-Ubuntu SMP Mon Jun 19 13:30:12 UTC 2023', machine='x86_64')\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>(): sys.executable='/home/ubuntu/anaconda3/envs/notebook@6.5.4/bin/python'\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>(): sys.version='3.10.12 (main, Jul  5 2023, 18:54:27) [GCC 11.2.0]'\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>(): sys.version_info=sys.version_info(major=3, minor=10, micro=12, releaselevel='final', serial=0)\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>(): list(sys.version_info)=[3, 10, 12, 'final', 0]\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>(): CPU bits: 64\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>(): sys.argv (3):\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>():     0: '/home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py'\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>():     1: 'prepare_metadata_for_build_wheel'\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>():     2: '/tmp/tmpg9w4y07t'\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>(): os.environ (48):\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>():     CLICOLOR: '1'\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>():     CLICOLOR_FORCE: '1'\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>():     CONDA_DEFAULT_ENV: 'notebook@6.5.4'\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>():     CONDA_EXE: '/home/ubuntu/anaconda3/bin/conda'\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>():     CONDA_PREFIX: '/home/ubuntu/anaconda3/envs/notebook@6.5.4'\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>():     CONDA_PREFIX_1: '/home/ubuntu/anaconda3'\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>():     CONDA_PROMPT_MODIFIER: '(notebook@6.5.4) '\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>():     CONDA_PYTHON_EXE: '/home/ubuntu/anaconda3/bin/python'\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>():     CONDA_SHLVL: '2'\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>():     DBUS_SESSION_BUS_ADDRESS: 'unix:path=/run/user/500/bus'\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>():     FORCE_COLOR: '1'\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>():     GIT_PAGER: 'cat'\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>():     HISTSIZE: '3000'\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>():     HISTTIMEFORMAT: '%F %T '\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>():     HOME: '/home/ubuntu'\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>():     JPY_PARENT_PID: '7481'\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>():     JPY_SESSION_NAME: '/home/ubuntu/data/student_A/A2/aigc_tm_level /A2 /A2.3大模型的API及Plugins调用/大模型的API及Plugins调用.ipynb'\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>():     LANG: 'en_US.utf8'\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>():     LESSCLOSE: '/usr/bin/lesspipe %s %s'\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>():     LESSOPEN: '| /usr/bin/lesspipe %s'\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>():     LOGNAME: 'ubuntu'\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>():     LS_COLORS: 'rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:'\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>():     MAIL: '/var/mail/ubuntu'\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>():     MPLBACKEND: 'module://matplotlib_inline.backend_inline'\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>():     OLDPWD: '/home/ubuntu/data'\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>():     PAGER: 'cat'\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>():     PATH: '/tmp/pip-build-env-vfwm5e7n/overlay/bin:/tmp/pip-build-env-vfwm5e7n/normal/bin:/home/ubuntu/anaconda3/envs/notebook@6.5.4/bin:/home/ubuntu/anaconda3/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin'\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>():     PEP517_BACKEND_PATH: '/tmp/pip-install-gqfz_ldt/pymupdf_180fa2e8eacd48b0b4f92744fa13649b'\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>():     PEP517_BUILD_BACKEND: 'setup'\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>():     PIP_BUILD_TRACKER: '/tmp/pip-build-tracker-14r6wato'\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>():     PROMPT_COMMAND: 'history -a; history -a; history -a; '\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>():     PWD: '/home/ubuntu/data/student_A/A2/aigc_tm_level /A2 /A2.3大模型的API及Plugins调用'\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>():     PYDEVD_USE_FRAME_EVAL: 'NO'\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>():     PYTHONNOUSERSITE: '1'\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>():     PYTHONPATH: '/tmp/pip-build-env-vfwm5e7n/site'\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>():     SHELL: '/bin/bash'\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>():     SHLVL: '2'\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>():     SSH_CLIENT: '39.144.45.251 32021 22'\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>():     SSH_CONNECTION: '39.144.45.251 32021 172.16.0.7 22'\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>():     SSH_TTY: '/dev/pts/0'\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>():     TERM: 'xterm-color'\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>():     USER: 'ubuntu'\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>():     XDG_DATA_DIRS: '/usr/local/share:/usr/share:/var/lib/snapd/desktop'\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>():     XDG_RUNTIME_DIR: '/run/user/500'\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>():     XDG_SESSION_ID: '2'\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>():     _: '/home/ubuntu/anaconda3/envs/notebook@6.5.4/bin/pip'\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>():     _CE_CONDA: ''\n",
      "  \u001b[31m   \u001b[0m setup.py:219:<module>():     _CE_M: ''\n",
      "  \u001b[31m   \u001b[0m setup.py:243:<module>(): PYMUPDF_SETUP_URL_WHEEL=None\n",
      "  \u001b[31m   \u001b[0m setup.py:246:<module>(): PYMUPDF_SETUP_DUMMY=None\n",
      "  \u001b[31m   \u001b[0m pipcl.py:906:tag_platform(): From self.tag_platform_: ret=None.\n",
      "  \u001b[31m   \u001b[0m pipcl.py:914:tag_platform(): From AUDITWHEEL_PLAT: ret=None.\n",
      "  \u001b[31m   \u001b[0m pipcl.py:929:tag_platform(): From sysconfig.get_platform(): ret='linux_x86_64'.\n",
      "  \u001b[31m   \u001b[0m pipcl.py:933:tag_platform(): tag_platform(): returning ret='linux_x86_64'.\n",
      "  \u001b[31m   \u001b[0m setup.py:453:get_mupdf_internal(): get_mupdf_internal(): out='dir' location=None\n",
      "  \u001b[31m   \u001b[0m setup.py:482:get_mupdf_internal(): Download location='https://mupdf.com/downloads/archive/mupdf-1.26.11-source.tar.gz' local_tgz='mupdf-1.26.11-source.tar.gz' name='mupdf-1.26.11-source'\n",
      "  \u001b[31m   \u001b[0m setup.py:492:get_mupdf_internal(): Downloading from location='https://mupdf.com/downloads/archive/mupdf-1.26.11-source.tar.gz' to local_tgz='mupdf-1.26.11-source.tar.gz'.\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 353, in <module>\n",
      "  \u001b[31m   \u001b[0m     main()\n",
      "  \u001b[31m   \u001b[0m   File \"/home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 335, in main\n",
      "  \u001b[31m   \u001b[0m     json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "  \u001b[31m   \u001b[0m   File \"/home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 152, in prepare_metadata_for_build_wheel\n",
      "  \u001b[31m   \u001b[0m     whl_basename = backend.build_wheel(metadata_directory, config_settings)\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-gqfz_ldt/pymupdf_180fa2e8eacd48b0b4f92744fa13649b/pipcl.py\", line 721, in build_wheel\n",
      "  \u001b[31m   \u001b[0m     items = self._call_fn_build(config_settings)\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-gqfz_ldt/pymupdf_180fa2e8eacd48b0b4f92744fa13649b/pipcl.py\", line 1007, in _call_fn_build\n",
      "  \u001b[31m   \u001b[0m     ret = self.fn_build()\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-gqfz_ldt/pymupdf_180fa2e8eacd48b0b4f92744fa13649b/setup.py\", line 589, in build\n",
      "  \u001b[31m   \u001b[0m     mupdf_local, mupdf_location = get_mupdf()\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-gqfz_ldt/pymupdf_180fa2e8eacd48b0b4f92744fa13649b/setup.py\", line 560, in get_mupdf\n",
      "  \u001b[31m   \u001b[0m     return get_mupdf_internal('dir', m)\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-gqfz_ldt/pymupdf_180fa2e8eacd48b0b4f92744fa13649b/setup.py\", line 493, in get_mupdf_internal\n",
      "  \u001b[31m   \u001b[0m     urllib.request.urlretrieve( location, local_tgz + '-')\n",
      "  \u001b[31m   \u001b[0m   File \"/home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/urllib/request.py\", line 280, in urlretrieve\n",
      "  \u001b[31m   \u001b[0m     raise ContentTooShortError(\n",
      "  \u001b[31m   \u001b[0m urllib.error.ContentTooShortError: <urlopen error retrieval incomplete: got only 41943040 out of 64537292 bytes>\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# 在开始课程之前，需要安装本节课需要的库\n",
    "!pip install -r requirements.txt -U -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **每次运行前，请安装上面依赖！**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 安装依赖说明\n",
    "- **sparkdesk-api**: SparkDesk API 是一个用于与 SparkDesk 平台进行交互的 Python 库。它允许开发者通过编程方式访问 SparkDesk 的功能，如数据查询、任务管理等。如果你需要与 SparkDesk 平台集成，这个库是必不可少的。\n",
    "\n",
    "- **websocket-client**: WebSocket 客户端库，用于在 Python 中实现 WebSocket 通信。WebSocket 是一种在单个 TCP 连接上进行全双工通信的协议，适用于实时应用程序，如聊天应用、实时数据更新等。\n",
    "\n",
    "- **openai**: OpenAI 官方提供的 Python 库，用于与 OpenAI 的 API 进行交互。通过这个库，你可以轻松访问 OpenAI 的强大模型，如 GPT-3、DALL-E 等，用于自然语言处理、图像生成等任务。\n",
    "\n",
    "- **markdown-it-py**: 这是一个 Python 实现的 Markdown 解析器，基于 JavaScript 的 `markdown-it`。它支持 CommonMark 规范，并且可以通过插件扩展功能。适用于需要将 Markdown 文本转换为 HTML 或其他格式的场景。\n",
    "\n",
    "- **faiss-cpu**: Faiss 是 Facebook AI 开发的一个高效的相似性搜索库，特别适用于大规模向量搜索。`faiss-cpu` 是 Faiss 的 CPU 版本，适合在没有 GPU 的环境中使用。常用于推荐系统、图像检索等领域。\n",
    "\n",
    "- **langchain**: LangChain 是一个用于构建基于语言模型的应用的框架。它提供了丰富的工具和接口，帮助开发者快速构建和部署基于自然语言处理的应用，如聊天机器人、文档生成器等。\n",
    "\n",
    "- **pymupdf**: PyMuPDF 是一个用于处理 PDF 文件的 Python 库。它提供了强大的功能，如文本提取、图像提取、PDF 生成和修改等。适用于需要处理和分析 PDF 文档的场景。\n",
    "\n",
    "- **numpy**: NumPy 是 Python 中用于科学计算的基础库，提供了高效的多维数组对象和丰富的数学函数。它是许多其他科学计算库的基础，广泛应用于数据分析、机器学习等领域。\n",
    "\n",
    "- **matplotlib**: Matplotlib 是一个用于绘制图表和数据可视化的 Python 库。它支持多种图表类型，如折线图、柱状图、散点图等，适用于数据分析和科学计算中的可视化需求。\n",
    "\n",
    "- **python-dotenv**: `python-dotenv` 是一个用于从 `.env` 文件中加载环境变量的 Python 库。它简化了环境变量的管理，使得在开发和生产环境中切换配置更加方便。\n",
    "\n",
    "- **tiktoken**: `tiktoken` 是 OpenAI 提供的一个用于计算文本 token 数量的 Python 库。它支持多种 OpenAI 模型，帮助开发者更好地理解和控制文本输入的长度和成本。\n",
    "\n",
    "- **langchain-community**: `langchain-community` 是 LangChain 生态系统中的一个扩展库，提供了社区贡献的额外工具和功能。它可以帮助开发者更灵活地使用 LangChain，扩展其功能和应用场景。\n",
    "\n",
    "建议国内安装包时加上 `-i https://pypi.tuna.tsinghua.edu.cn/simple` 命令，使用清华的 PyPI 镜像源，可以显著加快下载速度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 1.1 主流模型领域专业性比较\n",
    "\n",
    "**基座大模型与对话大模型**\n",
    "\n",
    "**基座大模型**：这类模型通常被设计为多用途的语言模型，能够处理包括文本生成、文本摘要、问答、语言翻译等在内的多种语言任务。它们的目标是理解和生成各种类型的自然语言文本。\n",
    "\n",
    "**对话大模型**：这些模型专门针对对话生成和理解进行优化。它们的主要目标是在保持上下文一致性的基础上，生成连贯、相关且自然的对话文本。\n",
    "\n",
    "下面是来自OpenCompass的大模型评测榜单，该榜单的性能指标综合了多项评测结果，包括MMLU，C-EVAL，CMMLU等。\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"./images/opencompass-LLM-diagram.png\" width = \"900\" alt=\"图片名称\" align=center />\n",
    "\n",
    "[C-Eval](https://arxiv.org/abs/2305.08322) 是由清华大学、上海交通大学和爱丁堡大学合作构建的面向中文语言模型的综合性考试评测集,包含13948道多项选择题,涵盖数学、物理、化学、生物、历史、政治、计算机等52个不同学科和四个难度级别，是全球最具影响力的综合性考试评测集之一。\n",
    "\n",
    "STEM: 科学、技术、工程和数学（Science, Technology, Engineering, and Mathematics）\n",
    "\n",
    "Social Science：社会科学\n",
    "\n",
    "Humanities：人文学科\n",
    "\n",
    "Other：其他\n",
    "\n",
    "Average：平均值\n",
    "\n",
    "| **#** | **Model**                                                    | **Creator**                                     | **Access**   | **Submission Date** | **Avg** | **Avg(Hard)** | **STEM** | **Social Science** | **Humanities** | **Others** |\n",
    "| ----- | ------------------------------------------------------------ | ----------------------------------------------- | ------------ | ------------------- | ------- | ------------- | -------- | ------------------ | -------------- | ---------- |\n",
    "| 0     | [Qwen-72B](https://cevalbenchmark.com/static/model.html?method=Qwen-72B) | Alibaba Cloud                                   | Weight       | 2023/11/30          | 82.8    | 64.7          | 77.1     | 91.7               | 84.7           | 82.9       |\n",
    "| 1     | [Yi-34B](https://cevalbenchmark.com/static/model.html?method=Yi-34B) | 零一万物                                        | Weight       | 2023/11/2           | 81.4    | 58.7          | 73.7     | 89.6               | 84.6           | 84.9       |\n",
    "| 2     | [TuringMM-34B-Chat](https://cevalbenchmark.com/static/model.html?method=TuringMM-34B-Chat) | 北京光年无限科技有限公司                        | Weight       | 2024/2/27           | 80.7    | 60.2          | 73.8     | 89.3               | 82.3           | 83.7       |\n",
    "| 3     | [Linly-Chinese-LLaMA2-70B](https://cevalbenchmark.com/static/model.html?method=Linly-Chinese-LLaMA2-70B) | 深圳大学大数据系统计算技术国家工程实验室 & APUS | Weight       | 2024/2/3            | 80.6    | 63            | 76       | 87.2               | 80             | 83.4       |\n",
    "| 4     | [PCI-TransGPT](https://cevalbenchmark.com/static/model.html?method=PCI-TransGPT) | 佳都科技                                        | API, Web     | 2024/1/4            | 80.4    | 62.5          | 75.4     | 89.2               | 81.7           | 80.3       |\n",
    "| 5     | [Taichu-70B](https://cevalbenchmark.com/static/model.html?method=Taichu-70B) | 紫东太初                                        | Weight       | 2024/1/12           | 80.1    | 59.8          | 73.8     | 89.5               | 82.9           | 80.4       |\n",
    "| 6     | [OrionStar-Yi-34B-Chat](https://cevalbenchmark.com/static/model.html?method=OrionStar-Yi-34B-Chat) | OrionStarAI                                     | Weight       | 2023/11/22          | 78.1    | 55.8          | 70.1     | 88                 | 80.7           | 80.9       |\n",
    "| 7     | [XuanYuan-13B](https://cevalbenchmark.com/static/model.html?method=XuanYuan-13B) | 度小满AI-Lab                                    | Weight       | 2024/2/2            | 76.8    | 59            | 71.3     | 86.5               | 80.1           | 74.9       |\n",
    "| 8     | [YAYI2-30B](https://cevalbenchmark.com/static/model.html?method=YAYI2-30B) | 中科闻歌                                        | Weight       | 2023/12/18          | 75.3    | 53.1          | 67.2     | 83.8               | 80.6           | 76.8       |\n",
    "| 9     | [XuanYuan-6B](https://cevalbenchmark.com/static/model.html?method=XuanYuan-6B) | 度小满AI-Lab                                    | Weight       | 2024/2/2            | 74.4    | 58            | 69.5     | 84.5               | 76.8           | 71.9       |\n",
    "| 10    | [xDAN-L2-Chat-lite-v1.0](https://cevalbenchmark.com/static/model.html?method=xDAN-L2-Chat-lite-v1.0) | xDAN-AI                                         | API, Private | 2023/12/17          | 74.3    | 50.7          | 66.5     | 84.8               | 78.1           | 75.3       |\n",
    "| 11    | [BlueLM-7B](https://cevalbenchmark.com/static/model.html?method=BlueLM-7B) | vivo                                            | Weight       | 2023/11/7           | 73.3    | 48.9          | 64.3     | 83.3               | 76.5           | 77.1       |\n",
    "| 12    | [XuanYuan2-70B](https://cevalbenchmark.com/static/model.html?method=XuanYuan2-70B) | 度小满AI-Lab                                    | Weight       | 2024/2/2            | 72.7    | 53.1          | 67.2     | 84.2               | 75.8           | 69         |\n",
    "| 13    | [XVERSE-65B-2](https://cevalbenchmark.com/static/model.html?method=XVERSE-65B-2) | XVERSE Technology                               | Weight       | 2023/12/8           | 72.4    | 50.8          | 65.7     | 85                 | 74             | 71.8       |\n",
    "| 14    | [Qwen-14B](https://cevalbenchmark.com/static/model.html?method=Qwen-14B) | Alibaba Cloud                                   | Weight       | 2023/9/22           | 72.1    | 53.7          | 65.7     | 85.4               | 75.3           | 68.4       |\n",
    "| 15    | [Yi-6B](https://cevalbenchmark.com/static/model.html?method=Yi-6B) | 零一万物                                        | Weight       | 2023/11/2           | 72      | 46.6          | 62.3     | 83.9               | 76.3           | 74.6       |\n",
    "| 16    | [XuanYuan-70B](https://cevalbenchmark.com/static/model.html?method=XuanYuan-70B) | 度小满AI-Lab                                    | Weight       | 2023/9/21           | 71.9    | 53.6          | 67.7     | 83.3               | 73.9           | 67.4       |\n",
    "| 17    | [ChatGLM3-6B-base](https://cevalbenchmark.com/static/model.html?method=ChatGLM3-6B-base) | Tsinghua & Zhipu.AI                             | Weight       | 2023/10/26          | 69      | 46.8          | 61       | 82.4               | 73.4           | 66.9       |\n",
    "| 18    | [GPT-4*](https://cevalbenchmark.com/static/model.html?method=GPT-4*) | OpenAI                                          | API, Web     | 2023/5/15           | 68.7    | 54.9          | 67.1     | 77.6               | 64.5           | 67.8       |\n",
    "| 19    | [XVERSE-65B](https://cevalbenchmark.com/static/model.html?method=XVERSE-65B) | XVERSE Technology                               | Weight       | 2023/11/5           | 68.6    | 46.2          | 61.3     | 81.4               | 71             | 67.8       |\n",
    "| 20    | [Aquila2-70B-Expr](https://cevalbenchmark.com/static/model.html?method=Aquila2-70B-Expr) | 北京智源人工智能研究院                          | Weight       | 2023/11/27          | 66.8    | 47.2          | 61.6     | 79.7               | 69.4           | 62         |\n",
    "| 21    | [Nanbeige-16B-Base](https://cevalbenchmark.com/static/model.html?method=Nanbeige-16B-Base) | Nanbeige LLM Lab                                | Weight       | 2023/11/8           | 63.8    | 43.5          | 57.8     | 77.2               | 66.9           | 59.4       |\n",
    "| 22    | [LingoWhale-8B](https://cevalbenchmark.com/static/model.html?method=LingoWhale-8B) | 深言科技(DeepLangAI)                            | Weight       | 2023/11/3           | 63.6    | 46.4          | 57       | 73.7               | 68.5           | 61.5       |\n",
    "| 23    | [Qwen-7B v1.1](https://cevalbenchmark.com/static/model.html?method=Qwen-7B v1.1) | Alibaba Cloud                                   | Weight       | 2023/9/12           | 63.5    | 46.4          | 57.7     | 78.1               | 66.6           | 57.8       |\n",
    "| 24    | [XVERSE-13B-2](https://cevalbenchmark.com/static/model.html?method=XVERSE-13B-2) | XVERSE Technology                               | Weight       | 2023/11/4           | 63.5    | 41.6          | 55.7     | 77.3               | 66             | 62.7       |  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 重要领域能力对比\n",
    "\n",
    "![综合能力](images/capability.png)\n",
    "\n",
    "![领域能力](images/domain-capability.png)\n",
    "\n",
    "从目前的各类benchmark来看，随着时间的推移，新出的大模型在语言能力，逻辑推理能力上都有了长足的进步，在部分早期模型无法实现的领域（例如工具调用，函数调用等），开源的大模型如今也有了对应的能力，不过和头部的大模型厂商OpenAI相比，在各类任务的zero-shot能力上差距较为明显，有待改进。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 信息抽取任务在各个模型上的比较\n",
    "\n",
    "Chinese Llama-2-13B-Chat\n",
    "\n",
    "![Chinese Llama-2-13B-Chat](images/chinese-llama2-13b-chat.png)\n",
    "\n",
    "gpt-3.5-turbo\n",
    "![gpt-3.5-turbo](images/gpt-3.5-turbo.png)\n",
    "\n",
    "百度文心一言\n",
    "![WenXin](images/baidu-wenxin.png)\n",
    "\n",
    "星火大模型\n",
    "![Spark](images/xunfei-spark.png)\n",
    "\n",
    "Llama2-70B-chat\n",
    "![Llama2-70B-chat](images/llama2-70b-chat.png)\n",
    "\n",
    "文本信息抽取任务对人类来说是一个比较简单的任务，而同一个问题输入不同的模型，得到的答案却各有不同，其中商用的三个大模型表现较为一致，都可以正确的找到答案，并且输出正确的格式，json对象的键也是对的，而中文Llama2模型虽然输出了正确的json格式，但是键的名称并不对应，同类的键也没有合并生成列表，虽然这些要求没有在输入中说明，但是这些细节对于人类来说应当算约定俗成的规则，至于英文的Llama2模型，没有输出正确的列表格式，虽然这只是一个表达的不同，但仍然不符合日常的书写习惯。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、使用Python调用各类大语言模型的API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 百度文心一言\n",
    "\n",
    "![baidu wenxin](images/baidu-flow-graph.png)\n",
    "\n",
    "百度的文心一言API优点在于提供了一种简单通用的方式来调用百度的大模型，鉴权、请求每一步都可以自己完成，可控性相对更高，缺点是不如直接调用官方的Python第三方库来的方便，而且需要自己完成鉴权、请求等步骤，相对来说比较繁琐，而且要配置的内容相比OpenAI等成熟的API来说更多。\n",
    "\n",
    "另一个优势是百度在千帆大平台上支持了很多开源模型，如果本地没有足够的算力直接运行开源模型，可以通过百度提供的接口进行调用。\n",
    "\n",
    "| 服务内容                                                     | 单价                                                    |\n",
    "| ------------------------------------------------------------ | ------------------------------------------------------- |\n",
    "| ERNIE-Bot 4.0大模型公有云在线调用服务(**输入**)              | 0.12元/千tokens (限时优惠，**~~原价0.15元~~/千tokens**) |\n",
    "| ERNIE-Bot 4.0大模型公有云在线调用服务(**输出**)              | 0.12元/千tokens (限时优惠，**~~原价0.3元~~/千tokens**)  |\n",
    "| ERNIE-Bot-8k大模型公有云在线调用服务(**输入**)               | 0.024元/千tokens                                        |\n",
    "| ERNIE-Bot-8k大模型公有云在线调用服务(**输出**)               | 0.048元/千tokens                                        |\n",
    "| ERNIE-Bot大模型公有云在线调用服务(**输入**)                  | 0.012元/千tokens                                        |\n",
    "| ERNIE-Bot大模型公有云在线调用服务(**输出**)                  | 0.012元/千tokens                                        |\n",
    "| ERNIE-Bot-turbo-0922大模型公有云在线调用服务(**输入**)       | 0.008元/千tokens                                        |\n",
    "| ERNIE-Bot-turbo-0922大模型公有云在线调用服务(**输出**)       | 0.008元/千tokens (限时优惠，**~~原价0.012~~/千tokens**) |\n",
    "| [ERNIE-Bot-turbo-AI原生应用](https://console.bce.baidu.com/ai_apaas/app) | 0.008元/千tokens                                        |\n",
    "\n",
    "[百度产品价格](https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Blfmc9dlf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                                  Version\n",
      "---------------------------------------- --------------------\n",
      "absl-py                                  2.0.0\n",
      "accelerate                               0.25.0\n",
      "aiofiles                                 23.2.1\n",
      "aiohttp                                  3.8.4\n",
      "aiosignal                                1.3.1\n",
      "alembic                                  1.15.2\n",
      "altair                                   5.2.0\n",
      "annotated-types                          0.6.0\n",
      "anthropic                                0.16.0\n",
      "anyio                                    3.7.1\n",
      "aot-x                                    1.5.3\n",
      "argon2-cffi                              23.1.0\n",
      "argon2-cffi-bindings                     21.2.0\n",
      "arrow                                    1.3.0\n",
      "asgiref                                  3.7.2\n",
      "asttokens                                2.4.1\n",
      "astunparse                               1.6.3\n",
      "async-lru                                2.0.4\n",
      "async-timeout                            4.0.2\n",
      "asyncio                                  3.4.3\n",
      "attrs                                    23.1.0\n",
      "Authlib                                  1.3.0\n",
      "autocorrect                              2.6.1\n",
      "Babel                                    2.14.0\n",
      "backoff                                  2.2.1\n",
      "bcrypt                                   4.1.2\n",
      "beautifulsoup4                           4.12.2\n",
      "bitsandbytes                             0.42.0\n",
      "black                                    23.3.0\n",
      "bleach                                   6.1.0\n",
      "blinker                                  1.7.0\n",
      "Brotli                                   1.0.9\n",
      "bs4                                      0.0.2\n",
      "build                                    1.0.3\n",
      "cached-property                          1.5.2\n",
      "cachetools                               5.3.2\n",
      "certifi                                  2023.5.7\n",
      "cffi                                     1.16.0\n",
      "chardet                                  4.0.0\n",
      "charset-normalizer                       3.1.0\n",
      "chroma-hnswlib                           0.7.3\n",
      "chromadb                                 0.4.14\n",
      "click                                    8.1.7\n",
      "cohere                                   4.24\n",
      "colorama                                 0.4.6\n",
      "coloredlogs                              15.0.1\n",
      "colorlog                                 6.9.0\n",
      "comm                                     0.1.4\n",
      "commentjson                              0.9.0\n",
      "contourpy                                1.2.0\n",
      "cryptography                             42.0.4\n",
      "cycler                                   0.10.0\n",
      "d2l                                      1.0.3\n",
      "dashscope                                1.23.2\n",
      "dataclasses-json                         0.6.3\n",
      "datasets                                 2.15.0\n",
      "debugpy                                  1.6.7\n",
      "decorator                                4.4.2\n",
      "defusedxml                               0.7.1\n",
      "Deprecated                               1.2.14\n",
      "diffusers                                0.26.3\n",
      "dill                                     0.3.7\n",
      "diskcache                                5.6.3\n",
      "distro                                   1.8.0\n",
      "dnspython                                2.4.2\n",
      "dspy-ai                                  2.4.10\n",
      "einops                                   0.7.0\n",
      "entrypoints                              0.4\n",
      "exceptiongroup                           1.2.0\n",
      "executing                                2.0.1\n",
      "faiss-cpu                                1.7.4\n",
      "faiss-gpu                                1.7.2\n",
      "fastapi                                  0.108.0\n",
      "fastavro                                 1.8.2\n",
      "fastjsonschema                           2.19.0\n",
      "ffmpy                                    0.3.2\n",
      "filelock                                 3.13.1\n",
      "FLAML                                    2.1.1\n",
      "Flask                                    3.0.0\n",
      "flatbuffers                              23.5.26\n",
      "fonttools                                4.47.0\n",
      "fqdn                                     1.5.1\n",
      "frozenlist                               1.3.3\n",
      "fsspec                                   2023.10.0\n",
      "gast                                     0.5.4\n",
      "gevent                                   23.9.1\n",
      "gitdb                                    4.0.12\n",
      "GitPython                                3.1.44\n",
      "google-ai-generativelanguage             0.4.0\n",
      "google-api-core                          2.17.1\n",
      "google-auth                              2.25.2\n",
      "google-auth-oauthlib                     1.2.0\n",
      "google-generativeai                      0.3.1\n",
      "google-pasta                             0.2.0\n",
      "googleapis-common-protos                 1.62.0\n",
      "gradio                                   4.19.2\n",
      "gradio_client                            0.10.1\n",
      "graph_of_thoughts                        0.0.2\n",
      "greenlet                                 3.0.2\n",
      "grpcio                                   1.60.1\n",
      "grpcio-status                            1.60.1\n",
      "grpcio-tools                             1.60.1\n",
      "h11                                      0.14.0\n",
      "h2                                       4.1.0\n",
      "h5py                                     3.10.0\n",
      "hpack                                    4.0.0\n",
      "html2text                                2020.1.16\n",
      "httpcore                                 0.17.3\n",
      "httptools                                0.6.1\n",
      "httpx                                    0.24.1\n",
      "httpx-sse                                0.4.0\n",
      "huggingface-hub                          0.20.3\n",
      "humanfriendly                            10.0\n",
      "hyperframe                               6.0.1\n",
      "idna                                     3.4\n",
      "imageio                                  2.33.1\n",
      "imageio-ffmpeg                           0.4.9\n",
      "importlib-metadata                       6.11.0\n",
      "importlib-resources                      6.1.1\n",
      "ipykernel                                6.26.0\n",
      "ipython                                  8.18.1\n",
      "ipython-genutils                         0.2.0\n",
      "ipywidgets                               8.1.1\n",
      "isodate                                  0.6.1\n",
      "isoduration                              20.11.0\n",
      "itsdangerous                             2.1.2\n",
      "jedi                                     0.19.1\n",
      "jieba                                    0.42.1\n",
      "Jinja2                                   3.1.2\n",
      "jiter                                    0.11.0\n",
      "joblib                                   1.3.2\n",
      "json5                                    0.9.14\n",
      "jsonlines                                4.0.0\n",
      "jsonpatch                                1.33\n",
      "jsonpointer                              2.4\n",
      "jsonschema                               4.20.0\n",
      "jsonschema-path                          0.3.2\n",
      "jsonschema-spec                          0.2.4\n",
      "jsonschema-specifications                2023.7.1\n",
      "jupyslides                               0.194\n",
      "jupyter                                  1.0.0\n",
      "jupyter_client                           8.6.0\n",
      "jupyter-console                          6.6.3\n",
      "jupyter_core                             5.5.1\n",
      "jupyter-events                           0.9.0\n",
      "jupyter-lsp                              2.2.1\n",
      "jupyter_server                           2.12.1\n",
      "jupyter_server_terminals                 0.5.0\n",
      "jupyterlab                               4.0.9\n",
      "jupyterlab_pygments                      0.3.0\n",
      "jupyterlab_server                        2.25.2\n",
      "jupyterlab-widgets                       3.0.9\n",
      "keras                                    2.15.0\n",
      "kiwisolver                               1.4.5\n",
      "kubernetes                               28.1.0\n",
      "langchain                                0.3.13\n",
      "langchain-community                      0.3.13\n",
      "langchain-core                           0.3.58\n",
      "langchain-experimental                   0.0.10\n",
      "langchain-openai                         0.3.16\n",
      "langchain-text-splitters                 0.3.8\n",
      "langchainhub                             0.1.21\n",
      "langgraph                                0.2.62\n",
      "langgraph-checkpoint                     2.0.25\n",
      "langgraph-sdk                            0.1.66\n",
      "langsmith                                0.2.11\n",
      "lark-parser                              0.7.8\n",
      "lazy_loader                              0.3\n",
      "lazy-object-proxy                        1.10.0\n",
      "libclang                                 16.0.6\n",
      "llvmlite                                 0.44.0\n",
      "load-dotenv                              0.1.0\n",
      "lxml                                     5.1.0\n",
      "Mako                                     1.3.10\n",
      "Markdown                                 3.5.1\n",
      "markdown-it-py                           3.0.0\n",
      "MarkupSafe                               2.1.1\n",
      "marshmallow                              3.20.1\n",
      "matplotlib                               3.8.3\n",
      "matplotlib-inline                        0.1.6\n",
      "mdurl                                    0.1.2\n",
      "mistune                                  3.0.2\n",
      "ml-dtypes                                0.2.0\n",
      "mmh3                                     4.0.1\n",
      "monotonic                                1.6\n",
      "more-itertools                           10.1.0\n",
      "motor                                    3.3.2\n",
      "moviepy                                  2.2.0\n",
      "mpmath                                   1.3.0\n",
      "multidict                                6.0.4\n",
      "multiprocess                             0.70.15\n",
      "mypy-extensions                          1.0.0\n",
      "natsort                                  8.4.0\n",
      "nbclassic                                1.0.0\n",
      "nbclient                                 0.8.0\n",
      "nbconvert                                7.13.0\n",
      "nbformat                                 5.9.2\n",
      "nest-asyncio                             1.5.8\n",
      "networkx                                 3.2.1\n",
      "nltk                                     3.8.1\n",
      "notebook                                 6.5.4\n",
      "notebook_shim                            0.2.3\n",
      "numba                                    0.61.2\n",
      "numpy                                    1.24.3\n",
      "nvidia-cublas-cu12                       12.1.3.1\n",
      "nvidia-cuda-cupti-cu12                   12.1.105\n",
      "nvidia-cuda-nvrtc-cu12                   12.1.105\n",
      "nvidia-cuda-runtime-cu12                 12.1.105\n",
      "nvidia-cudnn-cu12                        8.9.2.26\n",
      "nvidia-cufft-cu12                        11.0.2.54\n",
      "nvidia-curand-cu12                       10.3.2.106\n",
      "nvidia-cusolver-cu12                     11.4.5.107\n",
      "nvidia-cusparse-cu12                     12.1.0.106\n",
      "nvidia-nccl-cu12                         2.18.1\n",
      "nvidia-nvjitlink-cu12                    12.3.101\n",
      "nvidia-nvtx-cu12                         12.1.105\n",
      "oauthlib                                 3.2.2\n",
      "onnxruntime                              1.16.3\n",
      "openai                                   2.3.0\n",
      "openai-whisper                           20250625\n",
      "openapi-core                             0.18.2\n",
      "openapi-schema-validator                 0.6.2\n",
      "openapi-spec-validator                   0.7.1\n",
      "opencv-python                            4.9.0.80\n",
      "opencv-python-headless                   4.8.1.78\n",
      "opentelemetry-api                        1.22.0\n",
      "opentelemetry-exporter-otlp-proto-common 1.22.0\n",
      "opentelemetry-exporter-otlp-proto-grpc   1.22.0\n",
      "opentelemetry-instrumentation            0.43b0\n",
      "opentelemetry-instrumentation-asgi       0.43b0\n",
      "opentelemetry-instrumentation-fastapi    0.43b0\n",
      "opentelemetry-proto                      1.22.0\n",
      "opentelemetry-sdk                        1.22.0\n",
      "opentelemetry-semantic-conventions       0.43b0\n",
      "opentelemetry-util-http                  0.43b0\n",
      "opt-einsum                               3.3.0\n",
      "optimum                                  1.15.0\n",
      "optuna                                   4.3.0\n",
      "orjson                                   3.10.18\n",
      "ormsgpack                                1.9.1\n",
      "overrides                                7.4.0\n",
      "packaging                                23.2\n",
      "pandas                                   2.0.3\n",
      "pandocfilters                            1.5.0\n",
      "paper-qa                                 3.13.0\n",
      "parse                                    1.20.0\n",
      "parso                                    0.8.3\n",
      "pathable                                 0.4.3\n",
      "pathspec                                 0.12.1\n",
      "peft                                     0.8.2\n",
      "pexpect                                  4.8.0\n",
      "pgvector                                 0.2.5\n",
      "pickleshare                              0.7.5\n",
      "pillow                                   11.3.0\n",
      "pinecone-client                          3.0.3\n",
      "pip                                      23.3.1\n",
      "pkgutil_resolve_name                     1.3.10\n",
      "platformdirs                             4.1.0\n",
      "portalocker                              2.8.2\n",
      "posthog                                  3.1.0\n",
      "prance                                   23.6.21.0\n",
      "proglog                                  0.1.10\n",
      "prometheus-client                        0.19.0\n",
      "prompt-toolkit                           3.0.42\n",
      "promptbench                              0.0.2\n",
      "proto-plus                               1.23.0\n",
      "protobuf                                 4.23.4\n",
      "psutil                                   5.9.0\n",
      "ptyprocess                               0.7.0\n",
      "pulsar-client                            3.4.0\n",
      "pure-eval                                0.2.2\n",
      "py-cpuinfo                               9.0.0\n",
      "pyarrow                                  14.0.2\n",
      "pyarrow-hotfix                           0.6\n",
      "pyasn1                                   0.5.1\n",
      "pyasn1-modules                           0.3.0\n",
      "pyautogen                                0.2.4\n",
      "pycparser                                2.21\n",
      "pycryptodome                             3.20.0\n",
      "pydantic                                 2.11.6\n",
      "pydantic_core                            2.33.2\n",
      "pydantic-settings                        2.9.1\n",
      "pydub                                    0.25.1\n",
      "pygame                                   2.6.1\n",
      "Pygments                                 2.17.2\n",
      "pymongo                                  4.6.1\n",
      "PyMuPDF                                  1.23.25\n",
      "PyMuPDFb                                 1.23.22\n",
      "PyNLPIR                                  0.6.0\n",
      "pypandoc                                 1.12\n",
      "pyparsing                                2.4.7\n",
      "pypdf                                    3.17.4\n",
      "PyPDF2                                   3.0.1\n",
      "PyPika                                   0.48.9\n",
      "pyproject_hooks                          1.0.0\n",
      "PySocks                                  1.7.1\n",
      "python-dateutil                          2.8.2\n",
      "python-dotenv                            1.0.0\n",
      "python-json-logger                       2.0.7\n",
      "python-multipart                         0.0.9\n",
      "python-pptx                              0.6.23\n",
      "pytz                                     2023.3.post1\n",
      "PyYAML                                   6.0.1\n",
      "pyzmq                                    25.1.0\n",
      "qdrant-client                            1.7.3\n",
      "qtconsole                                5.5.1\n",
      "QtPy                                     2.4.1\n",
      "ratelimit                                2.2.1\n",
      "referencing                              0.30.2\n",
      "regex                                    2023.10.3\n",
      "requests                                 2.31.0\n",
      "requests-oauthlib                        1.3.1\n",
      "requests-toolbelt                        1.0.0\n",
      "rfc3339-validator                        0.1.4\n",
      "rfc3986-validator                        0.1.1\n",
      "rich                                     13.5.2\n",
      "rise                                     5.7.1\n",
      "roboflow                                 1.1.4\n",
      "rpds-py                                  0.10.6\n",
      "rsa                                      4.9\n",
      "ruamel.yaml                              0.18.5\n",
      "ruamel.yaml.clib                         0.2.8\n",
      "ruff                                     0.2.2\n",
      "safetensors                              0.4.1\n",
      "scikit-image                             0.22.0\n",
      "scikit-learn                             1.3.2\n",
      "scipy                                    1.10.1\n",
      "seaborn                                  0.13.2\n",
      "semantic-kernel                          0.3.15.dev0\n",
      "semantic-version                         2.10.0\n",
      "Send2Trash                               1.8.2\n",
      "sentence-transformers                    2.3.1\n",
      "sentencepiece                            0.1.99\n",
      "services                                 0.1.1\n",
      "setuptools                               80.0.0\n",
      "shellingham                              1.5.4\n",
      "six                                      1.16.0\n",
      "smmap                                    5.0.2\n",
      "sniffio                                  1.3.0\n",
      "soundfile                                0.12.1\n",
      "soupsieve                                2.5\n",
      "sparkdesk-api                            1.5.0\n",
      "SQLAlchemy                               2.0.23\n",
      "stack-data                               0.6.2\n",
      "starlette                                0.32.0.post1\n",
      "structlog                                25.3.0\n",
      "supervision                              0.18.0\n",
      "swarms                                   4.1.6\n",
      "sympy                                    1.12\n",
      "tavily-python                            0.7.2\n",
      "tenacity                                 8.2.2\n",
      "tensorboard                              2.15.1\n",
      "tensorboard-data-server                  0.7.2\n",
      "tensorflow                               2.15.0.post1\n",
      "tensorflow-estimator                     2.15.0\n",
      "tensorflow-io-gcs-filesystem             0.35.0\n",
      "termcolor                                2.2.0\n",
      "terminado                                0.18.0\n",
      "thop                                     0.1.1.post2209072238\n",
      "threadpoolctl                            3.2.0\n",
      "tifffile                                 2024.2.12\n",
      "tiktoken                                 0.8.0\n",
      "timm                                     0.9.16\n",
      "tinycss2                                 1.2.1\n",
      "tokenizers                               0.15.0\n",
      "toml                                     0.10.2\n",
      "tomli                                    2.0.1\n",
      "tomlkit                                  0.12.0\n",
      "toolz                                    0.12.1\n",
      "torch                                    2.1.1\n",
      "torchaudio                               2.1.2+cpu\n",
      "torchvision                              0.16.1\n",
      "tornado                                  6.3.3\n",
      "tqdm                                     4.66.1\n",
      "traitlets                                5.14.0\n",
      "transformers                             4.35.2\n",
      "tree-of-thoughts-llm                     0.1.0\n",
      "triton                                   2.1.0\n",
      "typer                                    0.9.0\n",
      "types-python-dateutil                    2.8.19.14\n",
      "types-requests                           2.32.0.20250328\n",
      "typing_extensions                        4.13.2\n",
      "typing-inspect                           0.9.0\n",
      "typing-inspection                        0.4.0\n",
      "typing-utils                             0.1.0\n",
      "tzdata                                   2023.3\n",
      "ujson                                    5.10.0\n",
      "ultralytics                              8.3.120\n",
      "ultralytics-thop                         2.0.14\n",
      "uri-template                             1.3.0\n",
      "urllib3                                  2.0.2\n",
      "uvicorn                                  0.25.0\n",
      "uvloop                                   0.19.0\n",
      "validators                               0.22.0\n",
      "watchfiles                               0.21.0\n",
      "wcwidth                                  0.2.12\n",
      "weaviate-client                          3.25.3\n",
      "webcolors                                1.13\n",
      "webencodings                             0.5.1\n",
      "websocket-client                         1.7.0\n",
      "websockets                               11.0.3\n",
      "Werkzeug                                 3.0.1\n",
      "wget                                     3.2\n",
      "wheel                                    0.41.2\n",
      "widgetsnbextension                       4.0.9\n",
      "wrapt                                    1.14.1\n",
      "XlsxWriter                               3.1.9\n",
      "xxhash                                   3.4.1\n",
      "yarl                                     1.9.2\n",
      "zipp                                     3.17.0\n",
      "zope.event                               5.0\n",
      "zope.interface                           6.1\n",
      "Looking in indexes: http://mirrors.tencentyun.com/pypi/simple\n",
      "Requirement already satisfied: sparkdesk-api in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (1.5.0)\n",
      "Requirement already satisfied: websocket-client in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (1.7.0)\n",
      "Requirement already satisfied: openai in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (2.3.0)\n",
      "Requirement already satisfied: markdown-it-py in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (3.0.0)\n",
      "Requirement already satisfied: faiss-cpu in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (1.7.4)\n",
      "Requirement already satisfied: langchain in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (0.3.13)\n",
      "Requirement already satisfied: pymupdf in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (1.23.25)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (1.24.3)\n",
      "Requirement already satisfied: matplotlib in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (3.8.3)\n",
      "Requirement already satisfied: python-dotenv in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (1.0.0)\n",
      "Requirement already satisfied: tiktoken in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (0.8.0)\n",
      "Requirement already satisfied: langchain-community in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (0.3.13)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from openai->-r requirements.txt (line 3)) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from openai->-r requirements.txt (line 3)) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from openai->-r requirements.txt (line 3)) (0.24.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from openai->-r requirements.txt (line 3)) (0.11.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from openai->-r requirements.txt (line 3)) (2.11.6)\n",
      "Requirement already satisfied: sniffio in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from openai->-r requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from openai->-r requirements.txt (line 3)) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from openai->-r requirements.txt (line 3)) (4.13.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from markdown-it-py->-r requirements.txt (line 4)) (0.1.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 6)) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 6)) (2.0.23)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 6)) (3.8.4)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 6)) (4.0.2)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.26 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 6)) (0.3.58)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 6)) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.17 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 6)) (0.2.11)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 6)) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 6)) (8.2.2)\n",
      "Requirement already satisfied: PyMuPDFb==1.23.22 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from pymupdf->-r requirements.txt (line 7)) (1.23.22)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 9)) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 9)) (0.10.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 9)) (4.47.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 9)) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 9)) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 9)) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 9)) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 9)) (2.8.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from tiktoken->-r requirements.txt (line 11)) (2023.10.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from langchain-community->-r requirements.txt (line 12)) (0.6.3)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from langchain-community->-r requirements.txt (line 12)) (0.4.0)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from langchain-community->-r requirements.txt (line 12)) (2.9.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 6)) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 6)) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 6)) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 6)) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 6)) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 6)) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 3)) (3.4)\n",
      "Requirement already satisfied: exceptiongroup in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 3)) (1.2.0)\n",
      "Requirement already satisfied: six in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from cycler>=0.10->matplotlib->-r requirements.txt (line 9)) (1.16.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->-r requirements.txt (line 12)) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->-r requirements.txt (line 12)) (0.9.0)\n",
      "Requirement already satisfied: certifi in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 3)) (2023.5.7)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 3)) (0.17.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.26->langchain->-r requirements.txt (line 6)) (1.33)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from langsmith<0.3,>=0.1.17->langchain->-r requirements.txt (line 6)) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from langsmith<0.3,>=0.1.17->langchain->-r requirements.txt (line 6)) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 3)) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 3)) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 3)) (0.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from requests<3,>=2->langchain->-r requirements.txt (line 6)) (2.0.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain->-r requirements.txt (line 6)) (3.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from httpcore<0.18.0,>=0.15.0->httpx<1,>=0.23.0->openai->-r requirements.txt (line 3)) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.26->langchain->-r requirements.txt (line 6)) (2.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->-r requirements.txt (line 12)) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip list\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping websocket as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y websocket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入 lru_cache 装饰器，用于缓存函数的返回值，避免重复计算\n",
    "from functools import lru_cache\n",
    "\n",
    "# 定义一个基础的模型类 BaseLLM\n",
    "class BaseLLM:\n",
    "    # 使用 lru_cache 装饰器，设置缓存大小为 1024，缓存函数 chat 的返回值\n",
    "    @lru_cache(maxsize=1024)\n",
    "    def chat(self, text):\n",
    "        # 调用内部函数 _chat 处理传入的文本\n",
    "        return self._chat(text)\n",
    "    \n",
    "    # 定义一个内部函数 _chat，用于处理文本，需要在子类中实现具体逻辑\n",
    "    def _chat(self, text):\n",
    "        # 抛出 NotImplementedError 异常，提示子类需要实现该方法\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 缓存是一种用来提高响应速度，降低成本的常用方法\n",
    "> 最简单的缓存实现就是将输入和输出进行记录，当第二次出现相同的输入时，将不执行函数本体，而是直接返回输出，以节省执行函数本体的成本\n",
    "> lru cache与最简单的缓存的区别是，引入了一种高效的缓存管理方案，因为最简单的方案随着函数执行次数的增加，输入输出对会累积的非常多，导致存储成本上升，因此lru cache引入了缓存的上限和缓存达到上限之后的替换机制，以确保存储成本的上界可以接受，并尽可能满足后续的缓存命中率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的模块\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# 定义 ErnieLLM 类，继承自 BaseLLM\n",
    "class ErnieLLM(BaseLLM):\n",
    "    \"\"\"\n",
    "    百度文心一言 ERNIE-Bot 参考文档：https://cloud.baidu.com/doc/WENXINWORKSHOP/s/clntwmv7t\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.key = self.key = os.getenv(\"BAIDU_WENXIN_HEADER_KEY\")\n",
    "        self.url = \"https://qianfan.baidubce.com/v2/chat/completions\"\n",
    "\n",
    "    def _chat(self, text, messages=[]):\n",
    "        \"\"\"\n",
    "        使用 ERNIE 生成回复\n",
    "        \"\"\"\n",
    "\n",
    "        headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "        # 构建请求体 payload，包括用户消息\n",
    "        if not messages:\n",
    "            # 如果没有历史消息，则将用户输入作为第一条消息\n",
    "            messages = [{\"role\": \"user\", \"content\": text}]\n",
    "\n",
    "        payload = json.dumps ({\n",
    "            \"model\":\"ernie-3.5-8k\",\n",
    "            \"messages\": messages\n",
    "        })\n",
    "        headers ={\n",
    "            'Content-Type':'application/json',\n",
    "            'Authorization':self.key\n",
    "        }\n",
    "\n",
    "        # 发送 POST 请求给 ERNIE，并获取回复结果\n",
    "        response = requests.request(\"POST\", self.url, headers=headers, data=payload)\n",
    "\n",
    "        # 返回 ERNIE 生成的回复结果\n",
    "        return response.json().get(\"choices\")[0].get(\"message\").get(\"content\")\n",
    "\n",
    "# ernie = ErnieLLM()\n",
    "# print(ernie.chat(\"你好\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 星火大语言模型\n",
    "\n",
    "讯飞星火大模型官方提供的调用方案是使用 websocket 进行流式传输，为了保证课程的流畅性和模型调用的一致性，我们使用开源社区第三方封装的星火大模型 API 进行调用。\n",
    "\n",
    "在执行一下命令前，你需要先安装一下依赖包："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.tencentyun.com/pypi/simple\n",
      "Requirement already satisfied: sparkdesk-api==1.5.0 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (1.5.0)\n",
      "Looking in indexes: http://mirrors.tencentyun.com/pypi/simple\n",
      "Requirement already satisfied: websocket-client in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (1.7.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sparkdesk-api==1.5.0\n",
    "!pip install websocket-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的模块\n",
    "from sparkdesk_api.core import SparkAPI\n",
    "\n",
    "# 定义 SparkLLM 类，继承自 BaseLLM\n",
    "class SparkLLM(BaseLLM):\n",
    "    def __init__(self):\n",
    "        # 初始化 SparkAPI 实例，传入环境变量中的 app_id、api_secret、api_key，并指定版本为 2.1\n",
    "        self.llm = SparkAPI(\n",
    "            app_id=os.getenv(\"SPARKDESK_APP_ID\"),\n",
    "            api_secret=os.getenv(\"SPARKDESK_API_SECRET\"),\n",
    "            api_key=os.getenv(\"SPARKDESK_API_KEY\"),\n",
    "            version=3.1\n",
    "        )\n",
    "\n",
    "    def _chat(self, text):\n",
    "        # 调用 SparkAPI 实例的 chat 方法进行对话处理\n",
    "        response = self.llm.chat(text)\n",
    "        # 返回处理后的回复\n",
    "        return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 OpenAI 的大语言模型\n",
    "\n",
    "OpenAI 的大语言模型也就是我们常说的 ChatGPT，而在接口调用中，不同版本的模型有不同的代称：\n",
    "- `gpt-3.5-turbo`: 最常用的版本，相对 gpt-4 而言价格更加优惠，响应速度也更快，缺点是逻辑能力稍差，上下文窗口仅有 4096，这在某些场景下可能会不够用。\n",
    "- `gpt-4`: 逻辑能力更强，上下文窗口更大，但是价格更贵，响应速度也更慢。\n",
    "- `gpt-3.5-0613`: 某个时间节点的模型快照，能力基本与 gpt-3.5-turbo 相当，实验中为了保证结果的一致性，可以选择该类带有时间节点的模型。\n",
    "\n",
    "使用OpenAI的官方Python SDK可以方便我们接入许多不同的框架，OpenAI作为目前最流行的大模型供应商，其SDK内包含的许多功能值得我们探究。\n",
    "\n",
    "而在 Python 中调用 OpenAI 的大语言模型，我们需要使用 OpenAI 官方提供的 Python SDK，安装方式如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.tencentyun.com/pypi/simple\n",
      "Requirement already satisfied: openai in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (2.3.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from openai) (0.24.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from openai) (0.11.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from openai) (2.11.6)\n",
      "Requirement already satisfied: sniffio in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from openai) (4.13.2)\n",
      "Requirement already satisfied: idna>=2.8 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: exceptiongroup in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2023.5.7)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (0.17.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from httpcore<0.18.0,>=0.15.0->httpx<1,>=0.23.0->openai) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的模块\n",
    "from openai import OpenAI\n",
    "\n",
    "# 定义 OpenAILLM 类，继承自 BaseLLM\n",
    "class OpenAILLM(BaseLLM):\n",
    "    def __init__(self):\n",
    "        # 初始化 OpenAI 实例，传入环境变量中的 api_key 和 base_url\n",
    "        self.client = OpenAI(\n",
    "            api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "            base_url=os.getenv(\"OPENAI_API_BASE\")\n",
    "        )\n",
    "        \n",
    "    # def chat(self, text, messages=[], stops=None):\n",
    "    #     # 调用 _chat 方法处理对话\n",
    "    #     return self._chat(text, messages, stops)\n",
    "        \n",
    "    def chat(self, text, messages=[], stops=None):\n",
    "        if not messages:\n",
    "            # 如果没有历史消息，则将用户输入作为第一条消息\n",
    "            messages = [{\"role\": \"user\", \"content\": text}]\n",
    "        \n",
    "        # 使用固定的 engine 发送对话请求，并获取回复结果\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo-0125\",\n",
    "            messages=messages,\n",
    "            stream=False,\n",
    "            stop=stops,\n",
    "        )\n",
    "        \n",
    "        # 返回回复内容\n",
    "        return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 使用 OneApi 统一调用各类大语言模型的 API\n",
    "\n",
    "[OneApi](https://github.com/songquanpeng/one-api) 是一套兼容 OpenAI 接口规范的大模型端口管理与分发系统，支持 Azure、Anthropic Claude、Google PaLM 2、智谱 ChatGLM、百度文心一言、讯飞星火认知、阿里通义千问、360 智脑以及腾讯混元，我们可以一次配置，在多处使用。\n",
    "\n",
    "![Alt text](images/one-api.png)\n",
    "\n",
    "如上图所示，我们可以把多个不同的大模型平台都接入到 OneApi 中，然后通过 OneApi 统一调用这些大模型的 API，对于某些具有多种调用途径的大模型，例如各种代理的OpenAI接口，在oneapi中配置相同的模型名称可以进行负载均衡调用，从而提高效率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# 导入必要的模块\n",
    "import openai\n",
    "\n",
    "# 定义 OneApiLLM 类，继承自 BaseLLM\n",
    "class OneApiLLM():\n",
    "    def __init__(self):\n",
    "        # 设置 openai 的 api_key 和 api_base\n",
    "        openai.api_key = os.getenv(\"ONEAPI_API_KEY\")\n",
    "        openai.api_base = os.getenv(\"ONEAPI_API_BASE\")\n",
    "\n",
    "    def _chat(self, text, stops=None):\n",
    "        # 发送对话请求并获取回复结果\n",
    "        response = openai.ChatCompletion.create(\n",
    "            # 指定使用的模型为 chatglm3-6b\n",
    "            model=\"chatglm3-6b\",\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": text},\n",
    "            ],\n",
    "            stream=False,\n",
    "            stops=stops\n",
    "        )\n",
    "        # 返回回复内容\n",
    "        return response.choices[0].message.content\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 使用 硅基流动API 调用大语言模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[siliconflow](https://cloud.siliconflow.cn) 硅基流动主要提供模型云服务平台 SiliconCloud、大语言模型推理引擎 SiliconLLM、高性能文生图/视频加速库 OneDiff 等产品，让企业和个人用户高效、低成本地部署 AI 模型。想要体验全量的DeepSeek-R1和DeepSeek-V3等模型，我们可以使用SiliconCloud的API进行调用，非常方便。\n",
    "\n",
    "首先进入硅基流动的官网进行注册和登录，页面如下：\n",
    "![Alt text](images/1.jpg)\n",
    "\n",
    "注册登录后，我们能看到首页的模型广场，这里面有硅基流动平台支持的各种大模型，以及对应的参数和价格说明。\n",
    "![Alt text](images/2.jpg)\n",
    "\n",
    "点击页面左侧的“API 密钥”选项：\n",
    "<div align=\"center\">\n",
    "<img src=\"./images/3.jpg\" width=\"200\" alt=\"3\">\n",
    "</div>\n",
    "\n",
    "随后点击“新建 API 密钥”，在弹出的窗口中填写密钥描述。这里可以自己随便命名。\n",
    "<div align=\"center\">\n",
    "<img src=\"./images/4.jpg\" width=\"900\" alt=\"4\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "新建后，我们将得到的密钥复制，就可以用于大模型的调用了！\n",
    "<div align=\"center\">\n",
    "<img src=\"./images/api.jpg\" width=\"900\" alt=\"api\">\n",
    "</div>\n",
    "\n",
    "仅仅有密钥还不能使用大模型，我们还需要客户端对API进行调用。Chatbox AI 是一款 AI 客户端应用和智能助手，支持众多先进的 AI 模型和 API，可在 Windows、MacOS、Android、iOS、Linux 和网页版上使用。我们首先打开Chatbox AI的官网：\n",
    "<div align=\"center\">\n",
    "<img src=\"./images/5.jpg\" width=\"900\" alt=\"5\">\n",
    "</div>\n",
    "\n",
    "这里我们选择网页版即可。需要的话也可以下载客户端版本或者手机版本。进入聊天界面后，选择下面的选项，使用自己本人的API：\n",
    "<div align=\"center\">\n",
    "<img src=\"./images/6.jpg\" width=\"900\" alt=\"6\">\n",
    "</div>\n",
    "\n",
    "这里有多种API可以选择，我们选择之前复制好的硅基流动的API，即siliconflow API。\n",
    "<div align=\"center\">\n",
    "<img src=\"./images/7.jpg\" width=\"400\" alt=\"7\">\n",
    "</div>\n",
    "\n",
    "复制API后，选择我们想要调用的模型：\n",
    "<div align=\"center\">\n",
    "<img src=\"./images/8.jpg\" width=\"700\" alt=\"8\">\n",
    "</div>\n",
    "\n",
    "这样就可以使用大模型了！非常方便。注意，硅基流动的API免费额度是有限制的，如果需要深度使用，可以结合官网收费选项进行购买。\n",
    "<div align=\"center\">\n",
    "<img src=\"./images/money.jpg\" width=\"900\" alt=\"money.jpg\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、Prompt 工程与人工智能应用\n",
    "\n",
    "prompt 工程也称为提示工程，是指在大模型人工智能中，通过给定的提示文本，来引导模型生成特定的文本。在本节课中，我们将介绍 prompt 工程的基本原理和技巧，并探讨 prompt 工程的应用场景和案例。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提示工程不仅仅是关于设计和研发提示词。它包含了与大语言模型交互和研发的各种技能和技术。提示工程在实现和大语言模型交互、对接，以及理解大语言模型能力方面都起着重要作用。用户可以通过提示工程来提高大语言模型的安全性，也可以赋能大语言模型，比如借助专业领域知识和外部工具来增强大语言模型能力。\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "提问：为什么需要各种各样的提示工程？\n",
    "</div>\n",
    "\n",
    "为什么需要各种各样的提示工程？这是因为大语言模型的能力是有限的，模型不可能凭空创造知识，不论是真实事件还是虚拟幻觉，模型的输出都是依赖于提供给模型的文本以及训练模型时固化在模型参数中的**知识**，它只能在有限的上下文中生成文本。如果我们想要让大语言模型生成特定的文本，就需要给它提供一些提示。提示工程就是为了提供这些提示而存在的。\n",
    "\n",
    "下面给出一些简单的例子，来介绍提示工程的一些最基本的用法："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 为了保证输出的美观性，请先安装 markdown-it 库，该库的作用是把模型输出的 markdown 格式的文本转换为 HTML 格式的文本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.tencentyun.com/pypi/simple\n",
      "Requirement already satisfied: markdown-it-py in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ubuntu/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages (from markdown-it-py) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install markdown-it-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Prompt 简要设计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的模块\n",
    "from markdown_it import MarkdownIt\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# 创建 MarkdownIt 实例，配置为支持换行和 HTML 标签，并启用表格功能\n",
    "md = MarkdownIt('commonmark', {'breaks': True, 'html': True}).enable('table')\n",
    "\n",
    "def markdown_to_html(markdown_source):\n",
    "    \"\"\"\n",
    "    将 Markdown 转换为 HTML 并显示\n",
    "    \"\"\"\n",
    "    # 将输入的 Markdown 转换为 HTML\n",
    "    html = md.render(markdown_source)\n",
    "    # 在输出中显示转换后的 HTML\n",
    "    display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ernie_bot = ErnieLLM()\n",
    "spark_bot = SparkLLM()\n",
    "openai_bot = OpenAILLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error code  11200\n",
      "you can see this website to know code detail\n",
      "https://www.xfyun.cn/doc/spark/%E6%8E%A5%E5%8F%A3%E8%AF%B4%E6%98%8E.html\n"
     ]
    }
   ],
   "source": [
    "res = spark_bot.chat(\"你是一名专业的计算机老师，请告诉我如何学习python，回答时请将要点加粗表达出来\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'Your account is not active, please check your billing details on our website.', 'type': 'billing_not_active', 'param': None, 'code': 'billing_not_active'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mopenai_bot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m你是谁\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 23\u001b[0m, in \u001b[0;36mOpenAILLM.chat\u001b[0;34m(self, text, messages, stops)\u001b[0m\n\u001b[1;32m     20\u001b[0m     messages \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: text}]\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# 使用固定的 engine 发送对话请求，并获取回复结果\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-3.5-turbo-0125\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstops\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# 返回回复内容\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[0;32m~/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages/openai/_utils/_utils.py:286\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py:1156\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   1110\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m   1112\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m not_given,\n\u001b[1;32m   1154\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m   1155\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m-> 1156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1157\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1159\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1167\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1168\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1169\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1170\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1171\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1172\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1173\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1174\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt_cache_key\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1178\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1179\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msafety_identifier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1181\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1184\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1185\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1186\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1187\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1188\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1189\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mverbosity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweb_search_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages/openai/_base_client.py:1259\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1246\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1247\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1254\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1255\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1256\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1257\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1258\u001b[0m     )\n\u001b[0;32m-> 1259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/notebook@6.5.4/lib/python3.10/site-packages/openai/_base_client.py:1047\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1044\u001b[0m             err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1046\u001b[0m         log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1047\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not resolve response (should never happen)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'Your account is not active, please check your billing details on our website.', 'type': 'billing_not_active', 'param': None, 'code': 'billing_not_active'}}"
     ]
    }
   ],
   "source": [
    "openai_bot.chat(\"你是谁\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "markdown_to_html(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 续写\n",
    "# 天空真的\n",
    "# 鲁迅是一个\n",
    "\n",
    "# prompt_1 = \"天空真的\"\n",
    "prompt_1 = \"鲁迅是一个\"\n",
    "print(\"Ernie:\")\n",
    "markdown_to_html(ernie_bot.chat(prompt_1))\n",
    "print(\"Spark:\")\n",
    "markdown_to_html(spark_bot.chat(prompt_1))\n",
    "print(\"OpenAI:\")\n",
    "markdown_to_html(openai_bot.chat(prompt_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上面的例子可以看到，有些模型的输出是直接跟在“鲁迅是一个”后面的，而有的模型则不会完全跟随用户输入的提示词，这是因为不同的模型对于提示的理解不同，跟模型在训练和微调时使用的语料是密切相关的，为了保证输出的一致性，我们可以通过简单调整提示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 续写\n",
    "# 直接续写下面的句子，不要重复开头的句子\n",
    "# 鲁迅是一个\n",
    "\n",
    "prompt_1_1 = \"\"\"直接续写下面的句子，不要重复开头的句子\n",
    "鲁迅是一个\n",
    "\"\"\"\n",
    "display(HTML(\"<h3>Ernie:</h3>\"))\n",
    "markdown_to_html(ernie_bot.chat(prompt_1_1))\n",
    "display(HTML(\"<h3>Spark:</h3>\"))\n",
    "markdown_to_html(spark_bot.chat(prompt_1_1))\n",
    "display(HTML(\"<h3>OpenAI:</h3>\"))\n",
    "markdown_to_html(openai_bot.chat(prompt_1_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对话描述\n",
    "\n",
    "prompt_1_2 = \"\"\"\n",
    "鲁迅是一个什么样的人\n",
    "\"\"\"\n",
    "display(HTML(\"<h3>Ernie:</h3>\"))\n",
    "markdown_to_html(ernie_bot.chat(prompt_1_1))\n",
    "display(HTML(\"<h3>Spark:</h3>\"))\n",
    "markdown_to_html(spark_bot.chat(prompt_1_2))\n",
    "display(HTML(\"<h3>OpenAI:</h3>\"))\n",
    "markdown_to_html(openai_bot.chat(prompt_1_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 指令类型的prompt，一般是以陈述句的形式表达的，例如要求模型执行某项任务\n",
    "# 帮我写一个Python快速排序函数\n",
    "\n",
    "prompt_2 = \"\"\"\n",
    "帮我写一个Python快速排序函数，不要用递归的方式\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(\"<h3>Ernie:</h3>\"))\n",
    "markdown_to_html(ernie_bot.chat(prompt_2))\n",
    "display(HTML(\"<h3>Spark:</h3>\"))\n",
    "markdown_to_html(spark_bot.chat(prompt_2))\n",
    "display(HTML(\"<h3>OpenAI:</h3>\"))\n",
    "markdown_to_html(openai_bot.chat(prompt_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "快速排序的基本思想：通过一趟排序将待排记录分隔成独立的两部分，其中一部分记录的关键字均比另一部分的关键字小，则可分别对这两部分记录继续进行排序，以达到整个序列有序。\n",
    "\n",
    "快速排序使用分治法来把一个串（list）分为两个子串（sub-lists）。具体算法描述如下：\n",
    "\n",
    "1. 从数列中挑出一个元素，称为 “基准”（pivot）；\n",
    "2. 重新排序数列，所有元素比基准值小的摆放在基准前面，所有元素比基准值大的摆在基准的后面（相同的数可以到任一边）。在这个分区退出之后，该基准就处于数列的中间位置。这个称为分区（partition）操作；\n",
    "3. 递归地（recursive）把小于基准值元素的子数列和大于基准值元素的子数列排序。\n",
    "\n",
    "![quick sort](./images/quick-sort.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 问答类型的prompt，一般是以问句的形式表达的，例如问某个问题，这种 prompt 的优势是接近人类对话的形式，并且通常在大语言模型的训练数据中有很好的覆盖，因此这种 prompt 模板的效果会好于单纯的指令类型的 prompt （针对一些比较复杂的场景）\n",
    "# 问：Python快速排序函数的时间复杂度是多少？\n",
    "# 答：\n",
    "prompt_3 = \"\"\"\n",
    "问：Python快速排序函数的时间复杂度是多少？并一步一步解释为什么\n",
    "答：\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(\"<h3>Ernie:</h3>\"))\n",
    "markdown_to_html(ernie_bot.chat(prompt_3))\n",
    "display(HTML(\"<h3>Spark:</h3>\"))\n",
    "markdown_to_html(spark_bot.chat(prompt_3))\n",
    "display(HTML(\"<h3>OpenAI:</h3>\"))\n",
    "markdown_to_html(openai_bot.chat(prompt_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 3.2 组件式 Prompt 设计\n",
    " \n",
    " 那么，除了这些简单的用法之外，我们还可以使用什么样的技巧来设计更加有效的提示？在设计复杂的提示之前，我们要先了解提示的不同用途：\n",
    "\n",
    " - 基于对话的提示工程设计，这类提示工程的应用场景主要是聊天场景，例如闲聊机器人，语音助手或者客服机器人等，特点是任务无关的，可能的特点是人设模拟和对话风格设计，例如：闲聊机器人的人设模拟是一个 18 岁的女孩，对话风格是甜美可爱。\n",
    " - 基于任务的提示工程，这类提示工程的应用场景主要是 AI 原生应用，要求模型能够输出特定的文本，有特定的问答范围，例如实体抽取，文本分类，工具调用，这些任务的输出的阅读者很有可能不是人类，而是一些设计好的文本处理工具，例如 json 解析器，特定工具等"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt engineering 指的是设计和优化输入给人工智能（如语言模型）的提示（或称“prompt”）的过程，以期获得更精确、相关或有创意的输出。\n",
    "而基本的提示结构存在一些共性：\n",
    "\n",
    "1. 模型特征描述，人设定义，例如：你是一个计算机算法工程师，你是一个作家，你是一个医生等\n",
    "2. 任务描述，例如：你要抽取文本中的实体，你要对文本进行分类，你要生成一篇文章等\n",
    "3. 样例，例如：输入`<Input>` 输出 `<Output>` ，一般来说是输入输出对， 具体的，输入：今天天气真好，输出：positive\n",
    "4. 任务输入，希望模型处理的输入\n",
    "5. 输出格式描述，例如：输出是一个 json 格式的数据，输出是一个 markdown 格式的文本等，也可以更加细化，例如：输出是一个 json 格式的列表数据，列表中每个元素都是一个 json 格式的数据，每个数据都包含一个 title 和一个 content 字段，title 是一个字符串，content 是一个 markdown 格式的文本。这样的描述可以帮助模型更好的输出指定格式，便于后续处理程序的运行，优秀的模型可以良好的遵循格式描述信息。\n",
    "\n",
    "而设计过程可以分为一下几点：\n",
    "1. 目标定义：明确你希望从模型中获得什么样的信息或结果。这可能是一个问题的答案、创造性的文本、数据分析等。\n",
    "2. 语境设定：构建一个背景或语境，帮助模型理解你的问题或请求。这可能包括相关信息、背景知识、特定的指示或前提条件。\n",
    "3. 指令清晰度：确保你的指令清晰、具体，且直接相关于你的目标。避免歧义和过于复杂的表述。\n",
    "4. 反馈循环：根据模型的输出对你的提示进行调整。这可能意味着改变问题的表述方式，添加更多的细节，或者重新定位你的问题。\n",
    "5. 优化和迭代：通过重复测试和调整，优化你的提示以获得最佳结果。随着时间的推移，你可能需要根据新信息或模型更新来调整提示。\n",
    "在实践中，这意味着要多次尝试不同的提示方式，观察哪种方式产生最好的结果，然后据此调整你的方法。prompt engineering 是一个动态过程，随着模型的学习和环境的变化而不断进化。\n",
    "\n",
    "当然，不同任务的提示工程可能会有所不同，但是大体上都是遵循上面的结构，"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我们用一个渐进式的例子来逐步介绍提示工程的结构：\n",
    "\n",
    "首先，我们需要明确任务的目标，例如我们要用提示工程的方案让大模型将输入的一段文本中的命名实体抽取出来，第一次尝试我们使用最简单的提示词：\n",
    "\n",
    "> 命名实体识别任务的目标是将一段自然语言文本中需要的片段抽取出来，并分配正确的类别\n",
    "> 例如：“林丹是世界冠军”，这句话中，如果我们要抽取人名和荣誉两个类别命名实体，那么它的结果应该是{\"人名\": \"林丹\", \"荣誉\": \"世界冠军\"}\n",
    "\n",
    "<!-- > 该任务的灵感来源自[GPT-NER: Named Entity Recognition via Large Language Models](https://arxiv.org/abs/2304.10428)\n",
    "> \n",
    "> 样例来自[DuIE: A Large-scale Chinese Dataset for\n",
    "Information Extraction](http://tcci.ccf.org.cn/conference/2019/papers/EV10.pdf) -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_4_1 = \"\"\"请抽取出输入文本中的日期，人名，电影名，角色名\n",
    "文本内容：\n",
    "2月19日，96岁的资深演员侯焕玲离世，侯焕玲一生未嫁，但一直热爱电影，她曾在《回魂夜》和《喜剧之王》等电影饰演婆婆一角，而临终前侯焕玲一直说，自己好喜欢电影，好喜欢周星驰\n",
    "\"\"\"\n",
    "display(HTML(\"<h3>Spark:</h3>\"))\n",
    "markdown_to_html(spark_bot.chat(prompt_4_1))\n",
    "display(HTML(\"<h3>OpenAI:</h3>\"))\n",
    "markdown_to_html(openai_bot.chat(prompt_4_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上面的例子可以看到，我们的提示词是非常简单的，只是简单的描述了我们的任务目标，但是这样的提示词对于大模型来说是不够的，因为大模型不知道什么是日期，什么是人名，什么是电影名，什么是角色名，而且有些实体的类别从文本上看是重叠的，例如角色名和人名，从单独的文本片段来看，很难区分，必须通过上下文或者例子来区分，所以我们需要给模型提供更多的信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_4_2 = \"\"\"这是一个命名实体抽取的任务，你要把输入文本中的命名实体原文提取出来，命名实体类别包括：\n",
    "- 日期：一般是中文的日期表示，例如：3月5日，2021年3月5日，2021-3-5，2021/3/5,二月九日等\n",
    "- 人名：代表人的真名而不是剧本中的名字，例如：《来魂日》里的演员猴还艺\n",
    "- 电影名：电影剧集的名称，通常包含在书名号中，例如：来魂日\n",
    "- 角色名：电影剧集中的角色名称，通常和电影名在一起出现，例如：《来魂日》中的角色是公公\n",
    "文本内容：\n",
    "2月19日，96岁的资深演员侯焕玲离世，侯焕玲一生未嫁，但一直热爱电影，她曾在《回魂夜》和《喜剧之王》等电影饰演婆婆一角，而临终前侯焕玲一直说，自己好喜欢电影，好喜欢周星驰\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(\"<h3>Spark:</h3>\"))\n",
    "markdown_to_html(spark_bot.chat(prompt_4_2))\n",
    "display(HTML(\"<h3>OpenAI:</h3>\"))\n",
    "markdown_to_html(openai_bot.chat(prompt_4_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过观察上面的模型输出，我们可以看到，通过添加更多的提示词，模型的输出相比最简单的提示词已经有了一定的改变，但是模型并没有告诉我们选择这些文本作为实体的理由，假如我们希望模型能在输出结果的同时，一步一步的告诉我们为何选择（2月19日）作为实体类别（日期），我们可以通过添加一句简单的提示词来实现\n",
    "\n",
    "```python\n",
    "prompt = \"\"\"这是一个命名实体抽取的任务，你要把输入文本中的命名实体原文提取出来，并一步步输出选择的理由，命名实体类别包括：\n",
    "- 日期：一般是中文的日期表示，例如：3月5日，2021年3月5日，2021-3-5，2021/3/5等\n",
    "- 人名：代表人的真名而不是剧本中的名字，例如：《来魂日》里的猴还艺\n",
    "- 电影名：电影剧集的名称，通常包含在书名号中，例如：《来魂日》\n",
    "- 角色名：电影剧集中的角色名称，通常和电影名在一起出现，例如：《来魂日》里的公公\n",
    "\n",
    "2月19日，96岁的资深演员侯焕玲离世，候婆婆一生未嫁，但一直热爱电影，她曾在《回魂夜》和《喜剧之王》等电影饰演婆婆一角，而临终前候婆婆一直说，自己好喜欢电影，好喜欢周星驰\n",
    "\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_4_2 = \"\"\"这是一个命名实体抽取的任务，你要把输入文本中的命名实体原文提取出来，并一步步输出选择的理由，命名实体类别包括：\n",
    "- 日期：一般是中文的日期表示，例如：3月5日，2021年3月5日，2021-3-5，2021/3/5等\n",
    "- 人名：代表人的真名而不是剧本中的名字，例如：《来魂日》里的演员猴还艺\n",
    "- 电影名：电影剧集的名称，通常包含在书名号中，例如：来魂日\n",
    "- 角色名：电影剧集中的角色名称，通常和电影名在一起出现，例如：《来魂日》中的角色是公公\n",
    "文本内容：\n",
    "2月19日，96岁的资深演员侯焕玲离世，侯焕玲一生未嫁，但一直热爱电影，她曾在《回魂夜》和《喜剧之王》等电影饰演婆婆一角，而临终前侯焕玲一直说，自己好喜欢电影，好喜欢周星驰\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(\"<h3>Spark:</h3>\"))\n",
    "markdown_to_html(spark_bot.chat(prompt_4_2))\n",
    "display(HTML(\"<h3>OpenAI:</h3>\"))\n",
    "markdown_to_html(openai_bot.chat(prompt_4_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以很明显的看到，添加一句简单的“并一步步输出选择的理由”，模型就能给每个实体都输出其选择的理由，这在许多需要解释理由的场景是非常有用的，甚至能提升一定的任务性能。\n",
    "\n",
    "但是与此同时，我们注意到，模型输出的格式仍然更像人类的阅读习惯，而不是计算机程序更易读的可反序列化文本，并且这种格式并不足够稳定，解析起来费时费力，为了让大模型的输出可以更加高效的被后续处理工具解析，我们需要给模型提供更加明确的输出格式描述，例如：\n",
    "\n",
    "> 我们在这里去掉了一步步输出选择的理由这个提示词，因为接下来我们将要输出的是一个 json 对象，跟人类的真正思考过程相去甚远，如果要加上甚至有可能适得其反，所以我们在这里去掉了这个提示词。当然读者若是有兴趣，可以尝试加上这个提示词，看看模型的输出会有什么变化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_4_3 = \"\"\"这是一个命名实体抽取的任务，你要把输入文本中的命名实体原文提取出来，并使用 json 对象的格式输出，命名实体类别包括：\n",
    "- 日期：一般是中文的日期表示，例如：3月5日，2021年3月5日，2021-3-5，2021/3/5等\n",
    "- 人名：代表人的真名而不是剧本中的名字，例如：《来魂日》里的演员猴还艺\n",
    "- 电影名：电影剧集的名称，通常包含在书名号中，例如：来魂日\n",
    "- 角色名：电影剧集中的角色名称，通常和电影名在一起出现，例如：《来魂日》中的角色是公公\n",
    "文本内容：\n",
    "2月19日，96岁的资深演员侯焕玲离世，侯焕玲一生未嫁，但一直热爱电影，她曾在《回魂夜》和《喜剧之王》等电影饰演婆婆一角，而临终前侯焕玲一直说，自己好喜欢电影，好喜欢周星驰\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(\"<h3>Spark:</h3>\"))\n",
    "markdown_to_html(spark_bot.chat(prompt_4_3))\n",
    "display(HTML(\"<h3>OpenAI:</h3>\"))\n",
    "markdown_to_html(openai_bot.chat(prompt_4_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "很好，通过这个例子，我们了解了提示工程的基本结构，以及如何设计一个有效的提示工程，并将大模型的能力转换为我们需要的格式并切入到我们过去传统的工作流中，完成对传统小模型的替换。当然，这类领域专业性较强的信息抽取任务对于未经过垂直领域数据的大模型来说，零样本抽取能力对比过去领域有监督微调的小模型（Bert 等）还是稍显不足的，但是我们相信随着数据收集的越来越丰富，模型架构越来越先进，一次训练处处推理的大模型将会成为未来的主流。\n",
    "\n",
    "当然，上面介绍的这种提示工程设计方案并不是唯一的方案，不同的任务可能有不同的最佳实践，如果你的目标是将某一项任务优化到极致，那么你理所应当地要去钻研最佳提示词，但是如果你的目标是寻找一种广泛有效的提示词设计方案，那么你可以参考上面的提示词设计方案，并根据自己的任务特点进行调整，除此以外，你还可以借鉴下面的一些设计思路：\n",
    "\n",
    "[Effective Prompt: 编写高质量Prompt的14个有效方法](https://mp.weixin.qq.com/s/kqm8IRXRb7CW7DKbN-XqIw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型的提示词更像是在软调参，我们希望在茫茫无穷的语句中找出对大模型最有效的提示词，这个过程是非常耗时的，虽然我们可以借鉴其他人的经验，但是不同的场景下，提示词的使用范围并不相同，那么除了直接调整输入模型的提示词格式以外，我们是否还有更加高效的办法让模型尽可能输出我们想要的答案呢？\n",
    "\n",
    "答案是肯定的，那就是检索增强，也称 RAG。\n",
    "\n",
    "<!-- Meta AI的研究人员提出了一种名为检索增强生成（[Retrieval Augmented Generation](https://ai.meta.com/blog/retrieval-augmented-generation-streamlining-the-creation-of-intelligent-natural-language-processing-models/)，RAG）的方法，用于处理知识密集型任务。RAG将信息检索组件与文本生成模型结合在一起。RAG可以进行微调，并且修改其内部知识的方式非常高效，无需重新训练整个模型。\n",
    "\n",
    "RAG接收输入并检索出一组相关的文档，同时提供文档的来源（例如维基百科）。这些文档与输入的原始提示词结合在一起作为上下文，送入文本生成器生成最终的输出。这使得RAG能够更好地适应事实可能随时间变化的情况。这非常有用，因为语言模型的参数化知识是静态的。RAG使得语言模型能够获取最新的信息，而无需重新训练，并基于检索生成可靠的输出。\n",
    " -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 什么是检索增强 *Retrieval Augmented Generation*？\n",
    "\n",
    "在理解检索增强的实现原理之前，我们要认识到大语言模型在落地AI原生应用时还存在哪些局限性。跟人类相比，大语言模型拥有的知识范围在一次问答中是固定的，仅仅局限于大模型在训练时所接触到的训练语料以及对话时传入的上下文信息，而真实的人类在进行对话时可以借助各类工具做出实时性更高的问答对话，例如：在对话中提到了一个时间，人类可以通过搜索引擎或者钟表来获取实时的时间信息，而大模型则无法做到这一点，因为大模型的知识是固化在模型参数中的，无法实时更新，对于实时变化的信息有着天然的局限性\n",
    "\n",
    "<img src=\"./images/limitation.png\" width = \"600\" alt=\"图片名称\" align=center />\n",
    "\n",
    "\n",
    "除了实时信息，另一个重要局限就是模型训练数据的有限性与自然世界领域的无限性之间的矛盾，例如世界上的细分领域如牛毛般多，尽管大模型在训练时已经尽可能搜集多的训练数据，但是局限于人力的有限，不可能在所有的细节上都得到充分的训练，并且许多的领域信息是高度保密的，例如军工，企业内部知识库等等，这些领域的知识是无法通过公开的数据集来获取的，而这些领域的知识又是在真实场景落地的重要组成部分，所以我们需要一种方法来让大模型能够获取这些领域的知识，而不是仅仅局限于训练数据中的知识。\n",
    "\n",
    "综上，我们可以总结出大模型的两个重要局限性：\n",
    "\n",
    "1. 实时性局限性：大模型的知识是固化在模型参数中的，无法实时更新，对于实时变化的信息有着天然的局限性\n",
    "2. 领域性局限性：大模型的训练数据是有限的，无法覆盖所有的领域，对于未知领域的信息有着天然的局限性\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了解决这两个问题，我们需要一种方法来让大模型能够获取实时的信息，以及获取未知领域的信息，而这种方法就是检索增强，下面的图来自亚马逊AWS团队发布的一篇[博客](https://aws.amazon.com/cn/blogs/china/intelligent-search-based-enhancement-solutions-for-llm-part-three/)，基于智能搜索和大模型打造企业下一代知识库，我们可以借此一窥检索增强在实际应用中的作用。\n",
    "\n",
    "<img src=\"./images/aws-architecture.png\" width = \"600\" alt=\"图片名称\" align=center />\n",
    "\n",
    "在上面的架构图中，我们可以看到，检索增强的架构是由三部分组成的：\n",
    "\n",
    "1. 数据处理，该部分通过各类定制化的数据解析工具将各类文本、非文本数据转换为文本，并根据数据特征进行分块、向量化处理，得到易于检索、易于理解的数据片段。\n",
    "2. 数据存储，该部分将数据落入到企业内部的高效存储中，并结合过去业务积累的数据，形成一个企业级的知识库，该知识库可以通过各类传统的文本检索引擎进行匹配搜索，也可以使用向量化检索引擎进行相似度检索，除此以外还可以接入互联网搜索引擎，给模型的问答对话加入实时性的信息。\n",
    "3. 人机交互，该部分是为了针对问答中各类问题的特点，设计出合适的人机交互方案，例如：对于一些简单的问题，可以直接使用大模型进行回复，而对于一些复杂的问题，可以先检索企业知识库，然后根据预先设定的问答对话状态机，将传统QA流程与大模型的问答对话流程进行结合，从而提升问答的效率与准确率。\n",
    "\n",
    "前两部分是为了给大模型提供优质良好的检索信息，而第三部分则是为了让人类能够更好的与大模型进行交互，从而提升大模型的性能。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那么由此又引申出一个问题，我们该如何实现检索增强呢？该项技术的重点是如何检索，目前的检索方案有许多，例如关键字检索，模糊查询，向量化检索等等，而在这些方案中，如何兼顾检索的速度和检索内容与用户提问的相关性呢？\n",
    "\n",
    "首先，我们需要明确的是，在大语言模型的应用中，检索不应该作为一个显式的功能提供给用户，而应该作为隐藏在冰山之下的一种技术，用户不应当感受到检索过程的存在，而应当感受到的是检索增强后的大模型的能力，而这种无缝切入用户问答过程中的检索，天然的不适用于关键字检索等技术，因为很难从用户的自然对话文本中提取出用户意向的关键字，直接使用整段文本进行检索反而是更加的方案。\n",
    "\n",
    "所以我们需要一种检索方案，能够在保证检索速度的同时，尽可能的提升检索内容与用户提问的相关性，而这种方案就是向量化检索。\n",
    "\n",
    "向量化检索的核心思想是朴素且直观的：\n",
    "\n",
    "1. 将每个知识点进行向量化转换\n",
    "2. 将用户提问进行向量化转换\n",
    "3. 计算用户提问向量与每个知识点向量的相似度，选取最相似的 Top K 个知识点作为检索结果\n",
    "\n",
    "![vector search](images/vector-search.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "而相似度检索常用的方法有余弦相似度，欧拉距离，下面我们用matplotlib简单绘制一下多个向量之间的相似度比较。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt  # plt是matplotlib.pyplot的简称，是Python中用于创建图形和图表的非常强大的库，广泛用于数据分析和可视化。\n",
    "\n",
    "# 定义向量：使用np.array创建，例如vector1是一个二维数组，表示向量在x轴和y轴上的分量。\n",
    "vector1 = np.array([1, 2])  # 向量(1, 2)\n",
    "vector2 = np.array([3, 4])  # 向量(3, 4)\n",
    "vector3 = np.array([2, 1])  # 向量(2, 1)\n",
    "\n",
    "# 使用plt.quiver绘制向量：\n",
    "# plt.quiver(x, y, u, v, ...)函数绘制向量场，这里用于绘制单个向量。\n",
    "# 参数解释：\n",
    "# - x, y是起点坐标（通常为原点0,0）。\n",
    "# - u, v是向量在x轴和y轴上的分量。\n",
    "# - angles='xy'表示分量u和v是直接的坐标增量。\n",
    "# - scale_units='xy'和scale=1保持向量的长度与实际分量成比例。\n",
    "# - color='r', label='Vector 1'设置向量颜色和标签。\n",
    "plt.quiver(0, 0, vector1[0], vector1[1], angles='xy', scale_units='xy', scale=1, color='r', label='Vector 1')\n",
    "# 同上，绘制其他向量。\n",
    "plt.quiver(0, 0, vector2[0], vector2[1], angles='xy', scale_units='xy', scale=1, color='b', label='Vector 2')\n",
    "plt.quiver(0, 0, vector3[0], vector3[1], angles='xy', scale_units='xy', scale=1, color='g', label='Vector 3')\n",
    "\n",
    "# 设置坐标轴的限制，确保所有向量都能完全显示。\n",
    "plt.xlim(0, 5)  # x轴范围从0到5\n",
    "plt.ylim(0, 5)  # y轴范围从0到5\n",
    "\n",
    "# 添加坐标轴标签。\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "\n",
    "# 添加图例，解释每个颜色代表的向量。\n",
    "plt.legend()\n",
    "\n",
    "# 计算和标注向量间的夹角。使用向量点积公式：cos(θ) = A·B / (||A||*||B||)，\n",
    "# 其中θ是夹角，A·B是点积，||A||和||B||分别是向量A和B的模。\n",
    "# 计算得到余弦值之后，使用反余弦函数来得到他们的夹角\n",
    "angle12 = np.arccos(np.dot(vector1, vector2) / (np.linalg.norm(vector1) * np.linalg.norm(vector2)))\n",
    "# 使用plt.annotate和箭头属性来可视化夹角。\n",
    "plt.annotate(\"\", xy=(vector1[0], vector1[1]), xytext=(vector2[0], vector2[1]), arrowprops=dict(arrowstyle=\"->\", lw=1, color='black'))\n",
    "# 显示夹角的度数。\n",
    "plt.text(2.5, 2.5, f'Angle 1-2: {np.degrees(angle12):.2f} degrees', fontsize=12)\n",
    "\n",
    "# 绘制v1和v3之间的夹角\n",
    "angle13 = np.arccos(np.dot(vector1, vector3) / (np.linalg.norm(vector1) * np.linalg.norm(vector3)))\n",
    "plt.annotate(\"\", xy=(vector1[0], vector1[1]), xytext=(vector3[0], vector3[1]), arrowprops=dict(arrowstyle=\"->\", lw=1, color='black'))\n",
    "plt.text(1.5, 1.5, f'Angle 1-3: {np.degrees(angle13):.2f} degrees', fontsize=12)\n",
    "\n",
    "\n",
    "# 计算余弦相似度\n",
    "cosine_similarity12 = np.dot(vector1, vector2) / (np.linalg.norm(vector1) * np.linalg.norm(vector2))\n",
    "cosine_similarity13 = np.dot(vector1, vector3) / (np.linalg.norm(vector1) * np.linalg.norm(vector3))\n",
    "# 添加余弦相似度文本\n",
    "plt.text(0.5, 4.5, f'Cosine Similarity 1-2: {cosine_similarity12:.2f}', fontsize=12)\n",
    "plt.text(0.5, 4, f'Cosine Similarity 1-3: {cosine_similarity13:.2f}', fontsize=12)\n",
    "\n",
    "# 显示图形\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来我们将使用一个简单的向量数据库来实现检索增强，这在模型没有训练过的场景上非常有效。\n",
    "\n",
    "首先我们需要安装一些必要的依赖包："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以通过如下的流程来实现大语言模型的检索增强，让大语言模型快速上手未训练过的领域\n",
    "\n",
    "![Alt text](images/rag.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import faiss\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "hit_vd = faiss.IndexFlatL2(384) # 百度的嵌入模型词向量长度为384，这里参数与OpenAI的模型不相同\n",
    "\n",
    "knowledge_list = [\n",
    "    \"剑桥大学的校长是马冬梅，马教授是一名计算机专业的教授，她的主要研究方向是自然语言处理\",\n",
    "    \"牛津大学的软件学院院长是李磊，李教授是一名计算机专业的教授，他的主要研究方向是机器学习\",\n",
    "    \"hit 有五万名学生\",\n",
    "    \"wit 有三万名学生\",\n",
    "    \"huts 的医学院是中部地区最好的医学院，最擅长临床医学的研究\",\n",
    "]\n",
    "\n",
    "# 使用 百度 的模型生成对应的 embedding\n",
    "\n",
    "@lru_cache(maxsize=1024)\n",
    "def get_embedding(texts: tuple):\n",
    "    texts = list(texts)\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]\n",
    "    url = \"https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/embeddings/embedding-v1?access_token=\" + ernie_bot.ACCESS_TOKEN\n",
    "    payload = json.dumps({\n",
    "        \"input\": knowledge_list\n",
    "    })\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "\n",
    "    resp = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "    response = resp.json()\n",
    "    embs = [e[\"embedding\"] for e in response[\"data\"]]\n",
    "    # print(response.text)\n",
    "    return embs\n",
    "\n",
    "# 生成 embedding\n",
    "embs = get_embedding(tuple(knowledge_list))\n",
    "print(len(embs))\n",
    "# 将 embedding 添加到 faiss 索引中\n",
    "\n",
    "hit_vd.add(np.array(embs).astype(\"float32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"第一句话的词嵌入长度:\",len(embs[0]))\n",
    "print(\"第二句话的词嵌入长度:\",len(embs[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embs[0][:20])\n",
    "print(len(embs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "hit_vd = faiss.IndexFlatL2(1536)\n",
    "\n",
    "knowledge_list = [\n",
    "    \"剑桥大学的校长是马冬梅，马教授是一名计算机专业的教授，她的主要研究方向是自然语言处理\",\n",
    "    \"牛津大学的软件学院院长是李磊，李教授是一名计算机专业的教授，他的主要研究方向是机器学习\",\n",
    "    \"hit 有五万名学生\",\n",
    "    \"wit 有三万名学生\",\n",
    "    \"huts 的医学院是中部地区最好的医学院，最擅长临床医学的研究\",\n",
    "]\n",
    "\n",
    "# 使用 openai 的模型生成对应的 embedding\n",
    "\n",
    "@lru_cache(maxsize=1024)\n",
    "def get_embedding(texts: tuple, model=\"text-embedding-ada-002\"):\n",
    "    texts = list(texts)\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]\n",
    "    response = openai_bot.client.embeddings.create(\n",
    "        input=texts,\n",
    "        model=model,\n",
    "    )\n",
    "    # 使用指定的 model 对 texts 中的文本进行嵌入向量的生成。\n",
    "    #openai_bot.client.embeddings.create 函数接收两个参数：input（待处理的文本列表）和 model（用于生成嵌入向量的模型）。\n",
    "    embs = [e.embedding for e in response.data]\n",
    "    return embs\n",
    "\n",
    "# 生成 embedding\n",
    "embs = get_embedding(tuple(knowledge_list))\n",
    "# print(embs)\n",
    "# 将 embedding 添加到 faiss 索引中\n",
    "\n",
    "hit_vd.add(np.array(embs).astype(\"float32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"第一句话的词嵌入长度:\",len(embs[0]))\n",
    "print(\"第二句话的词嵌入长度:\",len(embs[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(embs[0][:20])\n",
    "print(len(embs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 提示文本\n",
    "prompt_5 = \"请告诉我牛津大学软件学院院长的研究方向是什么？\"\n",
    "\n",
    "# 获取查询向量\n",
    "query_vector = get_embedding(prompt_5)[0]\n",
    "\n",
    "# 使用 rag 检索增强方案搜索最相似的两个结果\n",
    "distances, indices = hit_vd.search(np.array([query_vector]).astype('float32'), 2)\n",
    "\n",
    "# 获取检索结果对应的知识列表\n",
    "research_result = [knowledge_list[i] for i in indices.tolist()[0]]\n",
    "\n",
    "# 将查询问题和检索到的答案转换为 HTML 并显示\n",
    "markdown_to_html(f\"查询的问题是：{prompt_5}\\n检索到的答案是：{research_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML(\"<h3>Spark without RAG:</h3>\"))\n",
    "markdown_to_html(spark_bot.chat(prompt_5))\n",
    "display(HTML(\"<h3>Spark with RAG:</h3>\"))\n",
    "markdown_to_html(spark_bot.chat(f\"从知识库中检索到了相关知识：：{research_result}\\n{prompt_5}\"))\n",
    "\n",
    "#display(HTML(\"<h3>OpenAI without RAG:</h3>\"))\n",
    "#markdown_to_html(openai_bot.chat(prompt_5))\n",
    "#display(HTML(\"<h3>OpenAI with RAG:</h3>\"))\n",
    "#markdown_to_html(openai_bot.chat(f\"从知识库中检索到了相关知识：：{research_result}\\n{prompt_5}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来让我们用一个更复杂的例子来感受检索增强的魅力。\n",
    "\n",
    "在ChatGPT刚刚推出的时候，一个名为chatpdf的应用横空出世，他的主要功能是针对任意pdf文档提供知识问答服务，帮助用户在一个陌生的超长文档中快速找到自己想要的信息，并帮助用户快速理解文档内容，这在阅读新领域的论文时格外有效，因为论文中的专业术语很多，而且很多时候我们并不知道这些术语的含义，我们的身边也不一定会恰好有这些领域的专业人士，使用这类pdf阅读应用可以提升我们了解一个新领域的效率。\n",
    "\n",
    "![ChatPDF](images/chatpdf.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来我们使用langchain来模拟实现chatpdf的核心功能：pdf文档阅读，在这个实验中，我们将使用时下流行的langchain工具包来调用我们的知识库，并使用pdf解析库来解析文档内容，最后使用大模型来完成问答对话。\n",
    "\n",
    "首先，我们需要安装实验必须的langchain依赖库："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain\n",
    "#!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "\n",
    "load_dotenv(\"../.env\")\n",
    "\n",
    "openai_api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "openai.proxy = { \"http\": openai_api_base}\n",
    "\n",
    "# openai_api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import PyMuPDFLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了尽可能避免使用那些可能已经被训练过的pdf文本，我们选用今年新推出的一篇论文作为我们的pdf阅读理解实验文本\n",
    "\n",
    "首先我们使用 pymupdf 库读取pdf文本，这个库的主要工作是解析pdf文档中的文本内容，因此要求文档必须有可解析的文字，而不是纯粹的图片内容，如果是图片内容，需要使用OCR工具进行解析处理，否则无法获取文本内容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyMuPDFLoader(\"./files/2311.05556.pdf\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后我们需要将读取到的pdf文档内容进行分片，因为模型每次能够处理的文本是有限的，不可能一次性处理整个文档，我们将文本划分成小块，并用向量化模型对每个小块生成对应的文本检索向量，这样我们就能用用户输入的文本来检索这些分片，从而兼顾检索的效率和模型的生成效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 CharacterTextSplitter 对文档进行拆分\n",
    "text_splitter = CharacterTextSplitter()\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "# 使用 FAISS.from_documents 方法构建索引\n",
    "docsearch = FAISS.from_documents(texts, OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化 OpenAI 模型\n",
    "lc_openai_model = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    base_url=os.getenv(\"OPENAI_API_BASE\")\n",
    ")\n",
    "\n",
    "# 查询文本\n",
    "query = \"Latent Consistency Models是什么？\"\n",
    "\n",
    "# 使用 docsearch 进行相似性搜索\n",
    "docs = docsearch.similarity_search(query)\n",
    "\n",
    "# 初始化相关内容字符串\n",
    "relvants = \"\"\n",
    "\n",
    "# 将检索到的文档内容连接起来\n",
    "for i in range(len(docs)):\n",
    "    relvants += docs[i].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "markdown_to_html(\"### 不使用pdf文档进行检索\")\n",
    "print(openai_bot.chat(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_to_html(\"### 使用pdf文档进行检索\")\n",
    "print(openai_bot.chat(relvants + \"\\n\" +query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上面的输出结果可以看到，在不使用检索增强的情况下，模型的输出效果并不理想，部分针对性的问题由于模型获取不到对应的知识，导致模型无法正确回复，甚至会出现幻觉问题，也就是不按照事实情况来回复用户的提问，这在许多追求真实性的场景中是非常致命的，例如：在医疗领域，模型回复的答案如果不是事实，可能会导致患者的误诊，这是非常严重的问题，好在我们使用检索增强的方案能够在一定程度上缓解这个问题，让模型有了落地的可能性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四、大模型外部能力调用\n",
    "\n",
    "受限于大模型训练的成本，模型训练使用的数据往往不是网络上最新的数据，例如 gpt-3.5-turbo 在刚推出时仅仅支持 2021年 9 月之前的数据，而在这个时间节点之后的数据模型并没有训练过，而为了弥补大模型在获取网络实时消息、调用各类不同工具的缺陷，OpenAI 推出了插件（Plugins）的功能，OpenAI ChatGPT 的插件每次可以勾选数个，每个都有可能被模型重复调用，如何调用，调用多少次都依赖于大语言模型自身的选择，下面是 OpenAI ChatGPT 插件的简要原理说明：\n",
    "\n",
    "1. 用户输入问题，触发会话开始。\n",
    "2. 根据用户当前安装并选中的插件，生成一个紧凑的插件描述，包括插件的描述、端点和示例。\n",
    "3. 判断紧凑的插件描述与用户问题的相关性。如果相关性较低，则将用户问题交给GPT模型完成completion。如果相关性较高，则将插件信息和用户问题一起交给GPT模型，并进入下一步。\n",
    "4. GPT模型选中相应的插件（例如wolfram）并抽取出槽位（例如输入为\"123*456\"）。\n",
    "5. 插件执行器负责调用具体的API，并传入相应的参数。\n",
    "6. 插件执行器执行插件操作，并将执行结果返回。\n",
    "7. 插件执行器将执行结果和上下文传递给GPT模型，GPT模型完成completion。\n",
    "8. GPT模型将生成的结果返回给用户。\n",
    "\n",
    "![Alt text](images/function-call.png)\n",
    "\n",
    "[OpenAI 插件开发](https://openai.xiniushu.com/docs/plugins/introduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在外部能力调用的过程中，模型主要使用了三个能力：\n",
    "\n",
    "1. 工具（外部能力）选取的能力，模型需要根据用户输入的问题，选取合适的工具来完成用户的需求，例如：用户输入的问题是“今天天气怎么样”，模型需要选取天气工具来完成用户的需求，而不是选取其他工具，例如：计算器工具。\n",
    "2. 参数抽取的能力，模型需要根据用户输入的问题，抽取出工具需要的参数，例如：用户输入的问题是“今天天气怎么样”，模型需要抽取出“今天”作为天气工具的参数，而不是抽取出“天气”作为天气工具的参数。\n",
    "3. 多轮对话的能力，因为真实的场景下，用户的需求往往是复杂的，多次调用不同的工具是非常常见的情况，模型必须能够在多轮对话中保持上下文的一致性，从而完成复杂的任务。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "而倘若让我们用纯粹的提示工程语句来实现外部能力的调用，我们需要设计一套可以有效的提示工程语句，让模型不仅可以选取用户提供的工具，还可以流畅的观察工具的完成情况，为此我们采用ReAct的提示工程设计思路来实现外部工具调用的能力，下面是一个简单的例子：\n",
    "\n",
    "```text\n",
    "你可以调用下面列出的函数来辅助完成用户提出的问题，函数的描述如下\n",
    "- div_func(a: float, b: float)：除法函数\n",
    "- mul_func(a: float, b: float)：乘法函数\n",
    "- chat_func(text: str)：聊天函数\n",
    "\n",
    "动作: <你要调用的函数名称>\n",
    "函数输入: <输入函数的值，必须符合函数的输入参数要求，如果有多个值每个值之间用逗号分隔>\n",
    "观察: <函数的输出结果>\n",
    "思考: <你对接下来的思考>\n",
    "```\n",
    "\n",
    "同样的，我们首先描述了任务情况，明确指出要让模型调用工具函数来辅助完成用户的请求，然后给出可以调用的函数列表，函数名称、输入参数等于真实的函数表示一直，鉴于目前的大模型在各类代码数据集上应该已经训练的非常充分了，因此只需要明确的写出函数的参数类型，模型就足够理解函数的输入要求。\n",
    "\n",
    "完成任务定义与函数描述之后，就是任务循环组件，该部分由四个块组成，动作、函数输入、观察以及思考，每个块都很简单明确，不过我们要注意大模型的截断条件，因为在观察之后的文本是由外部函数生成的，如果不在此处截断，模型就会开始生成事实无关的幻觉文本，导致调用失败。另一个要注意的是我们加入了思考块，让模型可以输出自己的思考过程，由于整个调用过程是循环记录的过程，因此当前时间段的思考也会被后续的生成过程观察到，因此模型可以在思考的基础上继续生成，从而完成更加复杂的任务。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了更加直观地了解插件的内核，我们用上面学到的提示工程相关知识，设计一个简单的插件机制，让大模型可以调用我们设计好的插件，从而更加高效的完成任务\n",
    "> [REACT: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS](https://arxiv.org/abs/2210.03629)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ReAct](images/ReAct.png)\n",
    "\n",
    "我们借鉴了ReAct的设计思路，设计了一个简单的插件机制，让大模型可以调用我们设计好的插件，从而更加高效的完成任务，下面是一个简单的流程示意图\n",
    "\n",
    "![func call flow](images/func-call-flow.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "# 定义 QwenLLM 类，继承自 BaseLLM， 其接口与gpt系列基本相同\n",
    "class QwenLLM(BaseLLM):\n",
    "    def __init__(self):\n",
    "        # 初始化 QwenLLM 实例，传入环境变量中的 api_key 和 base_url\n",
    "        self.client = OpenAI(\n",
    "            api_key=\"sk-8709f7ed33dc402a8a9885a1a8ee403e\", \n",
    "            base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\"\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def chat(self, text, messages=[]):\n",
    "        if not messages:\n",
    "            # 如果没有历史消息，则将用户输入作为第一条消息\n",
    "            messages = [{\"role\": \"user\", \"content\": text}]\n",
    "        \n",
    "        # 使用固定的 engine 发送对话请求，并获取回复结果\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"qwen-turbo\",\n",
    "            messages=messages,\n",
    "            temperature=0.8,\n",
    "            top_p=0.8\n",
    "        )\n",
    "        \n",
    "        # 返回回复内容\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "qwen_bot = QwenLLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def div_func(a: float, b: float):\n",
    "    \"\"\"\n",
    "    除法函数\n",
    "    \"\"\"\n",
    "    return a / b\n",
    "\n",
    "def mul_func(a: float, b: float):\n",
    "    \"\"\"\n",
    "    乘法函数\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "def chat_func(text: str):\n",
    "    \"\"\"\n",
    "    聊天函数\n",
    "    \"\"\"\n",
    "    return text\n",
    "    \n",
    "\n",
    "prompt_6 = \"\"\"你可以调用下面列出的函数来辅助完成用户提出的问题，函数的描述如下\n",
    "- div_func(a: float, b: float)：除法函数\n",
    "- mul_func(a: float, b: float)：乘法函数\n",
    "- chat_func(text: str)：聊天函数\n",
    "你的输出必须满足如下的格式\n",
    "动作: <你要调用的函数名称>\n",
    "函数输入: <输入函数的值，必须符合函数的输入参数要求，如果有多个值每个值之间用逗号分隔>\n",
    "观察: <函数的输出结果>\n",
    "思考: 你对接下来的思考\n",
    "你将会在观察中看到函数的输出结果，然后思考你的下一步行动，思考完后将进行下一轮动作和函数输入，每组之间不要重叠，如果已经找到了答案就执行 chat_func 函数\n",
    "\n",
    "请问：1.5 除以 2.5 再乘以 3.5 是多少？直接告诉我答案\n",
    "\"\"\"\n",
    "\n",
    "def get_action_and_args(text: str):\n",
    "    \"\"\"\n",
    "    解析输入的字符串，得到动作和参数\n",
    "    \"\"\"\n",
    "    lines = [l for l in text.split(\"\\n\") if l.strip()]  # 将文本按行分割并去除空行\n",
    "    action = \"\"  # 初始化动作为空字符串\n",
    "    args = []  # 初始化参数列表为空\n",
    "    for line in lines:  # 遍历每一行\n",
    "        if line.startswith(\"动作:\"):  # 如果行以\"动作:\"开头\n",
    "            action = line.replace(\"动作:\", \"\").strip()  # 提取动作内容并去除首尾空格\n",
    "        elif line.startswith(\"函数输入:\"):  # 如果行以\"函数输入:\"开头\n",
    "            args = line.replace(\"函数输入:\", \"\").strip().split(\",\")  # 提取参数内容并按逗号分割成列表\n",
    "    return action, args  # 返回动作和参数列表\n",
    "\n",
    "def tool_call(llm: QwenLLM, text: str):\n",
    "    \"\"\"\n",
    "    调用工具函数，接受一个QwenLLM实例和文本作为参数\n",
    "    \"\"\"\n",
    "    output = \"\"  # 初始化输出为空字符串\n",
    "    loop_count = 0  # 初始化循环计数器为0\n",
    "    messages = [{\"role\": \"user\", \"content\": text}]  # 初始化消息列表，包含用户的输入文本\n",
    "    while loop_count < 10:  # 循环开始，最多循环10次\n",
    "        loop_count += 1  # 每次循环计数器加1\n",
    "        llm_output = llm.chat(text, messages)  # 调用llm的_chat方法，传入文本和消息列表\n",
    "        print(llm_output.replace(\"\\n\\n\", \"\\n\"))  # 打印llm输出并替换连续的空行为单个空行\n",
    "        messages += [{\"role\": \"assistant\", \"content\": llm_output}]  # 将助手返回的消息添加到消息列表中\n",
    "        action, args = get_action_and_args(llm_output)  # 解析助手返回消息中的动作和参数\n",
    "        if action and args:  # 如果存在动作和参数\n",
    "            if action == \"chat_func\":  # 如果动作是\"chat_func\"\n",
    "                output = chat_func(args[0])  # 调用chat_func函数并将结果赋给output\n",
    "                break  # 跳出循环\n",
    "            elif action == \"div_func\":  # 如果动作是\"div_func\"\n",
    "                func_output = div_func(float(args[0]), float(args[1]))  # 调用div_func函数\n",
    "            elif action == \"mul_func\":  # 如果动作是\"mul_func\"\n",
    "                func_output = mul_func(float(args[0]), float(args[1]))  # 调用mul_func函数\n",
    "            print(f\"观察: {func_output}\")  # 打印观察结果\n",
    "            messages += [{\"role\": \"user\", \"content\": f\"观察: {func_output}\"}]  # 将观察结果添加到消息列表中\n",
    "        else:  # 如果找不到对应的函数或参数传入错误\n",
    "            messages += [{\"role\": \"user\", \"content\": \"观察: 没有找到对应的函数或参数传入错误\"}]  # 添加提示消息到消息列表\n",
    "            continue  # 继续下一次循环\n",
    "\n",
    "    return output  # 返回输出结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_to_html(tool_call(qwen_bot, prompt_6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def div_func(a: float, b: float):\n",
    "    \"\"\"\n",
    "    除法函数\n",
    "    \"\"\"\n",
    "    return a / b\n",
    "\n",
    "def mul_func(a: float, b: float):\n",
    "    \"\"\"\n",
    "    乘法函数\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "def chat_func(text: str):\n",
    "    \"\"\"\n",
    "    聊天函数\n",
    "    \"\"\"\n",
    "    return text\n",
    "    \n",
    "\n",
    "prompt_6 = \"\"\"你可以调用下面列出的函数来辅助完成用户提出的问题，函数的描述如下\n",
    "- div_func(a: float, b: float)：除法函数\n",
    "- mul_func(a: float, b: float)：乘法函数\n",
    "- chat_func(text: str)：聊天函数\n",
    "你的输出必须满足如下的格式\n",
    "动作: <你要调用的函数名称>\n",
    "函数输入: <输入函数的值，必须符合函数的输入参数要求，如果有多个值每个值之间用逗号分隔>\n",
    "观察: <函数的输出结果>\n",
    "思考: 你对接下来的思考\n",
    "你将会在观察中看到函数的输出结果，然后思考你的下一步行动，思考完后将进行下一轮动作和函数输入，每组之间不要重叠，如果已经找到了答案就执行 chat_func 函数\n",
    "\n",
    "请问：1.5 除以 2.5 再乘以 3.5 是多少？直接告诉我答案\n",
    "\"\"\"\n",
    "\n",
    "def get_action_and_args(text: str):\n",
    "    \"\"\"\n",
    "    解析输入的字符串，得到动作和参数\n",
    "    \"\"\"\n",
    "    lines = [l for l in text.split(\"\\n\") if l.strip()]  # 将文本按行分割并去除空行\n",
    "    action = \"\"  # 初始化动作为空字符串\n",
    "    args = []  # 初始化参数列表为空\n",
    "    for line in lines:  # 遍历每一行\n",
    "        if line.startswith(\"动作:\"):  # 如果行以\"动作:\"开头\n",
    "            action = line.replace(\"动作:\", \"\").strip()  # 提取动作内容并去除首尾空格\n",
    "        elif line.startswith(\"函数输入:\"):  # 如果行以\"函数输入:\"开头\n",
    "            args = line.replace(\"函数输入:\", \"\").strip().split(\",\")  # 提取参数内容并按逗号分割成列表\n",
    "    return action, args  # 返回动作和参数列表\n",
    "\n",
    "def tool_call(llm: OpenAILLM, text: str):\n",
    "    \"\"\"\n",
    "    调用工具函数，接受一个OpenAILLM实例和文本作为参数\n",
    "    \"\"\"\n",
    "    output = \"\"  # 初始化输出为空字符串\n",
    "    loop_count = 0  # 初始化循环计数器为0\n",
    "    messages = [{\"role\": \"user\", \"content\": text}]  # 初始化消息列表，包含用户的输入文本\n",
    "    while loop_count < 10:  # 循环开始，最多循环10次\n",
    "        loop_count += 1  # 每次循环计数器加1\n",
    "        llm_output = llm.chat(text, messages, stops=\"观察:\")  # 调用llm的_chat方法，传入文本和消息列表\n",
    "        print(llm_output.replace(\"\\n\\n\", \"\\n\"))  # 打印llm输出并替换连续的空行为单个空行\n",
    "        messages += [{\"role\": \"assistant\", \"content\": llm_output}]  # 将助手返回的消息添加到消息列表中\n",
    "        action, args = get_action_and_args(llm_output)  # 解析助手返回消息中的动作和参数\n",
    "        if action and args:  # 如果存在动作和参数\n",
    "            if action == \"chat_func\":  # 如果动作是\"chat_func\"\n",
    "                output = chat_func(args[0])  # 调用chat_func函数并将结果赋给output\n",
    "                break  # 跳出循环\n",
    "            elif action == \"div_func\":  # 如果动作是\"div_func\"\n",
    "                func_output = div_func(float(args[0]), float(args[1]))  # 调用div_func函数\n",
    "            elif action == \"mul_func\":  # 如果动作是\"mul_func\"\n",
    "                func_output = mul_func(float(args[0]), float(args[1]))  # 调用mul_func函数\n",
    "            print(f\"观察: {func_output}\")  # 打印观察结果\n",
    "            messages += [{\"role\": \"user\", \"content\": f\"观察: {func_output}\"}]  # 将观察结果添加到消息列表中\n",
    "        else:  # 如果找不到对应的函数或参数传入错误\n",
    "            messages += [{\"role\": \"user\", \"content\": \"观察: 没有找到对应的函数或参数传入错误\"}]  # 添加提示消息到消息列表\n",
    "            continue  # 继续下一次循环\n",
    "\n",
    "    return output  # 返回输出结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "markdown_to_html(tool_call(openai_bot, prompt_6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过上面这个简单的实验，我们可以看到时至今日，大模型已经有了一定的外部工具调用的能力，不过如果仅仅使用我们自己写的提示词，模型调用工具的能力很难达到最优，因为如今的大模型在训练过程中大多数已经加入了类似工具学习的指令微调数据集，用以增强模型的外部工具调用能力，而他们在训练和优化过程中使用的提示词很难被我们猜到，因此，为了让模型在利用外部工具的能力上达到最优，最好的方案还是使用大模型厂商提供的函数调用能力，例如 OpenAI 提供的 function call，在 gpts 中提供的 actions 等，这些功能都是经过大模型厂商精心设计和优化过的，相对而言性能会更加优秀，结果也会更加稳定。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 函数调用\n",
    "\n",
    "这一小节我们将使用 OpenAI 提供的 function call 功能来实现上面的实验。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在开始我们的实验之前，我们需要修改一下在上面实现的 llm 类，让它可以支持 function call 的功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "# 定义 QwenLLM 类，继承自 BaseLLM， 其接口与gpt系列基本相同\n",
    "class QwenLLM(BaseLLM):\n",
    "    def __init__(self):\n",
    "        # 初始化 QwenLLM 实例，传入环境变量中的 api_key 和 base_url\n",
    "        self.client = OpenAI(\n",
    "            api_key=\"sk-8709f7ed33dc402a8a9885a1a8ee403e\", \n",
    "            base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\"\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def chat(self, text, messages=[]):\n",
    "        if not messages:\n",
    "            # 如果没有历史消息，则将用户输入作为第一条消息\n",
    "            messages = [{\"role\": \"user\", \"content\": text}]\n",
    "        \n",
    "        # 使用固定的 engine 发送对话请求，并获取回复结果\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"qwen-turbo\",\n",
    "            messages=messages,\n",
    "            temperature=0.8,\n",
    "            top_p=0.8\n",
    "        )\n",
    "        \n",
    "        # 返回回复内容\n",
    "        return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QwenTool(QwenLLM):\n",
    "    def __init__(self, tools=[]):\n",
    "        super().__init__()\n",
    "        self.tools = tools\n",
    "\n",
    "    def tool_chat(self, text, messages=[]):\n",
    "        if not messages:\n",
    "            messages = [{\"role\": \"user\", \"content\": text}]\n",
    "        # 为了保证实验和课程的结果一致，这里使用了固定的 engine\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"qwen-turbo\",\n",
    "            messages=messages,\n",
    "            tools=self.tools\n",
    "        )\n",
    "        return response.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "class OpenAITool(OpenAILLM):\n",
    "    def __init__(self, tools=[]):\n",
    "        super().__init__()\n",
    "        self.tools = tools\n",
    "\n",
    "    def tool_chat(self, text, messages=[], stops=None):\n",
    "        if not messages:\n",
    "            messages = [{\"role\": \"user\", \"content\": text}]\n",
    "        # 为了保证实验和课程的结果一致，这里使用了固定的 engine\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=messages,\n",
    "            stream=False,\n",
    "            stop=stops,\n",
    "            tools=self.tools\n",
    "        )\n",
    "        return response.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "div_tool = {  # 用 JSON 描述函数。可以定义多个。由大模型决定调用谁。也可能都不调用\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"div_func\",\n",
    "        \"description\": \"除法函数\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"a\": {\n",
    "                    \"type\": \"number\",\n",
    "                    \"description\": \"被除数\",\n",
    "                },\n",
    "                \"b\": {\n",
    "                    \"type\": \"number\",\n",
    "                    \"description\": \"除数\",\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "mul_tool = {  # 用 JSON 描述函数。可以定义多个。由大模型决定调用谁。也可能都不调用\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"mul_func\",\n",
    "        \"description\": \"乘法函数\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"a\": {\n",
    "                    \"type\": \"number\",\n",
    "                    \"description\": \"乘数\",\n",
    "                },\n",
    "                \"b\": {\n",
    "                    \"type\": \"number\",\n",
    "                    \"description\": \"乘数\",\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个名为 'tools' 的列表，包含两个工具对象 'div_tool' 和 'mul_tool'。\n",
    "tools = [div_tool, mul_tool]\n",
    "\n",
    "# 创建一个 'QwenTool' 类的实例 'qwen_tool'，并将 'tools' 列表作为参数传递给这个实例。\n",
    "qwen_tool = QwenTool(tools=tools)\n",
    "\n",
    "# 定义一个名为 'func_call' 的函数，它接受一个 'QwenTool' 类型的模型 'model' 和一个字符串 'text' 作为参数。\n",
    "def func_call(model: QwenTool, text: str):\n",
    "    \"\"\"\n",
    "    调用工具函数\n",
    "    \"\"\"\n",
    "    # 初始化一个空字符串 'output'，用于存储最终输出。\n",
    "    output = \"\"\n",
    "    # 初始化一个消息列表 'messages'，包含一个字典，表示用户的角色和发送的内容。\n",
    "    messages = [{\"role\": \"user\", \"content\": text}]\n",
    "    # 初始化一个循环计数器 'loop_cnt'，用于控制循环的次数。\n",
    "    loop_cnt = 0\n",
    "    # 使用一个 while 循环，当 'loop_cnt' 小于 10 时继续执行循环。\n",
    "    while loop_cnt < 10:\n",
    "        # 增加循环计数器 'loop_cnt' 的值。\n",
    "        loop_cnt += 1\n",
    "        # 调用模型的 'tool_chat' 方法，传入当前文本 'text' 和消息列表 'messages'，获取响应。\n",
    "        llm_response = model.tool_chat(text, messages)\n",
    "        # 将模型的响应添加到消息列表 'messages' 中。\n",
    "        messages.append(llm_response)\n",
    "        # 检查响应中是否包含工具调用 'tool_calls'。\n",
    "        if llm_response.tool_calls is not None:\n",
    "            # 如果有工具调用，遍历每个工具调用。\n",
    "            for tool_call in llm_response.tool_calls:\n",
    "                # 将工具调用中的参数从 JSON 字符串解析为 Python 字典。\n",
    "                args = json.loads(tool_call.function.arguments)\n",
    "                # 检查工具调用的函数名称是否是 'div_func'。\n",
    "                if tool_call.function.name == \"div_func\":\n",
    "                    # 如果是，调用除法函数 'div_func'，并将参数 'a' 和 'b' 转换为浮点数。\n",
    "                    func_output = div_func(float(args[\"a\"]), float(args[\"b\"]))\n",
    "                # 检查工具调用的函数名称是否是 'mul_func'。\n",
    "                elif tool_call.function.name == \"mul_func\":\n",
    "                    # 如果是，调用乘法函数 'mul_func'，并将参数 'a' 和 'b' 转换为浮点数。\n",
    "                    func_output = mul_func(float(args[\"a\"]), float(args[\"b\"]))\n",
    "                # 将工具调用的结果添加到消息列表 'messages' 中。\n",
    "                messages.append({\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"role\": \"tool\",\n",
    "                    \"name\": tool_call.function.name,\n",
    "                    \"content\": str(func_output)\n",
    "                })\n",
    "                # 打印工具调用的详细信息，包括函数名称、输入参数和输出结果。\n",
    "                print(f\"调用了 {tool_call.function.name} 函数，输入参数为 {args}，输出结果为 {func_output}\")\n",
    "        # 如果响应中没有工具调用，结束循环。\n",
    "        else:\n",
    "            break\n",
    "    # 将消息列表中最后一个消息的内容赋值给 'output' 变量。\n",
    "    output = messages[-1].content\n",
    "    # 返回最终的输出结果 'output'。\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个名为 'tools' 的列表，包含两个工具对象 'div_tool' 和 'mul_tool'。\n",
    "tools = [div_tool, mul_tool]\n",
    "\n",
    "# 创建一个 'OpenAITool' 类的实例 'openai_tool'，并将 'tools' 列表作为参数传递给这个实例。\n",
    "openai_tool = OpenAITool(tools=tools)\n",
    "\n",
    "# 定义一个名为 'func_call' 的函数，它接受一个 'OpenAITool' 类型的模型 'model' 和一个字符串 'text' 作为参数。\n",
    "def func_call(model: OpenAITool, text: str):\n",
    "    \"\"\"\n",
    "    调用工具函数\n",
    "    \"\"\"\n",
    "    # 初始化一个空字符串 'output'，用于存储最终输出。\n",
    "    output = \"\"\n",
    "    # 初始化一个消息列表 'messages'，包含一个字典，表示用户的角色和发送的内容。\n",
    "    messages = [{\"role\": \"user\", \"content\": text}]\n",
    "    # 初始化一个循环计数器 'loop_cnt'，用于控制循环的次数。\n",
    "    loop_cnt = 0\n",
    "    # 使用一个 while 循环，当 'loop_cnt' 小于 10 时继续执行循环。\n",
    "    while loop_cnt < 10:\n",
    "        # 增加循环计数器 'loop_cnt' 的值。\n",
    "        loop_cnt += 1\n",
    "        # 调用模型的 'tool_chat' 方法，传入当前文本 'text' 和消息列表 'messages'，获取响应。\n",
    "        llm_response = model.tool_chat(text, messages)\n",
    "        # 将模型的响应添加到消息列表 'messages' 中。\n",
    "        messages.append(llm_response)\n",
    "        # 检查响应中是否包含工具调用 'tool_calls'。\n",
    "        if llm_response.tool_calls is not None:\n",
    "            # 如果有工具调用，遍历每个工具调用。\n",
    "            for tool_call in llm_response.tool_calls:\n",
    "                # 将工具调用中的参数从 JSON 字符串解析为 Python 字典。\n",
    "                args = json.loads(tool_call.function.arguments)\n",
    "                # 检查工具调用的函数名称是否是 'div_func'。\n",
    "                if tool_call.function.name == \"div_func\":\n",
    "                    # 如果是，调用除法函数 'div_func'，并将参数 'a' 和 'b' 转换为浮点数。\n",
    "                    func_output = div_func(float(args[\"a\"]), float(args[\"b\"]))\n",
    "                # 检查工具调用的函数名称是否是 'mul_func'。\n",
    "                elif tool_call.function.name == \"mul_func\":\n",
    "                    # 如果是，调用乘法函数 'mul_func'，并将参数 'a' 和 'b' 转换为浮点数。\n",
    "                    func_output = mul_func(float(args[\"a\"]), float(args[\"b\"]))\n",
    "                # 将工具调用的结果添加到消息列表 'messages' 中。\n",
    "                messages.append({\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"role\": \"tool\",\n",
    "                    \"name\": tool_call.function.name,\n",
    "                    \"content\": str(func_output)\n",
    "                })\n",
    "                # 打印工具调用的详细信息，包括函数名称、输入参数和输出结果。\n",
    "                print(f\"调用了 {tool_call.function.name} 函数，输入参数为 {args}，输出结果为 {func_output}\")\n",
    "        # 如果响应中没有工具调用，结束循环。\n",
    "        else:\n",
    "            break\n",
    "    # 将消息列表中最后一个消息的内容赋值给 'output' 变量。\n",
    "    output = messages[-1].content\n",
    "    # 返回最终的输出结果 'output'。\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_7 = \"请问：1.5 除以 2.5 再乘以 3.5 是多少？请告诉我答案\"\n",
    "#markdown_to_html(func_call(openai_tool, prompt_7))\n",
    "markdown_to_html(func_call(qwen_tool, prompt_7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来我们使用一个更复杂的例子来感受函数调用的魅力。\n",
    "\n",
    "每年高考季，各类志愿填报网站就会变得非常热门，因为高考成绩是决定一个人未来命运的重要因素，而填报志愿是决定一个人未来学习环境的重要因素，而了解学校的过往分数线是了解一个学校的重要途径，相比完整的表格，自然语言的阐述更加的贴近日常对话，也更能让用户接受志愿建议，为此，我们收集了部分学校在过去几年的平均分数线（数据仅供参考，不保证数据的真实性），并将数据存储在关系数据库sqlite中，下面是数据的部分截图\n",
    "\n",
    "![gaokao database](images/gaokao-database.png)\n",
    "\n",
    "我们的目标是让大模型能够根据用户的提问（例如：“我今年在武汉考了六百四十分，我可以上什么学校比较有把握呢？”），撰写sql查询语句，并根据查询的结果或者查询失败的原因，给出合理的回复。我们接着使用OpenAI的函数调用能力来实现这个功能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实现一个函数，传入一条sql语句，返回查询结果，返回是一个字典列表，每个字典是一条记录\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "\n",
    "def gaokao_query(sql: str):\n",
    "    \"\"\"\n",
    "    查询高考录取分数\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(\"./files/gaokao.db\")\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(sql)\n",
    "    rows = cursor.fetchall()\n",
    "    columns = [c[0] for c in cursor.description]\n",
    "    results = []\n",
    "    for row in rows:\n",
    "        results.append(dict(zip(columns, row)))\n",
    "    conn.close()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_tool_desc = \"\"\"使用sql语句查询学校及其录取分数线，数据存储在sqlite数据库中，数据有四个字段，分别是学校，文理科，招生省份和平均分数，查询出来的结果可能会有很多，请尽量使用 limit 语句限制输出数量，例如：\n",
    "查询语句：\n",
    "select * from gaokao where 学校 = '北京大学' and 文理科 = '文科' limit 2\n",
    "查询结果：\n",
    "[{'学校': '北京大学', '文理科': '文科', '招生省份': '天津', '平均分数': 690.5},\n",
    " {'学校': '北京大学', '文理科': '文科', '招生省份': '吉林', '平均分数': 686.6}]\n",
    "\"\"\"\n",
    "\n",
    "sql_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"sql_func\",\n",
    "        \"description\": sql_tool_desc,\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"sql\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"SQL语句\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"sql\"],\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_qwen_tool = QwenTool(tools=[sql_tool])\n",
    "\n",
    "def sql_func_call(model: QwenTool, text: str):\n",
    "    \"\"\"\n",
    "    调用工具函数\n",
    "    \"\"\"\n",
    "    # 1. 解析输入的字符串\n",
    "    # 2. 调用对应的函数\n",
    "    # 3. 输出结果\n",
    "    # 4. 输出思考\n",
    "    output = \"\"\n",
    "    messages = [{\"role\": \"user\", \"content\": text}]\n",
    "    loop_cnt = 0\n",
    "    while loop_cnt < 10:\n",
    "        loop_cnt += 1\n",
    "        llm_response = model.tool_chat(text, messages)\n",
    "        messages.append(llm_response)\n",
    "        if llm_response.tool_calls is not None:\n",
    "            for tool_call in llm_response.tool_calls:\n",
    "                args = json.loads(tool_call.function.arguments)\n",
    "                if tool_call.function.name == \"sql_func\":\n",
    "                    func_output = gaokao_query(args[\"sql\"])\n",
    "                # 如果没有正确调用sql_func，可能导致下面的内容出错，此时重新执行即可。\n",
    "                messages.append({\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"role\": \"tool\",\n",
    "                    \"name\": tool_call.function.name,\n",
    "                    \"content\": str(func_output) if len(str(func_output)) < 3000 else str(func_output)[:3000] + \"...\"\n",
    "                })\n",
    "                markdown_to_html((f\"调用了 {tool_call.function.name} 函数，输入参数为 {args}，输出结果为 {func_output}\"))\n",
    "        else:\n",
    "            # print(messages)\n",
    "            # output = model.tool_chat(text, messages)\n",
    "            break\n",
    "    output = messages[-1].content\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_openai_tool = OpenAITool(tools=[sql_tool])\n",
    "\n",
    "def sql_func_call(model: OpenAITool, text: str):\n",
    "    \"\"\"\n",
    "    调用工具函数\n",
    "    \"\"\"\n",
    "    # 1. 解析输入的字符串\n",
    "    # 2. 调用对应的函数\n",
    "    # 3. 输出结果\n",
    "    # 4. 输出思考\n",
    "    output = \"\"\n",
    "    messages = [{\"role\": \"user\", \"content\": text}]\n",
    "    loop_cnt = 0\n",
    "    while loop_cnt < 10:\n",
    "        loop_cnt += 1\n",
    "        llm_response = model.tool_chat(text, messages)\n",
    "        messages.append(llm_response)\n",
    "        if llm_response.tool_calls is not None:\n",
    "            for tool_call in llm_response.tool_calls:\n",
    "                args = json.loads(tool_call.function.arguments)\n",
    "                if tool_call.function.name == \"sql_func\":\n",
    "                    func_output = gaokao_query(args[\"sql\"])\n",
    "                # 如果没有正确调用sql_func，可能导致下面的内容出错，此时重新执行即可。\n",
    "                messages.append({\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"role\": \"tool\",\n",
    "                    \"name\": tool_call.function.name,\n",
    "                    \"content\": str(func_output) if len(str(func_output)) < 3000 else str(func_output)[:3000] + \"...\"\n",
    "                })\n",
    "                markdown_to_html((f\"调用了 {tool_call.function.name} 函数，输入参数为 {args}，输出结果为 {func_output}\"))\n",
    "        else:\n",
    "            # print(messages)\n",
    "            # output = model.tool_chat(text, messages)\n",
    "            break\n",
    "    output = messages[-1].content\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(sql_func_call(sql_openai_tool, \"请问：北京大学文科在天津的录取分数是多少？\"))\n",
    "print(sql_func_call(sql_qwen_tool, \"请问：北京大学文科在天津的录取分数是多少？\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(sql_func_call(sql_openai_tool, \"我今年在浙江省高考考了650分，请问我这个分数有什么学校推荐吗？\"))\n",
    "print(sql_func_call(sql_qwen_tool, \"我今年在浙江省高考考了650分，请问我这个分数有什么学校推荐吗？\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(sql_func_call(sql_openai_tool, \"请问：在招生省份：浙江，平均分数低于650分的学校有哪些，降序排序，给出前10\"))\n",
    "print(sql_func_call(sql_qwen_tool, \"请问：在招生省份：浙江，平均分数低于650分的学校有哪些，降序排序，给出前10\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI Assistant API\n",
    "\n",
    "OpenAI Assistant API 使开发者能够将先进的人工智能功能整合到他们的应用程序中。这个API基于最新的机器学习和自然语言处理技术，提供了文本生成、语言翻译、摘要和问答等多种功能。它能够处理复杂和微妙的人类语言，适用于客户服务、内容创作和数据分析等多个领域。API的灵活架构使其可以根据不同行业的特定用途进行定制。此外，API不断进行更新和改进，融入人工智能研究的最新进展。\n",
    "\n",
    "Assistant API出现前有哪些问题：\n",
    "- 无法预先学习客户提供的知识，比如我没办法让它读完一本新写的书，因为这本书不在它的知识库里；\n",
    "- 没有连续对话支持，每次调用它的 API 都需要发送对话的全部上下文，而这个上下文是有长度限制的；\n",
    "- 没有真正的推理和执行能力，在数学计算方面尤其明显，它很可能给你一个错误的计算结果，因为它并没有真正的执行计算；\n",
    "\n",
    "Assistant API的主要功能：\n",
    "\n",
    "- Threading：提供持久保存且无限长度的上下文，开发人员可以不用关心上下文的存储了，而且更省钱\n",
    "- Knowledge Retrieval：检索用户上传的文件内容，并在未来可能支持开发者自定义检索方式\n",
    "- Code Interpreter：执行用户上传的脚本文件来解决问题，可以上传多个脚本，AI 自己会选择何时执行\n",
    "- Function Calling：调用第三方函数，只需要告诉 AI 函数功能和请求格式，AI 自己会选择何时执行\n",
    "\n",
    "下面我们通过 OpenAI Assistant API 来重新实现高考志愿推荐助手的逻辑，让我们看看这样是否会有不同，另外，你是用代码创建的 OpenAI Assistant 也可以在你的 [playground](https://platform.openai.com/playground?mode=assistant) 中找到。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = openai_bot.client.beta.assistants.create(\n",
    "    # 指定了Assistant的名称\n",
    "    name=\"高考志愿咨询助手\",\n",
    "    # 定义Assistant的指令和它的角色\n",
    "    instructions=\"你是一位高考志愿的填报专家，你可以查询高校在各个省份的文理科录取分数线，你要根据输入给出合适的志愿建议，并回答用户的相关问题，根据用户所在省份来选择招生省份。\",\n",
    "    # 指定Assistant使用的OpenAI模型\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    # 列出Assistant可以使用的工具，这里是代码解释器\n",
    "    tools=[sql_tool, {\"type\": \"code_interpreter\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一个thread代表一个对话窗口。我们建议在用户发起对话后立即为每个用户创建一个thread。 \n",
    "thread = openai_bot.client.beta.threads.create()\n",
    "\n",
    "# 在这个thread中添加一条用户提问，让我们预设好的assistant来回答\n",
    "openai_bot.client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"我是一个理科生，招生省份是浙江省，今年高考考了650分，请问有什么学校推荐吗？请给我推荐保底的学校，以及冲刺的学校。\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加完成之后我们创建一个run\n",
    "run = openai_bot.client.beta.threads.runs.create(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    "  instructions=\"请给出合适的学校推荐，并给出详细理由\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# 创建完成并不会立刻开始运行，需要轮询run的状态，直到状态变成completed\n",
    "while True:\n",
    "    run = openai_bot.client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
    "    # 根据run的状态来判断执行何种操作\n",
    "    # 若果正在排队或者正在处理生成结果，那么继续等待即可\n",
    "    if run.status in [\"queued\", \"in_progress\"]:\n",
    "        print(run.status)\n",
    "        run = openai_bot.client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
    "    # 如果是已完成，那么就跳出这个循环\n",
    "    elif run.status == \"completed\":\n",
    "        print(run.status)\n",
    "        break\n",
    "    # 如果run的过程中需要使用我们预先传入的一些函数，例如 sql_tool 函数，那么它的状态就会变成 requires_action\n",
    "    elif run.status == \"requires_action\":\n",
    "        require_action = run.required_action\n",
    "        func_call_outputs = []\n",
    "        print(require_action)\n",
    "        # 遍历本次需要使用的工具函数列表，因为有可能一次调用多个函数\n",
    "        for tool_call in require_action.submit_tool_outputs.tool_calls:\n",
    "            print(tool_call.function.name)\n",
    "            # 因为我们只有一个 sql_func 函数，因此只进行这个的判断\n",
    "            if tool_call.function.name == \"sql_func\":\n",
    "                args = json.loads(tool_call.function.arguments)\n",
    "                func_output = gaokao_query(args[\"sql\"])\n",
    "                # 调用完成之后，将返回结果包装成对应的结构加入到 func_call_outputs 列表中\n",
    "                func_call_outputs.append({\"output\": str(func_output), \"tool_call_id\": tool_call.id})\n",
    "                markdown_to_html(f\"调用了 {tool_call.function.name} 函数，输入参数为 {tool_call.function.arguments}，输出结果为 {func_output}\")\n",
    "        # 将工具调用的结果传回 openai\n",
    "        run = openai_bot.client.beta.threads.runs.submit_tool_outputs(\n",
    "            thread_id=thread.id,\n",
    "            run_id=run.id,\n",
    "            tool_outputs=func_call_outputs\n",
    "        )\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 运行完成后，我们可以查看run的结果\n",
    "messages = openai_bot.client.beta.threads.messages.list(\n",
    "  thread_id=thread.id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最后我们可以将结果输出\n",
    "#markdown_to_html(messages.data[0].content[0].text.value)\n",
    "print(messages.data[0].content[0].text.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这里，assistant api集成了function calling和rag的功能，所以这些功能之间没有替代关系，在前半部分我们说明了两个功能分别能干什么，然后讲述了assistant api的集成功能。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 课程小结\n",
    "\n",
    "1. 在本章节中，我们比较了目前市面上的主流的商业大模型和开源大模型的能力，学习了如何使用Python调用各类在线大模型平台的接口，并使用接口完成一些特定的问答任务。\n",
    "2. 第二部分，我们学习了如何使用提示工程的方法来设计一个有效的提示词，让大模型可以完成我们想要的任务，同时我们还学习了如何使用检索增强的方法来让大模型可以快速上手未训练过的领域。\n",
    "3. 第三部分，我们学习了如何使用大模型的外部能力调用，让大模型可以调用我们设计好的插件，从而更加高效的完成任务。\n",
    "4. 第四部分，我们学习了如何使用 OpenAI Assistant API 来让第三方应用也可以间接调用 code interpreter，进一步提升应用的智能化程度。\n",
    "\n",
    "## Reference 引用\n",
    "- [Prompt Engineering](https://www.promptingguide.ai/zh)\n",
    "- [Biadu Wenxin](https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Slkkydake)\n",
    "- [星火大语言模型](https://www.xfyun.cn/doc/spark/Web.html)\n",
    "- [OpenAI API](https://beta.openai.com/docs/api-reference/introduction)\n",
    "- [OpenAI Plugins](https://platform.openai.com/docs/plugins/introduction)\n",
    "- [OpenAI Actions](https://platform.openai.com/docs/actions)\n",
    "- [OpenAI Assistant API](https://platform.openai.com/docs/assistants/overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 环境配置\n",
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "1. **sparkdesk-api**\n",
    "   作用：是讯飞星火认知大模型的API接口，主要支持Web模式和API模式两种调用方法\n",
    "2. **openai**\n",
    "   作用：是由OpenAI公司提供的第三方Python库，用于调用OpenAI的模型\n",
    "3. **faiss-cpu**\n",
    "   作用：Faiss是一个用于高效相似性搜索和密集向量聚类的库，这里安装的faiss-cpu是其对应的CPU版本\n",
    "4. **langchain**\n",
    "   作用：大模型的API是无法联网的，因此检索信息并给出回答、总结PDF文档的内容、基于在线视频进行问答等功能肯定是无法实现的。因此需要langchain第三方库，将模型与外部数据源进行连接，让模型基于额外提供的数据生成回复\n",
    "5. **pymupdf**\n",
    "   作用：用于处理PDF文件的Python库。可以以解析文本框的方式读取、编辑和操作PDF文档，适用于需要程序化处理PDF的应用\n",
    "6. **numpy**\n",
    "   作用：用于科学计算的第三方库，提供了支持大规模多维数组和矩阵运算的功能，以及大量的数学函数库\n",
    "7. **matplotlib**\n",
    "   作用：用于将数据进行可视化的第三方库，支持生成各种类型的图表和图形\n",
    "8. **tiktoken**\n",
    "   作用：tiktoken是OpenAI开源的第三方库，主要实现了tokenizer的BPE（Byte pair encoding）分词算法，并对运行性能做了优化\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

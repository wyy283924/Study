{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 大模型思维链"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学习**技术**的同学们，你们要特别关注如何构建有效的推理路径、如何设计反馈机制以及权重更新策略，深入理解这些推理模型的构建方法和实践技巧。\n",
    "\n",
    "学习**AI产品经理**的同学们，你们需要着重理解推理模型的实际业务应用价值，包括如何利用推理模型有效提升产品决策能力，如何从用户视角评估推理效果，以及如何将推理过程与产品功能结合以提升整体用户体验。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Skeleton-of-Thought 思维骨架](https://arxiv.org/pdf/2307.15337.pdf)\n",
    "\n",
    "\n",
    "\n",
    "SoT 旨在降低大型语言模型（LLMs）的端到端生成延迟。高生成延迟的主要原因之一是几乎所有最先进的LLMs都采用的顺序解码方法。在这项工作中，受到人类思考和写作过程的启发，研究者提出了“思维框架”（SoT），首先引导LLMs生成答案的骨架，然后并行进行API调用或批处理解码，以同时完成每个骨架点的内容。SoT不仅在12个LLMs上提供了显著的加速，而且还有望在几个问题类别上提高答案质量。SoT是对推理效率进行数据中心优化的初步尝试，进一步强调了推动LLMs更像人类思考以提高答案质量的潜力。\n",
    "\n",
    "SoT思维框架的巧妙之处在于采用两阶段生成方法，以最大程度地缩短完整答案生成的时间。\n",
    "\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"image/SOT-1.png\" width=\"800\" alt=\"cot-example\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "#### 阶段一：Skeleton stage\n",
    "\n",
    "首先，系统制定了答案的初步蓝图，相当于搭建了一个基础结构。这并不是生成完整响应，而是提示模型生成一个简洁的答案框架。通过这个蓝图，我们捕捉了预期答案的核心要素，为下一阶段提供了基础。\n",
    "\n",
    "SoT首先使用骨架提示模板结合原始问题创建一个骨架请求。骨架提示模板的目的是引导LLM生成答案的简洁骨架。然后，我们从LLM的骨架响应中提取B个要点。\n",
    "\n",
    "骨架提示模板：为了使输出的骨架简短并以一致的格式，以提高效率和提取点的便利性，骨架提示模板（1）精确描述任务，（2）使用两个简单的示例，以及（3）为LLM提供一个部分答案“1.” 以便继续编写。我们发现，在大多数情况下，骨架响应都符合期望的格式。因此，我们可以简单地使用正则表达式从骨架响应中提取点索引和点骨架。\n",
    "\n",
    "#### 阶段二：Point-expanding stage\n",
    "\n",
    "基于骨架，我们使用点扩展提示模板组装B个点扩展请求，并让LLM并行扩展每个点。对于仅具有API访问权限的专有模型，我们可以发出多个并行的API调用。对于开源模型，我们让模型处理点扩展请求作为批处理（在点扩展请求的左侧添加填充）。最终，在完成所有点的处理后，我们串联点扩展响应以得到最终答案。\n",
    "\n",
    "\n",
    "\n",
    "#### Skeleton prompt 模版\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"image/SOT-3.png\" width=\"800\" alt=\"cot-example\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "这张图片展示了“Skeleton of Thought”（SOT）的概念，它是一种结构化的提示模板，用于辅助语言模型生成简洁的回答概要。在这个例子中，用户被告知要组织回答的“骨架”，而不是提供完整的内容。骨架应以简短的要点列表形式给出，每个要点只有3到5个单词，通常包含3到10个点。\n",
    "\n",
    "在图中给出了两个示例问题及其骨架回答：\n",
    "1. 问及“典型的中国菜有哪些？”的回答骨架列出了八种中国菜。\n",
    "2. 问及“个人减少碳排放的实用建议有哪些？”的回答骨架列出了六条减少碳排放的方法。\n",
    "\n",
    "这些示例展示了如何将复杂或详细的信息简化为核心要点，这样语言模型在回答问题时就可以更加高效和目的性强。SOT的目的是引导模型进行高效和集中的思考，以及在需要时能够展开更详细的讨论。\n",
    "\n",
    "还有一个提示让助手为一个新问题提供骨架，尽管新问题没有在图中显示。这表明SOT可以作为一种通用的模板，用于各种不同类型的问题，鼓励模型以简洁、结构化的方式来组织和表达信息。这与传统的长篇详细回答相比，提供了一种更简明扼要的信息交流方式。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 优势\n",
    "\n",
    "SoT的独特之处在于将生成任务分解为生成答案蓝图和并行充实细节两个步骤。这不仅加速了生成过程，还确保了生成的答案在一致性和准确性方面的质量。通过这种方式，SoT框架更加流畅地应对了端到端生成任务的挑战。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### [Everything of Thoughts (XOT)](https://arxiv.org/pdf/2311.04254.pdf)\n",
    "- Ding R, Zhang C, Wang L, et al. Everything of thoughts: Defying the law of penrose triangle for thought generation[J]. arXiv preprint arXiv:2311.04254, 2023.\n",
    "\n",
    "该论文主要介绍了大语言模型的最新进展，通过将复杂问题分解为更易管理的语言序列，即“思维”，从而革新了决策的方式。它提出了一种名为“思维的一切”（XoT）的新颖思维引导方法，来打破现有思维范式的[彭罗斯三角定律](https://zh.wikipedia.org/wiki/%E6%BD%98%E6%B4%9B%E6%96%AF%E4%B8%89%E8%A7%92)，以增强大语言模型的能力，并使其能够高效地推广到未知问题。通过利用预训练的强化学习和蒙特卡洛树搜索（MCTS），XoT可以将外部领域知识纳入思维中，从而自主地生成高质量全面的认知映射。同时，XoT使大语言模型能够进行无约束的思考，为多解问题提供了灵活的认知映射。\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"image/XOT-1.png\" width=\"800\" alt=\"cot-example\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "#### 当前提示技术的局限性\n",
    "  \n",
    "LLMs的最新进展采用了一种新方法，通过将复杂问题拆解成更易处理的“思想”，然后通过自然语言提示来表达。然而，现有的提示技术存在一些限制：\n",
    "\n",
    "- 输入-输出（IO）提示仅适用于简单问题，缺乏灵活性，因为它们主要适用于具有单步解决方案的场景。\n",
    "- 思维链（CoT）虽然能够逐步解决问题，但受限于线性思维结构，缺乏灵活性。\n",
    "- 思维树（ToT）和思维图（GoT）允许更灵活的思维结构，如树或图，但它们需要LLM自身来评估中间思想，导致大量计算成本。\n",
    "\n",
    "从本质上讲，当前的提示技术受到“彭罗斯三角”约束——最多只能实现两个属性（性能、效率、灵活性），而无法同时实现这三个属性。\n",
    "\n",
    "为了克服这些限制，微软开发了一种创新的提示技术，名为XOT（Everything of Thoughts）。XOT集成了强化学习和蒙特卡罗树搜索（MCTS），通过注入外部知识来增强提示过程。这不仅提高了LLM的功能，同时实现了更高的性能、效率和灵活性。\n",
    "\n",
    "#### XOT的方法过程\n",
    "\n",
    "- **XOT的关键组件**\n",
    "\n",
    "MCTS模块：蒙特卡洛树搜索（MCTS）模块通过轻量级的策略和价值网络，通过模拟有效地探索任务的潜在思想结构。\n",
    "\n",
    "LLM求解器：大型语言模型（LLM）求解器则运用LLM的内部知识对MCTS的思想进行提炼和修正。这种协作过程显著提升了任务思维的质量。\n",
    "\n",
    "- **XOT框架关键步骤**\n",
    "\n",
    "预训练阶段:在预训练阶段，我们通过MCTS模块对特定任务进行预训练，以获取与有效思维搜索相关的领域知识。在这个过程中，轻量级的策略和价值网络被用来引导搜索操作。\n",
    "\n",
    "- 思想搜索:在推理过程中，经过预训练的MCTS模块使用策略/价值网络，以一种高效的方式来探索和生成LLM的思想轨迹。\n",
    "\n",
    "- 思想修正:LLM审查MCTS的思想，并辨别其中的错误。修正的想法是通过额外的MCTS模拟产生的。\n",
    "\n",
    "- LLM推理:经过修正的想法被提供给LLM，成为解决问题的最终提示，用以进行推理。\n",
    "\n",
    "MCTS模块：\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"image/XOT-2.png\" width=\"800\" alt=\"cot-example\"/>\n",
    "</div>\n",
    "\n",
    "修订过程：\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"image/XOT-3.png\" width=\"600\" alt=\"cot-example\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "MCTS模块是针对特定任务进行预训练的，它运用策略和价值网络来引导搜索并学习领域知识。\n",
    "\n",
    "在thought搜索的过程中，经过预训练的MCTS利用策略和价值网络高效地探索搜索空间，生成thought轨迹。整个过程通过迭代选择、扩展、评估和反向传播节点的方式展开。\n",
    "\n",
    "生成的thought轨迹被提供给LLM作为Prompt。LLM利用其内部知识来审查thought中的任何潜在错误。如果发现错误，MCTS模块会通过额外的模拟进行修正。\n",
    "\n",
    "这一过程反复进行，直到LLM使用修订后的高质量thought成功解决问题。这种协同工作使得MCTS能够有效地辅助LLM在特定任务中达到更优的结果。\n",
    "\n",
    "\n",
    "XOT为多解决方案中的三个任务生成的思维结构示例场景。\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"image/XOT-4.png\" width=\"600\" alt=\"cot-example\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "XOT描述了一个问题解决过程中的几个关键组成部分：\n",
    "\n",
    "- **状态st**：代表问题的当前状态。初始状态s0对应于原始问题，而中间状态则通过分解出的子问题或其解决结果的产生而具有特征。\n",
    "- **动作at**：表示解决问题相关的一步解决方案或动作，通过合并其结果来过渡到新的状态。\n",
    "- **奖励r**：反映了对原始问题解决方案的综合评估，评估是否通过问题分解过程有效地解决了问题。\n",
    "- **思考τ**：一步思考是一步状态和动作的结合，即τ = {s, a}。这种表述自然地包含了将复杂问题分解为多个子任务的过程，每个子任务都伴随着它们各自的结果。\n",
    "\n",
    "\n",
    "**方法样例**\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"image/XOT-5.png\" width=\"600\" alt=\"cot-example\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "这张图表描述了三个不同的游戏或问题（24点游戏、8字谜游戏和口袋魔方），并用以下几个流程来展示了它们的解决过程：\n",
    "\n",
    "1. **Objective（目标）**: 描述了每个游戏的最终目的。例如，在24点游戏中，目标是使用四个数字通过加减乘除运算得到数字24。\n",
    "\n",
    "2. **Input（输入）**: 指出了解决问题所需的初始信息或给定条件。如在24点游戏中，输入是从1到13范围内的四个数字。\n",
    "\n",
    "3. **Output（输出）**: 表示问题的解决方案。在24点游戏中，输出是一个达到24的方程式。\n",
    "\n",
    "4. **Thought（思考）**: 描述了在解决问题过程中的中间步骤。例如，24点游戏中可能包括3个中间方程式。\n",
    "\n",
    "5. **State（状态）**: 表示问题解决过程中的各个阶段。在24点游戏中，状态可能是剩余的1-4个数字。\n",
    "\n",
    "6. **Action（动作）**: 描述了解决问题所采取的具体行动。在24点游戏中，动作是选择两个数字和一个运算符来组成一个方程式。\n",
    "\n",
    "7. **Reward（奖励）**: 反映了解决方案的评估结果。在24点游戏中，如果最终数字等于24，则奖励为1；否则为-1。\n",
    "\n",
    "这张图表展示了一个结构化的问题解决流程，体现了从问题的初始状态到达成目标状态所需的每一步。这与前面描述的流程相一致，将复杂问题的解决分解为可操作的步骤，并且每一步骤都有明确的目标和评估标准。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XOT的主要优点\n",
    "\n",
    "与现有Prompt技术相比，XOT具有几个显著优点：\n",
    "\n",
    "1. **性能提升：** XOT利用MCTS探索，将领域知识融入思考过程，以增强大型语言模型（LLM）的性能。通过协作修订过程，进一步提高了生成的思考质量。\n",
    "\n",
    "2. **高效性：** XOT采用轻量级策略/价值网络来指导MCTS，从而最大限度地减少了对LLM的昂贵调用。在推理过程中，只需进行1-2次调用，提高了整体效率。\n",
    "\n",
    "3. **灵活性增强：** XOT中的MCTS具有灵活性，可以探索不同的思维结构，如链、树和图，从而实现更具创造性的思考。这使得XOT在处理多样化思维任务时更为适用。\n",
    "\n",
    "总体而言，XOT在性能、效率和灵活性方面相较于其他Prompt技术表现出更为显著的优势。值得注意的是，XOT的实现成功地满足了其他Prompt范式无法同时满足的“Penrose Triangle”标准。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Cumulative Reasoning 累积推理](https://arxiv.org/pdf/2308.04371.pdf)\n",
    "- Zhang Y, Yang J, Yuan Y, et al. Cumulative reasoning with large language models[J]. arXiv preprint arXiv:2308.04371, 2023.\n",
    "\n",
    "Cumulative Reasoning (CR)的目标在于克服语言模型在处理复杂问题时的限制。特别是，观察到语言模型在直接生成高中数学问题的正确答案方面存在一定的困难。\n",
    "\n",
    "**之前的局限性**\n",
    "\n",
    "考虑到大型语言模型（LLMs）的训练方法，存在一个可预见的不足。具体而言，它们在训练时被设计为根据给定上下文的顺序来预测下一个标记，而不是在处理任务时进行思考的中途停顿。我们的认知处理过程涉及两个独立但不同的系统：系统1是迅速、本能和情感驱动的；系统2则是缓慢、深思熟虑和逻辑性强的。目前，LLMs更紧密地与系统1相结合，这或许能够解释它们在处理复杂任务时的限制。\n",
    "\n",
    "为了应对这些限制，一些模拟人类认知过程的方法已被提出，包括提示模型提供逐步解决方案的思想链（CoT）以及将求解过程建模为思维搜索树的思维树（ToT）。此外，专门的数据集已被创建，为模型训练提供逐步引导。然而，这些方法没有有效地存储中间结果的空间，因为它们假设所有的想法形成一条链或一棵树，这并不能充分捕捉人类的思维过程。\n",
    "\n",
    "  \n",
    "**CR方法**\n",
    "  \n",
    "\n",
    "CR通过引入三个独立的LLMs（proposer、verifier、reporter）显著提升了语言模型在处理复杂任务时的表现。在这个框架下，proposer持续提出可能的解决方案，由verifier进行验证，而reporter则负责决定何时停止验证并报告最终解决方案。CR的创新之处在于将整个任务分解成原子而可管理的步骤，这有效地解决了处理指数级增长可能性的计算复杂性。虽然枚举所有复杂任务的可能性在计算上是不可行的，但CR确保每个步骤都是可学习和可解决的。这种分解策略将原本难以管理的问题转化为一系列可行的任务，为解决原始问题提供了坚实而稳健的方法。\n",
    "\n",
    "Cumulative Reasoning (CR)是一种新方法，它以累积和迭代的方式使用语言模型来模拟人类思维过程。通过将任务分解成更小的组成部分，CR使得解决问题的过程更加可管理和有效。CR的实现步骤涉及三种不同类型的语言模型：\n",
    "\n",
    "- 提议者(Proposer)：这个模型基于当前的上下文提出下一步的建议。\n",
    "- 验证者(Verifier(s))：这个模型或模型集合会检验提议者提出的步骤的准确性。如果步骤被认为是正确的，它会被添加到上下文中。\n",
    "- 报告者(Reporter)：这个模型决定何时结束推理过程，并判断当前的条件是否可以直接导致最终解决方案。\n",
    "\n",
    "在每次迭代中，提议者首先提出一个或几个新的主张，然后验证者评估这些提议，确定是否可以将这些主张作为新的前提保留下来。最后，报告者决定是否是停止思考过程并提供答案的最佳时机。\n",
    "\n",
    "CR的理论动机源于直观逻辑、数学建构主义和拓扑理论，这些理论暗示构建新命题的累积过程是执行复杂推理的自然方式，尤其是在（高阶）逻辑和纯数学领域。\n",
    "\n",
    "CR工作的主要贡献在于将不同的LLM角色（提议者、验证者和报告者）在Cumulative Reasoning框架内的协同集成。这种集成使得中间结果的积累和验证更加有效，促进了更深入、更精确的推理过程。这些角色之间的协作互动，以及它们与（代码）环境之间的交互，共同作用以提高系统的推理能力。这种互动允许更有效地积累和验证中间结果，促进了更深入和更精确的推理过程。\n",
    "\n",
    "CR通过将复杂任务分解为更小的步骤，通过多个迭代累积地处理这些步骤，从而提供了一种强大的解决问题的方法。\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"image/CR-1.png\" width=\"600\" alt=\"cot-example\"/>\n",
    "</div>\n",
    "\n",
    "这个图展示了累积推理（CR）解决一个包含三个前提的问题的过程。CR方法使用三种不同类型的大型语言模型（LLMs）——提议者、验证者和报告者。提议者基于现有情况提出新的主张，然后验证者评估这些主张是否可以作为新的前提保留。最后，报告者决定是否是停止思考过程并给出答案的最佳时机。通过这种方式，CR能够以迭代和累积的方式模拟人类思维过程，从而有效地解决复杂问题。\n",
    "\n",
    "在每轮迭代中，Proposer借助预训练于相关推导任务的语言模型提出新声明。随后，Verifier评估提案，决定是否将其保留为新谓词。最终，Reporter在最佳时机决定是否停止思考并提供答案。理想情况下，Proposer可利用在特定推导任务上预训练的语言模型，而Verifier则将推导映射到适当的形式系统，并使用符号推理模块验证。然而，GPT-4或LLaMA等通用基础模型也可在这些角色中发挥作用，具体提示可有所不同。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"image/CR-2.png\" width=\"600\" alt=\"cot-example\"/>\n",
    "</div>\n",
    "\n",
    "这张图展示了GPT-4使用累积推理（Cumulative Reasoning，CR）来解决一个逻辑问题的过程。问题包括三个前提和一个假设，目标是判断这个假设是否正确。\n",
    "\n",
    "图中展示了两种推理方法：链式思考推理（Chain-of-Thought Reasoning）和累积推理。\n",
    "\n",
    "在这张图中，Cumulative Reasoning (CR) 通过两种不同的推理方法来解决同一个逻辑问题，展示了三个不同类型的语言模型（AI代理）的协同工作：\n",
    "\n",
    "**提议者(Proposer)**: 在\"Generated Propositions\"部分，提议者生成了两个命题：“GPT-3是一个性能良好的巨型语言模型”和“GPT-3被一些研究者使用”。这些命题是根据原始前提逻辑推导出的新信息，代表了提议者的作用，它提出新的可能性和观点供进一步讨论。\n",
    "\n",
    "**验证者(Verifier(s))**: 在\"Reasoning\"部分，验证者分析了提议者提出的命题，并结合已有的前提，进行了逻辑推理。在这个过程中，验证者确定了GPT-3作为一个被研究者使用的性能良好的语言模型，因此得出了GPT-3是流行的这一结论。验证者的角色是评估提议者的命题并根据原始前提进行论证。\n",
    "\n",
    "**报告者(Reporter)**: 在\"Prediction\"部分，报告者作出了最终判断。在此案例中，预测是“[True] (Correct)”，表明基于提议者和验证者的工作，报告者确认了问题的答案。报告者的决定基于前两者提供的信息，并确定何时结束推理过程并得出结论。\n",
    "\n",
    "图中展示的两种推理方法—由GPT-4进行的链式思考（Chain-of-Thought Reasoning）和累积推理—虽然结果不同，但都突显了语言模型如何以不同的角色协作解决问题。链式思考给出了未知的（错误）结果，而累积推理则正确预测了问题的答案，展示了CR在解决复杂问题时的有效性。\n",
    "\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"image/CR-3.png\" width=\"600\" alt=\"cot-example\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "**提议者(Proposer)**: 在解决问题的第一步，提议者可能会根据整数根定理提出潜在的整数根。\n",
    "\n",
    "**验证者(Verifier(s))**: 然后，验证者利用韦达公式（Vieta's formulas）来验证这些潜在根的合理性，并进一步缩小可能的根的范围。\n",
    "\n",
    "**报告者(Reporter)**: 最后，报告者基于前两者的工作，提出了最小的可能值为|a_n-1|，并通过代入特定的根来验证多项式的整数系数和整数根的条件，从而得出最终答案。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Self-Discover 自我发现](https://arxiv.org/pdf/2402.03620)\n",
    "- Pei Zhou, Jay Pujara, Xiang Ren, et al. SELF-DISCOVER: Large Language Models Self-Compose Reasoning Structures[J]. arXiv preprint arXiv:2402.03620, 2024.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Self-Discover解决的问题\n",
    "\n",
    "人们为了提高LLM对复杂问题的推理能力，提出COT的方法，模仿了人类逐步思考解决问题的过程，其基本思想是将复杂问题进行小型化拆分，同样基于这种思想的推理方法还有分解法（decomposition-based prompting）；此外，还从人类反思任务本质过程中受到启发，提出了退后法（step-back prompting）等方法。\n",
    "\n",
    "这些方法都能有效提升LLM的任务表现，我们可以将这些方法分别视为一种原子方法或原子推理模块。而我们对某个任务使用某种技术实际上对任务做出了一个隐含的先验假设，即“认为这个任务适合用这种方法来解决”。但不同方法其实都有更擅长和不擅长的领域。比如在解决涉及符号操作等问题时，分解法要优于CoT。\n",
    "\n",
    "所以研究人员希望，对于每个任务，都应该有独特的内在推理过程，同时还不提高模型的推理成本。\n",
    "\n",
    "#### Self-Discover方法流程\n",
    "\n",
    "Self-Discover是从人类如何利用先验知识和技能来设计推理程序来解决问题中汲取灵感，当人类面对一个新问题时，人类通常首先在内部寻找我们以前经验中的哪些知识和技能可能有助于解决它。然后，我们将尝试将相关知识和技能应用于此任务。最后，我们将连接多种个人技能和知识来解决问题。\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"image/Self-Discover-1.png\" width=\"800\" alt=\"Self-Discover\"/>\n",
    "</div>\n",
    "Self-Discover主要分为两阶段，第一阶段是根据任务构建出推理结构；第二阶段是使用第一阶段构建出的推理结构去完成推理过程。\n",
    "\n",
    "**第一阶段：自我发现特定的任务结构**\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"image/Self-Discover-2.png\" width=\"800\" alt=\"Self-Discover\"/>\n",
    "</div>\n",
    "\n",
    "给定一个任务描述和一组原子推理模块，让LLM根据任务实际，在原子推理模块中进行挑选、调整、组合，构造出一个可以解决特定任务的推理结构，这个阶段由三个动作组成：\n",
    "\n",
    "1）SELECT，从一组推理模块描述中选择适合用于解决给定任务的模块，例如，“反思性思维（reflective thinking）”可能有助于寻找关于科学问题的第一性原理理论，“创造性思维（creative thinking）”则有助于为故事生成新的延续。\n",
    "\n",
    "2）ADAPT，对选中的推理模块进行重新表述，使其更符合给定的任务。例如，对于算术问题，将“将问题分解为子问题（break the problems into sub-problems）”改写“按顺序计算每个算术运算（calculate each arithmetic operation in order）”。\n",
    "\n",
    "3）IMPLEMENT，将改编后的推理描述组装成一个结构化的可操作计划中（即Json格式的key-value对）\n",
    "\n",
    "**第二阶段：使用发现的结构来处理任务**\n",
    "\n",
    "在完成第一阶段后，得到了一个针对给定任务的推理结构，此时我们将其应用到任务数据上，即可借助LLM得到一个较好的结果。\n",
    "\n",
    "#### Self-Discover原子推理模块库\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"image/Self-Discover-3.png\" width=\"800\" alt=\"Self-Discover\"/>\n",
    "</div>\n",
    "\n",
    "#### Self-Discover示例\n",
    "\n",
    "以下是论文提供的[示例](https://github.com/catid/self-discover?tab=readme-ov-file)\n",
    "示例使用Miqu-70B模型，括号内容为教材注释。\n",
    "\n",
    "INPUT:\n",
    ">Lisa has 10 apples. She gives 3 apples to her friend and then buys 5 more apples from the store. How many >apples does Lisa have now?\n",
    ">\n",
    "(Lisa有10个苹果，她给了她的朋友3个，然后又从商店买了5个。请问Lisa现在有几个苹果？答案：12)\n",
    "\n",
    "OUTPUT:\n",
    ">(sd) ➜  self-discover git:(main) ✗ python self_discover.py\n",
    ">\n",
    ">**Stage 1 SELECT: Selected Modules**:(选择原子推理模块)\n",
    "> 9. How can I break down this problem into smaller, more manageable parts?（这里选择了原子推理模块库里的第9条，将问题进行小型化分解）\n",
    ">\n",
    ">The problem can be broken down into two parts: first, calculating how many apples Lisa has after giving some >away, and second, calculating how many apples she has after buying more. This approach simplifies the problem >and makes it easier to solve.（将问题分解成了两步，第一步是计算Lisa送出苹果后的剩余，第二步是计算购入苹果后的剩余）\n",
    ">\n",
    ">Additionally, 10. Critical Thinking: This style involves analyzing the problem from different perspectives, >questioning assumptions, and evaluating the evidence or information available. It focuses on logical >reasoning, evidence-based decision-making, and identifying potential biases or flaws in thinking.（还选择了第10条，批判性思维，这种风格包括从不同角度分析问题，质疑假设，并评估可用证据或信息。它侧重于逻辑推理、基于证据的决策制定，以及识别思维中潜在的偏见或缺陷。）\n",
    ">\n",
    ">Critical thinking is always relevant in problem-solving as it helps to ensure that the solution is based on >sound reasoning and evidence. In this case, it can help to confirm that the problem is being interpreted >correctly and that the solution is logical and accurate.（批判性思维在解决问题时总是相关的，因为它有助于确保解决方案基于健全的推理和证据。在这种情况下，它可以帮助确认问题的解释是正确的，并且解决方案是逻辑性和准确性的。）\n",
    ">\n",
    ">Therefore, both 9 and 10 are relevant reasoning modules for this problem.\n",
    ">\n",
    ">**Stage 1 ADAPT: Adapted Modules**:(适应性调整原子推理模块)\n",
    "> 1. Breaking down the problem:\n",
    ">The problem can be broken down into two smaller tasks:\n",
    ">\n",
    ">a) Calculate how many apples Lisa has after giving 3 to her friend.（要计算Lisa给朋友3个苹果后还剩多少个苹果）\n",
    ">b) Calculate how many apples Lisa has after buying 5 more apples from the store.（计算Lisa从商店买了5个苹果后有多少个苹果。）\n",
    ">\n",
    ">By breaking down the problem into these smaller tasks, it becomes easier to solve.\n",
    ">\n",
    ">2. Critical thinking:\n",
    ">Apply critical thinking to ensure that the problem is being interpreted correctly and that the solution is >logical and accurate. This involves:（应用批判性思维来确保问题的解释是正确的，并且解决方案是逻辑性和准确性的。这包括：）\n",
    ">\n",
    ">a) Confirming that the problem is understood correctly (Lisa starts with 10 apples, gives away 3, and buys 5 >more).（确认问题的理解是正确的）\n",
    ">b) Ensuring that the order of operations is followed correctly (subtracting the apples given away before >adding the apples bought).（确保遵循正确的操作顺序）\n",
    ">c) Double-checking the calculations to ensure accuracy.（再次检查计算以确保准确性）\n",
    ">\n",
    ">By applying critical thinking, you can be confident that the solution is based on sound reasoning and evidence.（通过应用批判性思维，您可以确信解决方案是基于健全的推理和证据）\n",
    ">\n",
    ">**Stage 1 IMPLEMENT: Reasoning Structure**:（组装成结构化的方法）\n",
    "> 1. Breaking down the problem:\n",
    ">\n",
    ">a) Calculate how many apples Lisa has after giving 3 to her friend:\n",
    ">- Lisa starts with 10 apples\n",
    ">- She gives away 3 apples\n",
    ">- Subtract the number of apples given away from the initial number of apples\n",
    ">\n",
    ">b) Calculate how many apples Lisa has after buying 5 more apples from the store:\n",
    ">- After giving away 3 apples, Lisa has a certain number of apples left (from task a)\n",
    ">- She then buys 5 more apples\n",
    ">- Add the number of apples bought to the remaining number of apples\n",
    ">\n",
    ">2. Critical thinking:\n",
    ">\n",
    ">a) Confirm that the problem is understood correctly:\n",
    ">- Lisa starts with 10 apples\n",
    ">- She gives 3 apples away\n",
    ">- She buys 5 more apples\n",
    ">\n",
    ">b) Ensure that the order of operations is followed correctly:\n",
    ">- First, subtract the apples given away\n",
    ">- Then, add the apples bought\n",
    ">\n",
    ">c) Double-check the calculations:\n",
    ">- Verify that the correct number of apples was subtracted\n",
    ">- Verify that the correct number of apples was added\n",
    ">\n",
    ">By following this reasoning structure, you can solve the problem by breaking it down into smaller tasks, applying critical thinking, and double-checking your calculations. The final answer should be accurate and based on sound reasoning.（通过遵循这种推理结构，您可以通过将问题分解为更小的任务、应用批判性思维以及再次检查您的计算来解决此问题。最终答案应该是准确且基于健全推理的）\n",
    ">\n",
    ">**Stage 2: Final Result**:（使用第一阶段生成的推理结构进行推理）\n",
    "> 1. Breaking down the problem:\n",
    ">\n",
    ">a) Calculate how many apples Lisa has after giving 3 to her friend:\n",
    ">- Lisa starts with 10 apples\n",
    ">- She gives away 3 apples\n",
    ">- Subtract the number of apples given away from the initial number of apples: 10 - 3 = 7 apples\n",
    ">\n",
    ">b) Calculate how many apples Lisa has after buying 5 more apples from the store:\n",
    ">- After giving away 3 apples, Lisa has 7 apples left (from task a)\n",
    ">- She then buys 5 more apples\n",
    ">- Add the number of apples bought to the remaining number of apples: 7 + 5 = 12 apples\n",
    ">\n",
    ">2. Critical thinking:\n",
    ">\n",
    ">a) Confirm that the problem is understood correctly:\n",
    ">- Lisa starts with 10 apples\n",
    ">- She gives 3 apples away\n",
    ">- She buys 5 more apples\n",
    ">\n",
    ">b) Ensure that the order of operations is followed correctly:\n",
    ">- First, subtract the apples given away (10 - 3)\n",
    ">- Then, add the apples bought (7 + 5)\n",
    ">\n",
    ">c) Double-check the calculations:\n",
    ">- Verify that the correct number of apples was subtracted (10 - 3 = 7)\n",
    ">- Verify that the correct number of apples was added (7 + 5 = 12)\n",
    ">\n",
    ">Final answer: Lisa has 12 apples now.\n",
    "\n",
    "#### Self-Discover的prompt details\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"image/Self-Discover-4.png\" width=\"800\" alt=\"Self-Discover\"/>\n",
    "</div>\n",
    "我们看到，在第一阶段中，除了从原子推理模块库中进行选择外，还可以引入任务示例，从而使整个自我发现过程更加灵活。\n",
    "\n",
    "#### Self-Discover代码示例\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "import openai\n",
    "import os\n",
    "import time\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client=OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "            base_url=os.getenv(\"OPENAI_API_BASE\")\n",
    ")\n",
    "\n",
    "def query_llm(messages, max_tokens=2048, temperature=0.1):\n",
    "    # 持续重试\n",
    "    while True:\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4\",#使用GPT4\n",
    "                messages=messages,\n",
    "                temperature=temperature,\n",
    "                max_tokens=max_tokens,\n",
    "                n=1,\n",
    "            )\n",
    "\n",
    "            content = response.choices[0].message.content.strip()\n",
    "\n",
    "            return content\n",
    "        except Exception as e:\n",
    "            print(\"Failure querying the AI. Retrying...\")\n",
    "            time.sleep(1)\n",
    "\n",
    "def query_openai(prompt):\n",
    "    messages = [\n",
    "        { \"role\": \"user\", \"content\": prompt }\n",
    "    ]\n",
    "    return query_llm(messages)\n",
    "\n",
    "# STAGE 1\n",
    "\n",
    "def select_reasoning_modules(task_description, reasoning_modules):\n",
    "    \"\"\"\n",
    "    Step 1: SELECT relevant reasoning modules for the task.\n",
    "    \"\"\"\n",
    "    prompt = f\"Given the task: {task_description}, which of the following reasoning modules are relevant? Do not elaborate on why.\\n\\n\" + \"\\n\".join(reasoning_modules)\n",
    "    selected_modules = query_openai(prompt)\n",
    "    return selected_modules\n",
    "\n",
    "def adapt_reasoning_modules(selected_modules, task_example):\n",
    "    \"\"\"\n",
    "    Step 2: ADAPT the selected reasoning modules to be more specific to the task.\n",
    "    \"\"\"\n",
    "    prompt = f\"Without working out the full solution, adapt the following reasoning modules to be specific to our task:\\n{selected_modules}\\n\\nOur task:\\n{task_example}\"\n",
    "    adapted_modules = query_openai(prompt)\n",
    "    return adapted_modules\n",
    "\n",
    "def implement_reasoning_structure(adapted_modules, task_description):\n",
    "    \"\"\"\n",
    "    Step 3: IMPLEMENT the adapted reasoning modules into an actionable reasoning structure.\n",
    "    \"\"\"\n",
    "    prompt = f\"Without working out the full solution, create an actionable reasoning structure for the task using these adapted reasoning modules:\\n{adapted_modules}\\n\\nTask Description:\\n{task_description}\"\n",
    "    reasoning_structure = query_openai(prompt)\n",
    "    return reasoning_structure\n",
    "\n",
    "# STAGE 2\n",
    "\n",
    "def execute_reasoning_structure(reasoning_structure, task_instance):\n",
    "    \"\"\"\n",
    "    Execute the reasoning structure to solve a specific task instance.\n",
    "    \"\"\"\n",
    "    prompt = f\"Using the following reasoning structure: {reasoning_structure}\\n\\nSolve this task, providing your final answer: {task_instance}\"\n",
    "    solution = query_openai(prompt)\n",
    "    return solution\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    #以下注释掉的是官方代码中原本就注释的\n",
    "    reasoning_modules = [\n",
    "        \"1. How could I devise an experiment to help solve that problem?\",\n",
    "        \"2. Make a list of ideas for solving this problem, and apply them one by one to the problem to see if any progress can be made.\",\n",
    "        #\"3. How could I measure progress on this problem?\",\n",
    "        \"4. How can I simplify the problem so that it is easier to solve?\",\n",
    "        \"5. What are the key assumptions underlying this problem?\",\n",
    "        \"6. What are the potential risks and drawbacks of each solution?\",\n",
    "        \"7. What are the alternative perspectives or viewpoints on this problem?\",\n",
    "        \"8. What are the long-term implications of this problem and its solutions?\",\n",
    "        \"9. How can I break down this problem into smaller, more manageable parts?\",\n",
    "        \"10. Critical Thinking: This style involves analyzing the problem from different perspectives, questioning assumptions, and evaluating the evidence or information available. It focuses on logical reasoning, evidence-based decision-making, and identifying potential biases or flaws in thinking.\",\n",
    "        \"11. Try creative thinking, generate innovative and out-of-the-box ideas to solve the problem. Explore unconventional solutions, thinking beyond traditional boundaries, and encouraging imagination and originality.\",\n",
    "        #\"12. Seek input and collaboration from others to solve the problem. Emphasize teamwork, open communication, and leveraging the diverse perspectives and expertise of a group to come up with effective solutions.\",\n",
    "        \"13. Use systems thinking: Consider the problem as part of a larger system and understanding the interconnectedness of various elements. Focuses on identifying the underlying causes, feedback loops, and interdependencies that influence the problem, and developing holistic solutions that address the system as a whole.\",\n",
    "        \"14. Use Risk Analysis: Evaluate potential risks, uncertainties, and tradeoffs associated with different solutions or approaches to a problem. Emphasize assessing the potential consequences and likelihood of success or failure, and making informed decisions based on a balanced analysis of risks and benefits.\",\n",
    "        #\"15. Use Reflective Thinking: Step back from the problem, take the time for introspection and self-reflection. Examine personal biases, assumptions, and mental models that may influence problem-solving, and being open to learning from past experiences to improve future approaches.\",\n",
    "        \"16. What is the core issue or problem that needs to be addressed?\",\n",
    "        \"17. What are the underlying causes or factors contributing to the problem?\",\n",
    "        \"18. Are there any potential solutions or strategies that have been tried before? If yes, what were the outcomes and lessons learned?\",\n",
    "        \"19. What are the potential obstacles or challenges that might arise in solving this problem?\",\n",
    "        \"20. Are there any relevant data or information that can provide insights into the problem? If yes, what data sources are available, and how can they be analyzed?\",\n",
    "        \"21. Are there any stakeholders or individuals who are directly affected by the problem? What are their perspectives and needs?\",\n",
    "        \"22. What resources (financial, human, technological, etc.) are needed to tackle the problem effectively?\",\n",
    "        \"23. How can progress or success in solving the problem be measured or evaluated?\",\n",
    "        \"24. What indicators or metrics can be used?\",\n",
    "        \"25. Is the problem a technical or practical one that requires a specific expertise or skill set? Or is it more of a conceptual or theoretical problem?\",\n",
    "        \"26. Does the problem involve a physical constraint, such as limited resources, infrastructure, or space?\",\n",
    "        \"27. Is the problem related to human behavior, such as a social, cultural, or psychological issue?\",\n",
    "        \"28. Does the problem involve decision-making or planning, where choices need to be made under uncertainty or with competing objectives?\",\n",
    "        \"29. Is the problem an analytical one that requires data analysis, modeling, or optimization techniques?\",\n",
    "        \"30. Is the problem a design challenge that requires creative solutions and innovation?\",\n",
    "        \"31. Does the problem require addressing systemic or structural issues rather than just individual instances?\",\n",
    "        \"32. Is the problem time-sensitive or urgent, requiring immediate attention and action?\",\n",
    "        \"33. What kinds of solution typically are produced for this kind of problem specification?\",\n",
    "        \"34. Given the problem specification and the current best solution, have a guess about other possible solutions.\"\n",
    "        \"35. Let’s imagine the current best solution is totally wrong, what other ways are there to think about the problem specification?\"\n",
    "        \"36. What is the best way to modify this current best solution, given what you know about these kinds of problem specification?\"\n",
    "        \"37. Ignoring the current best solution, create an entirely new solution to the problem.\"\n",
    "        #\"38. Let’s think step by step.\"\n",
    "        \"39. Let’s make a step by step plan and implement it with good notation and explanation.\"\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "task_example = \"Lisa has 10 apples. She gives 3 apples to her friend and then buys 5 more apples from the store. How many apples does Lisa have now?\"\n",
    "\n",
    "selected_modules = select_reasoning_modules(task_example, reasoning_modules)\n",
    "print(\"Stage 1 SELECT: Selected Modules:\\n\", selected_modules)\n",
    "    \n",
    "adapted_modules = adapt_reasoning_modules(selected_modules, task_example)\n",
    "print(\"\\nStage 1 ADAPT: Adapted Modules:\\n\", adapted_modules)\n",
    "    \n",
    "reasoning_structure = implement_reasoning_structure(adapted_modules, task_example)\n",
    "print(\"\\nStage 1 IMPLEMENT: Reasoning Structure:\\n\", reasoning_structure)\n",
    "\n",
    "result = execute_reasoning_structure(reasoning_structure, task_example)\n",
    "print(\"\\nStage 2: Final Result:\\n\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Chain of Thought\n",
    "- Bowen Jin, Chulin Xie, Jiawei Zhang, et al. Graph Chain-of-Thought: Augmenting Large Language Models by Reasoning on Graphs[j]. arXiv preprint arXiv:2404.07103, 2024."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph Chain of Thought解决的问题\n",
    "\n",
    "大模型(LLMs)虽然表现出色,但由于学习到的知识主要以参数化的形式存储在模型内部,它们容易产生幻觉,生成看似合理但实际上与事实不符的内容。为了缓解这一问题,现有工作提出利用外部文本语料作为知识来源来增强LLMs。然而,在现实场景中,文本单元通常是相互关联的,本质是一个具有文本属性的图。知识不仅蕴含在文本内容中,还体现在节点间的连接结构里。\n",
    "\n",
    "例如:\n",
    "\n",
    "在文献图中,论文通过引用相互链接。通过遍历这种图,我们可以追踪特定研究方向发展脉络。\n",
    "\n",
    "在法律图谱中,案例和意见通过边相关联。通过查找案例在图谱上的引用情况,可以验证相应判决的依据。\n",
    "\n",
    "人们在利用图信息时，有时也采用提取局部子图，并转为文字描述的方式，以上下文的形式加入Prompt，来获取结点间的关联信息，但当图的规模增大时，局部子图的规模会呈指数级增长，导致上下文过于冗长。既容易让LLM在过长的信息中迷失，也容易超过LLM的输入长度限制。\n",
    "\n",
    "Graph Chain of Thought的提出就是希望能有效利用图信息来增强LLM。\n",
    "\n",
    "#### Graph Chain of Thought流程\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"image/Graph-COT-1.png\"width=\"800\" alt=\"Graph-COT\"/>\n",
    "</div>\n",
    "\n",
    "Graph Chain-of-Thought (Graph-CoT)是一种图推理框架，主要针对使用图谱作为外部知识来增强LLMs的问题。其核心思想是引导LLMs逐步遍历图谱,找出问题所需的关键信息,而非一次性将整个子图作为上下文输入到LLMs中。\n",
    "\n",
    "Graph-CoT采用迭代的方式进行推理,每轮迭代对应图上的一个探索步骤,由以下三个子步骤组成:\n",
    "\n",
    "推理(Reasoning):LLMs根据当前掌握的信息得出初步结论,并分析还需从图中获取哪些进一步的信息。\n",
    "\n",
    "交互(Interaction):LLMs生成与图交互所需的操作指令(例如查找特定节点,检查相邻节点等),以获取所需信息。\n",
    "\n",
    "执行(Execution):图谱根据交互步骤中的指令执行相应操作,返回查询到的信息。\n",
    "\n",
    "通过这种迭代推理的方式,LLMs可以在图谱上进行链式探索,找到问题所需的关键信息。这一过程会持续进行,直到LLMs在推理阶段得出最终答案。这种方式也可以连接到LLM agent中。\n",
    "\n",
    "#### Graph Chain of Thought示例\n",
    "\n",
    "下面通过三个生物医学领域的示例，展示Graph Chain of Thought的工作过程，示例来自[论文github](https://github.com/PeterGriffinJin/Graph-CoT/blob/main/Graph-CoT/code/graph_fewshots.py)，括号内为教材注解\n",
    "\n",
    "**示例1**：\n",
    "\n",
    ">**Definition of the graph**: There are eleven types of nodes in the graph: Anatomy, Biological Process, Cellular Component, Compound, Disease, Gene, Molecular Function, Pathway, Pharmacologic Class, Side Effect, Symptom.\n",
    ">\n",
    ">Each node has name feature.\n",
    ">\n",
    ">There are these types of edges: Anatomy-downregulates-Gene, Anatomy-expresses-Gene, Anatomy-upregulates-Gene, Compound-binds-Gene, Compound-causes-Side Effect, Compound-downregulates-Gene, Compound-palliates-Disease, Compound-resembles-Compound, Compound-treats-Disease, Compound-upregulates-Gene, Disease-associates-Gene, Disease-downregulates-Gene, Disease-localizes-Anatomy, Disease-presents-Symptom, Disease-resembles-Disease, Disease-upregulates-Gene, Gene-covaries-Gene, Gene-interacts-Gene, Gene-participates-Biological Process, Gene-participates-Cellular Component, Gene-participates-Molecular Function, Gene-participates-Pathway, Gene-regulates-Gene, Pharmacologic Class-includes-Compound.\n",
    ">\n",
    ">（图中包含十一种类型的节点：解剖学、生物学过程、细胞成分、化合物、疾病、基因、分子功能、通路、药理学类别、副作用、症状。\n",
    ">\n",
    ">每个节点都有名称特征。\n",
    ">\n",
    ">存在以下类型的边：解剖学-下调-基因、解剖学-表达-基因、解剖学-上调-基因、化合物-结合-基因、化合物-导致-副作用、化合物-下调-基因、化合物-缓解-疾病、化合物-相似-化合物、化合物-治疗-疾病、化合物-上调-基因、疾病-关联-基因、疾病-下调-基因、疾病-定位-解剖学、疾病-呈现-症状、疾病-相似-疾病、疾病-上调-基因、基因-共变-基因、基因-相互作用-基因、基因-参与-生物学过程、基因-参与-细胞成分、基因-参与-分子功能、基因-参与-通路、基因-调控-基因、药理学类别-包含-化合物。）\n",
    ">\n",
    ">**Question**: What compounds can be used to treat Crohn's disease? Please answer the compound names rather than IDs.（可以用来治疗克罗恩病的化合物有哪些？请回答化合物名称，而不是ID。）\n",
    ">\n",
    ">**Thought 1**: The question is related to a disease node (Crohn's disease). We need to find the node in the graph.（这个问题与一个疾病节点（克罗恩病）相关。我们需要在图中找到这个节点。）\n",
    ">\n",
    ">**Action 1**: RetrieveNode[Crohn's disease]（检索节点[克罗恩病]）\n",
    ">\n",
    ">**Observation 1**: The ID of this node is DOID:8778.（这个节点的ID是DOID:8778。）\n",
    ">\n",
    ">**Thought 2**: The question is asking the compounds which can be used to treat a disease, we need to check the node's 'Compound-treats-Disease' neighbor from the graph.（问题询问的是可以用来治疗一种疾病的化合物，我们需要从图中检查节点的“化合物-治疗-疾病”邻近点。）\n",
    ">\n",
    ">**Action 2**: NeighbourCheck[DOID:8778, Compound-treats-Disease]（邻接点检查[DOID:8778, 化合物-治疗-疾病]）\n",
    ">\n",
    ">**Observation 2**: ['DB01014', 'DB00244', 'DB00795', 'DB00993', 'DB00635', 'DB01033']（得到几个邻接节点的ID）\n",
    ">\n",
    ">**Thought 3**: The IDs of the compounds are 'DB01014', 'DB00244', 'DB00795', 'DB00993', 'DB00635', 'DB01033'. We need to get their names.（这些化合物的ID是’DB01014’、‘DB00244’、‘DB00795’、‘DB00993’、‘DB00635’、‘DB01033’。我们需要获取它们的名称。）\n",
    ">\n",
    ">**Action 3**: NodeFeature[DB01014, name], NodeFeature[DB00244, name], NodeFeature[DB00795, name], NodeFeature[DB00993, name], NodeFeature[DB00635, name], NodeFeature[DB01033, name]（此操作，获取ID对应的名称）\n",
    ">\n",
    ">**Observation 3**: Balsalazide, Balsalazide, Mesalazine, Sulfasalazine, Azathioprine, Prednisone, Mercaptopurine（美沙拉秦、美沙拉秦、柳氮磺吡啶、硫唑嘌呤、泼尼松、巯嘌呤，一些药名，机翻不一定全对）\n",
    ">\n",
    ">**Thought 4**: The name of compounds are Balsalazide, Mesalazine, Sulfasalazine, Azathioprine, Prednisone, Mercaptopurine.（这些化合物的名称是：Balsalazide（巴沙拉嗪）、Mesalazine（美沙拉秦）、Sulfasalazine（柳氮磺吡啶）、Azathioprine（硫唑嘌呤）、Prednisone（泼尼松）、Mercaptopurine（巯嘌呤）。）\n",
    ">\n",
    ">**Action 4**: Finish[Balsalazide, Mesalazine, Sulfasalazine, Azathioprine, Prednisone, Mercaptopurine]（完成，输出）\n",
    "\n",
    "**示例2**：\n",
    "\n",
    ">**Definition of the graph**: There are eleven types of nodes in the graph: Anatomy, Biological Process, Cellular Component, Compound, Disease, Gene, Molecular Function, Pathway, Pharmacologic Class, Side Effect, Symptom.\n",
    ">Each node has name feature.\n",
    ">There are these types of edges: Anatomy-downregulates-Gene, Anatomy-expresses-Gene, Anatomy-upregulates-Gene, Compound-binds-Gene, Compound-causes-Side Effect, Compound-downregulates-Gene, Compound-palliates-Disease, Compound-resembles-Compound, Compound-treats-Disease, Compound-upregulates-Gene, Disease-associates-Gene, Disease-downregulates-Gene, Disease-localizes-Anatomy, Disease-presents-Symptom, Disease-resembles-Disease, Disease-upregulates-Gene, Gene-covaries-Gene, Gene-interacts-Gene, Gene-participates-Biological Process, Gene-participates-Cellular Component, Gene-participates-Molecular Function, Gene-participates-Pathway, Gene-regulates-Gene, Pharmacologic Class-includes-Compound.\n",
    ">\n",
    ">**Question**: What is the inchikey of Caffeine?（咖啡因的InChIKey是什么？注：InChIKey是指一种编码）\n",
    ">\n",
    ">**Thought 1**: The question is related to a compound node (Caffeine). We need to find the node in the graph.（需要找到Caffeine这个节点）\n",
    ">**Action 1**: RetrieveNode[Caffeine]（找节点的动作）\n",
    ">\n",
    ">**Observation 1**: The ID of this node is DB00201.（找到节点了，获得ID）\n",
    ">\n",
    ">**Thought 2**: The question is asking the inchikey feature of a node, we need to check the node's 'inchikey' feature from the graph.（跟据找到的结点去check结点的inchikey）\n",
    ">\n",
    ">**Action 2**: NodeFeature[DB00201, inchikey]（获取inchikey的操作）\n",
    ">\n",
    ">**Observation 2**: InChIKey=RYYVLZVUVIJVGH-UHFFFAOYSA-N（得到inchikey）\n",
    ">\n",
    ">**Thought 3**: The inchikey of the node is InChIKey=RYYVLZVUVIJVGH-UHFFFAOYSA-N.（确认就是要找的inchikey）\n",
    ">\n",
    ">**Action 3**: Finish[InChIKey=RYYVLZVUVIJVGH-UHFFFAOYSA-N]（完成，输出）\n",
    "\n",
    "**示例3**：\n",
    "\n",
    ">**Definition of the graph**: There are eleven types of nodes in the graph: Anatomy, Biological Process, Cellular Component, Compound, Disease, Gene, Molecular Function, Pathway, Pharmacologic Class, Side Effect, Symptom.\n",
    ">Each node has name feature.\n",
    ">There are these types of edges: Anatomy-downregulates-Gene, Anatomy-expresses-Gene, Anatomy-upregulates-Gene, Compound-binds-Gene, Compound-causes-Side Effect, Compound-downregulates-Gene, Compound-palliates-Disease, Compound-resembles-Compound, Compound-treats-Disease, Compound-upregulates-Gene, Disease-associates-Gene, Disease-downregulates-Gene, Disease-localizes-Anatomy, Disease-presents-Symptom, Disease-resembles-Disease, Disease-upregulates-Gene, Gene-covaries-Gene, Gene-interacts-Gene, Gene-participates-Biological Process, Gene-participates-Cellular Component, Gene-participates-Molecular Function, Gene-participates-Pathway, Gene-regulates-Gene, Pharmacologic Class-includes-Compound.\n",
    ">\n",
    ">**Question**: How many side effects does Caffeine have?（咖啡因有多少副作用？）\n",
    ">\n",
    ">**Thought 1**: The question is related to a compound node (Caffeine). We need to find the node in the graph.（\n",
    "这个问题与一个化合物节点（咖啡因）相关。我们需要在图中找到这个节点。）\n",
    ">\n",
    ">**Action 1**: RetrieveNode[Caffeine]\n",
    ">\n",
    ">**Observation 1**: The ID of this node is DB00201.\n",
    ">\n",
    ">**Thought 2**: The question is asking the number of side effects a compound has, we need to calculate the number of the node's 'Compound-causes-Side Effect' neighbors from the graph.（问题询问的是一个化合物有多少副作用，我们需要从图中计算节点的“化合物-导致-副作用”邻接点的数量。）\n",
    ">\n",
    ">**Action 2**: NodeDegree[DB00201, 'Compound-causes-Side Effect']\n",
    ">\n",
    ">**Observation 2**: 58\n",
    ">\n",
    ">**Thought 3**: The number of 'Compound-causes-Side Effect' neighbors are 58.\n",
    ">\n",
    ">**Action 3**: Finish[58]\n",
    "\n",
    "#### Graph Chain of Thought好处\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"image/Graph-COT-2.png\"width=\"800\" alt=\"Graph-COT\"/>\n",
    "</div>\n",
    "\n",
    "通在GRBench上的测试可以看出，Graph-COT在全部5个领域，都明显高于直接LLM推理、Text RAG推理以及Graph RAG推理。\n",
    "\n",
    "#### Graph Chain of Thought实现（核心代码展示）\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "class GraphAgent:\n",
    "    def __init__(self,\n",
    "                 args,\n",
    "                 agent_prompt,\n",
    "                 ) -> None:\n",
    "\n",
    "        self.max_steps = args.max_steps#最大步数\n",
    "        self.agent_prompt = agent_prompt#使用Langchain定义的agent,可以区分是否使用few_shot，在主程序中设置\n",
    "        self.examples = EXAMPLES[args.ref_dataset]#EXAMPLES是预先定义好的几类few_shot\n",
    "\n",
    "        self.llm_version = args.llm_version#llm_version区分不同的大模型，gpt系或本地部署的模型\n",
    "        if args.llm_version in ['gpt-3.5-turbo', 'gpt-4', 'gpt-3.5-turbo-1106', 'gpt-3.5-turbo-16k']:\n",
    "            self.llm = ChatOpenAI(temperature=0,\n",
    "                                max_tokens=300,\n",
    "                                model_name=args.llm_version,\n",
    "                                model_kwargs={\"stop\": \"\\n\"},\n",
    "                                )\n",
    "            self.enc = tiktoken.encoding_for_model(\"text-davinci-003\")\n",
    "        elif args.llm_version in [\"meta-llama/Llama-2-13b-chat-hf\", \"mistralai/Mixtral-8x7B-Instruct-v0.1\"]:\n",
    "            self.config = AutoConfig.from_pretrained(args.llm_version, use_auth_token=True)\n",
    "            self.enc = AutoTokenizer.from_pretrained(args.llm_version, use_auth_token=True)\n",
    "            self.llm = pipeline(\n",
    "                \"text-generation\",\n",
    "                model=args.llm_version,\n",
    "                torch_dtype=torch.float16,\n",
    "                device_map=\"auto\"\n",
    "    )\n",
    "        else:\n",
    "            raise ValueError(\"The given llm_version is not correct.\")\n",
    "\n",
    "        self.graph_definition = GRAPH_DEFINITION[args.dataset]#图的定义性描述，模板中的一个变量\n",
    "        self.load_graph(args.graph_dir)#引入图加载函数\n",
    "        self.graph_funcs = graph_funcs.graph_funcs(self.graph)#引入图操作函数\n",
    "        self.node_retriever = retriever.Retriever(args, self.graph)#引入检索器\n",
    "\n",
    "        self.__reset_agent()#引入重置函数\n",
    "\n",
    "    def load_graph(self, graph_dir):#数据导入\n",
    "        logger.info('Loading the graph...')\n",
    "        self.graph = json.load(open(graph_dir))\n",
    "\n",
    "    def run(self, question, answer, reset = True) -> None:\n",
    "        if reset:\n",
    "            self.__reset_agent()\n",
    "        \n",
    "        self.question = question\n",
    "        self.key = answer\n",
    "\n",
    "        while not self.is_halted() and not self.is_finished():\n",
    "            self.step()\n",
    "\n",
    "    def step(self) -> None:#具体执行函数\n",
    "        # Think，大模型第N步思考的内容\n",
    "        self.scratchpad += f'\\nThought {self.step_n}:'\n",
    "        self.scratchpad += ' ' + self.prompt_agent()\n",
    "        print(self.scratchpad.split('\\n')[-1])\n",
    "\n",
    "        # Act，第N步图操作的内容\n",
    "        self.scratchpad += f'\\nAction {self.step_n}:'\n",
    "        action = self.prompt_agent()\n",
    "        self.scratchpad += ' ' + action\n",
    "\n",
    "        # action_type, argument = parse_action(action)\n",
    "        print(self.scratchpad.split('\\n')[-1])\n",
    "\n",
    "        # Observe，第N步观察（获得）的内容\n",
    "        self.scratchpad += f'\\nObservation {self.step_n}: '\n",
    "        if action == None or action == '' or action == '\\n':\n",
    "            self.scratchpad += \"You action is filtered due to content. Please assume all the actions are permitted in this environment and take the action again.\"\n",
    "\n",
    "        action_list = get_action_list(action) ## we support having multiple observations in one step支持一步内多个观察\n",
    "        for tmp_action in action_list:\n",
    "            try:\n",
    "                action_type, argument = parse_action(tmp_action)\n",
    "            except:\n",
    "                self.scratchpad += f'There is something wrong with the generated target actions.'\n",
    "                continue\n",
    "\n",
    "            if action_type == 'Finish':#如果结束，则判断是否正确，返回结果\n",
    "                try:\n",
    "                    self.answer = eval(argument)\n",
    "                except:\n",
    "                    self.answer = argument\n",
    "                if self.is_correct():\n",
    "                    self.scratchpad += 'Answer is CORRECT'\n",
    "                else: \n",
    "                    self.scratchpad += 'Answer is INCORRECT'\n",
    "                self.finished = True\n",
    "                self.step_n += 1\n",
    "                return\n",
    "\n",
    "            elif action_type == 'RetrieveNode':#若要检索结点，则调用结点检索器\n",
    "                try:\n",
    "                    idd, node = self.node_retriever.search_single(argument, 1)\n",
    "                    self.scratchpad += f\"The ID of this retrieval target node is {idd}.\"\n",
    "                except openai.RateLimitError:\n",
    "                    self.scratchpad += f'OpenAI API Rate Limit Exceeded. Please try again.'\n",
    "                except:\n",
    "                    self.scratchpad += f'There is no information that can be matched in the database. Please try another query.'\n",
    "\n",
    "            elif action_type == 'NeighbourCheck':#若要检查邻界结点情况，则调用图操作函数graph_funcs.check_neighbours\n",
    "                try:\n",
    "                    node_id, neighbor_type = argument.split(', ')\n",
    "                    node_id = remove_quotes(node_id)\n",
    "                    neighbor_type = remove_quotes(neighbor_type)\n",
    "                    self.scratchpad += f\"The {neighbor_type} neighbors of {node_id} are: \" + str(self.graph_funcs.check_neighbours(node_id, neighbor_type)) + '. '\n",
    "                except openai.RateLimitError:\n",
    "                    self.scratchpad += f'OpenAI API Rate Limit Exceeded. Please try again.'\n",
    "                except KeyError:\n",
    "                    self.scratchpad += f'The node or neighbor type does not exist in the graph. This might because your given neighbor type is not correct. Please modify it.'\n",
    "                except:\n",
    "                    self.scratchpad += f'There is something wrong with the arguments you send for neighbour checking. Please modify it. Make sure that NeighbourCheck take two value as input: node id and neighbor type.'\n",
    "            \n",
    "            elif action_type == 'NodeFeature':#若要检查结点特征（参数），则调用图操作函数graph_funcs.check_nodes\n",
    "                try:\n",
    "                    node_id, feature_name = argument.split(', ')\n",
    "                    node_id = remove_quotes(node_id)\n",
    "                    feature_name = remove_quotes(feature_name)\n",
    "                    self.scratchpad += f\"The {feature_name} feature of {node_id} are: \" + self.graph_funcs.check_nodes(node_id, feature_name) + '. '\n",
    "                except openai.RateLimitError:\n",
    "                    self.scratchpad += f'OpenAI API Rate Limit Exceeded. Please try again.'\n",
    "                except KeyError:\n",
    "                    self.scratchpad += f'The node or feature name does not exist in the graph. This might because your given feature name is not correct. Please modify it.'\n",
    "                except:\n",
    "                    self.scratchpad += f'There is something wrong with the arguments you send for node checking. Please modify it. Make sure that NodeFeature take two value as input: node id and feature name.'\n",
    "\n",
    "            elif action_type == 'NodeDegree':#若要检查结点的度，则调用图操作函数graph_funcs.check_degree\n",
    "                try:\n",
    "                    node_id, neighbor_type = argument.split(', ')\n",
    "                    node_id = remove_quotes(node_id)\n",
    "                    neighbor_type = remove_quotes(neighbor_type)\n",
    "                    self.scratchpad += f\"The {neighbor_type} neighbor node degree of {node_id} are: \" + self.graph_funcs.check_degree(node_id, neighbor_type) + '. '\n",
    "                except openai.RateLimitError:\n",
    "                    self.scratchpad += f'OpenAI API Rate Limit Exceeded. Please try again.'\n",
    "                except KeyError:\n",
    "                    self.scratchpad += f'The node or neighbor type does not exist in the graph. This might because your given neighbor type is not correct. Please modify it.'\n",
    "                except:\n",
    "                    self.scratchpad += f'There is something wrong with the arguments you send for degree checking. Please modify it. Make sure that NodeDegree take two value as input: node id and neighbor type.'\n",
    "\n",
    "            else:\n",
    "                self.scratchpad += 'Invalid Action. Valid Actions are RetrieveNode[<Content>] NeighbourCheck[<Node>] NodeFeature[<Node>] and Finish[<answer>].'\n",
    "\n",
    "        print(self.scratchpad.split('\\n')[-1])\n",
    "\n",
    "        self.step_n += 1\n",
    "\n",
    "    def prompt_agent(self) -> str:\n",
    "        if self.llm_version in ['gpt-3.5-turbo', 'gpt-4', 'gpt-3.5-turbo-1106', 'gpt-3.5-turbo-16k']:\n",
    "            return gpt_format_step(self.llm(self._build_agent_prompt()))\n",
    "        elif self.llm_version in [\"meta-llama/Llama-2-13b-chat-hf\", \"mistralai/Mixtral-8x7B-Instruct-v0.1\"]:\n",
    "            return hf_format_step(\n",
    "                self.llm(self._build_agent_prompt()[1].content,\n",
    "                do_sample=True,\n",
    "                top_k=10,\n",
    "                num_return_sequences=1,\n",
    "                eos_token_id=13, # \\n for llama2 and mixtral\n",
    "                max_length=self.config.max_position_embeddings)\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"The given llm_version is not correct.\")\n",
    "\n",
    "        return format_step(self.llm(self._build_agent_prompt()))\n",
    "\n",
    "    def _build_agent_prompt(self) -> str:\n",
    "        return self.agent_prompt.format_messages(\n",
    "                            examples = self.examples,\n",
    "                            question = self.question,\n",
    "                            scratchpad = self.scratchpad,\n",
    "                            graph_definition = self.graph_definition\n",
    "                            )\n",
    "\n",
    "    def is_finished(self) -> bool:\n",
    "        return self.finished\n",
    "\n",
    "    def is_correct(self) -> bool:\n",
    "        return EM(self.answer, self.key)\n",
    "\n",
    "    def is_halted(self) -> bool:\n",
    "        # return ((self.step_n > self.max_steps) or (len(self.enc.encode(self._build_agent_prompt())) > 3896)) and not self.finished\n",
    "        return ((self.step_n > self.max_steps) or (len(self.enc.encode(self._build_agent_prompt()[1].content)) > 10000)) and not self.finished\n",
    "\n",
    "    def __reset_agent(self) -> None:\n",
    "        self.step_n = 1\n",
    "        self.answer = ''\n",
    "        self.finished = False\n",
    "        self.scratchpad: str = ''\n",
    "\n",
    "    def set_qa(self, question: str, key: str) -> None:\n",
    "        self.question = question\n",
    "        self.key = key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 技术总结\n",
    "**一、什么是思维链**\n",
    "\n",
    "**二、思维链体系**\n",
    "- 思维链自一致性：在COT推理过程中，模型可能产生逻辑上不连贯或自相矛盾的推理步骤，这会降低答案的准确性和可信度。\n",
    "- 思维链自纠正：由于COT推理涉及多步骤的逻辑链条，每一步的错误都可能导致最终结论的错误，累积误差可能导致答案完全偏离正确路径。\n",
    "- 自动化思维链提示：手动引导思维方式人力资源消耗大，推理链多样性有限。\n",
    "- Least to Most：模型在进行COT推理时，可能因为推理深度或广度的限制而无法完全探索问题的所有方面，导致遗漏关键信息。\n",
    "\n",
    "**三、思维链变种**\n",
    "- ToT：CoT思考链路单一\n",
    "- GoT：ToT搜索路径过于冗杂\n",
    "- SoT：端到端的生成延迟过长\n",
    "- AoT：ToT,GoT均需要创建大量的节点完成任务，占用资源过多，回答延迟长\n",
    "- XoT：ToT,GoT均需要创建大量的节点完成任务，占用资源过多，回答延迟长 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实际应用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. o1介绍\n",
    "\n",
    "#### 1.1 OpenAI o1\n",
    "\n",
    "OpenAI在2024年推出了o1模型，这款模型以其卓越的推理能力引起了广泛关注。它在多个平台上的表现，如AIME（人工智能数学竞赛）和CodeForces（编程竞赛），超越了其他领先的模型。o1模型通过强化学习技术来增强其推理能力，使其能够应对复杂、现实世界的挑战。特别地，o1模型采用了Chain-of-Thought (CoT) 精调方法，这种方法允许模型在生成答案前进行内部思考，从而提高回答的质量和准确性。此外，o1还利用了Monte Carlo Tree Search (MCTS) 和新颖的推理策略，以进一步优化其解决复杂问题的能力。这些特性使得o1不仅能够在标准答案明确的学科中表现出色，如数学、物理和编程，而且在没有明确标准或奖励难以量化的更广泛领域中也展现出了潜力。\n",
    "\n",
    "#### 1.2 Marco o1\n",
    "\n",
    "Marco-o1是由阿里巴巴国际数字商务团队开发的一个项目，灵感来源于OpenAI的o1模型，并在其基础上进行了扩展和改进。Marco-o1旨在探索大型推理模型（LRM）的技术路线图，特别是针对开放性问题解决方案。与传统的专注于有标准答案领域的模型不同，Marco-o1更加关注那些缺乏清晰标准和量化奖励机制的领域。\n",
    "\n",
    "![marco o1](./image_o1/logo.png \"marco o1\")\n",
    "\n",
    "Marco-o1的核心在于结合了几种先进的技术：CoT精调、MCTS以及自我反思机制。通过使用这些技术，Marco-o1可以有效地处理复杂的现实世界问题。例如，在MGSM数据集上，Marco-o1实现了显著的准确率提升，MGSM(English) 数据集上提升了6.17%，而在MGSM(Chinese) 数据集上则提升了5.60%。此外，Marco-o1还在翻译任务中展示了出色的表现，特别是在处理口语化表达方面。\n",
    "\n",
    "Marco-o1不仅仅是一个单一的努力成果，而是一个持续优化的过程。尽管目前的版本主要展现了o1类似的推理特征，但其性能尚未完全达到理想的o1水平。然而，随着不断的改进和优化，Marco-o1有望在未来取得更大的突破，尤其是在多语言应用领域展现出更多的可能性。项目主页提供了更多详细信息和技术文档，可供进一步阅读：[https://github.com/AIDC-AI/Marco-o1](https://github.com/AIDC-AI/Marco-o1)。 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 强化学习介绍\n",
    "\n",
    "强化学习（Reinforcement Learning, RL）是一种机器学习方法，通过代理（agent）与环境的交互来学习如何做出一系列决策以最大化某种长期奖励。强化学习在许多领域中都取得了显著的成功，其中最著名的例子是AlphaGo，它利用强化学习击败了围棋世界冠军。\n",
    "\n",
    "#### 2.1 MCTS 蒙特卡洛树搜索\n",
    "\n",
    "**一般的蒙特卡洛树搜索**\n",
    "\n",
    "蒙特卡洛树搜索（Monte Carlo Tree Search, MCTS）是一种用于决策制定的启发式搜索算法，特别适用于那些状态空间巨大且难以完全遍历的问题。MCTS通过模拟多个可能的行动路径来评估不同策略的好坏，并选择最佳路径进行下一步探索。其基本步骤包括：\n",
    "\n",
    "- **选择（Selection）**：从根节点开始，沿着树向下选择一个子节点，直到到达一个未完全展开的节点。\n",
    "- **扩展（Expansion）**：在该未完全展开的节点上添加一个新的子节点。\n",
    "- **模拟（Simulation）**：从新添加的子节点出发，随机执行动作直到游戏结束或达到某个终止条件，以估计该节点的价值。\n",
    "- **反向传播（Backpropagation）**：将模拟结果（如获胜概率或奖励值）反向传播回树中的父节点，更新这些节点的价值估计。\n",
    "\n",
    "这种迭代过程允许MCTS逐步聚焦于最有希望的策略，并随着更多的模拟而改进其决策质量。\n",
    "\n",
    "![蒙特卡洛树实例](./image_o1/tree_visualization.png \"蒙特卡洛树实例\")\n",
    "\n",
    "\n",
    "**实例：AlphaGo下的围棋**\n",
    "\n",
    "为了更好地理解MCTS的工作原理，我们可以看看它在AlphaGo中的应用。AlphaGo利用MCTS来评估棋盘上的每一个可能的走法及其后续影响。具体步骤如下：\n",
    "\n",
    "- **选择（Selection）**：AlphaGo从当前局面开始，根据已有的知识和统计信息，选择最有可能带来胜利的走法。这个过程会持续到遇到一个尚未充分探索的局面。\n",
    "  \n",
    "- **扩展（Expansion）**：一旦找到这样的局面，AlphaGo会在该位置上生成所有合法的下一步走法，并选择其中一个进行进一步分析。\n",
    "\n",
    "- **模拟（Simulation）**：接下来，AlphaGo会基于当前的选择进行快速的游戏模拟，通常采用一种简化的策略来进行快速评估，直到游戏结束或达到预设的深度限制。\n",
    "\n",
    "- **反向传播（Backpropagation）**：根据模拟的结果（赢、输或平局），AlphaGo会更新这条路径上所有相关节点的统计数据。这有助于指导未来的决策，使得更有效的策略得到优先考虑。\n",
    "\n",
    "通过这种方式，AlphaGo能够高效地探索庞大的搜索空间，并在有限时间内找到最优解。\n",
    "\n",
    "\n",
    "**Marco-o1中的MCTS应用**\n",
    "\n",
    "Marco-o1对传统的蒙特卡洛树搜索（Monte Carlo Tree Search, MCTS）进行了适应性修改，以便更好地与大型语言模型（LLMs）集成并支持复杂的推理任务。以下是几个关键点：\n",
    "\n",
    "- **节点作为推理状态**：在MCTS框架中，每个节点代表问题解决过程中的一个推理状态。对于Marco-o1来说，这意味着每个节点对应于推理链中的一个特定步骤或中间结论。例如，在处理数学问题时，每个节点可以表示一个具体的逻辑步骤或计算结果。这种结构化的方式帮助模型逐步构建复杂的推理路径。\n",
    "\n",
    "- **动作作为LLM输出**：从某个节点出发的可能动作即为大型语言模型生成的输出。这些输出表示推理链中的潜在步骤或子步骤。具体而言，LLM生成的每一个token都可以被视为一个可能的动作。例如，在处理数学问题时，LLM可能会生成一系列逻辑步骤，每一步都是一个可能的动作。通过这种方式，MCTS能够利用LLM的强大生成能力来探索多种可能的推理路径。\n",
    "\n",
    "- **展开和奖励计算**：在展开阶段，LLM会继续推理直到达到终止状态，并根据所采取的行动计算出相应的奖励得分R。为了评估每个token的置信度分数，我们使用softmax函数对其对数概率及其前五个替代token的对数概率进行处理：\n",
    "  \n",
    "$ c_i = \\frac{\\exp(p(t_i))}{\\sum_{k=1}^{5}\\exp(p(t_k))} $\n",
    "\n",
    "其中$c_i$ 是第i个token的置信度分数，$p(t_i)$ 是由LLM生成的第i个token的对数概率，而$p(t_k)$ (k=1到5) 则是第i步预测的前五个token的对数概率。最终，整个推演路径的整体奖励评分v是所有token置信度分数的平均值：\n",
    "\n",
    "$ v = \\frac{1}{n} \\sum_{i=1}^{n} c_i $\n",
    "\n",
    "这使得MCTS能够有效地扩展解决方案空间，允许模型基于计算出的置信度分数探索大量推理路径，并选择最有可能成功的路径。通过这种方式，MCTS与LLM紧密结合，充分利用LLM的生成能力来优化推理路径的选择。\n",
    "\n",
    "- **指导MCTS**：该奖励得分用于评估并选择有前景的路径，从而引导搜索朝向更自信、更可靠的推理链发展。例如，在MGSM数据集上的实验表明，采用不同粒度的动作策略（如“步骤作为行动”、“mini-step作为行动”）可以显著提高模型的性能。特别是，“mini-step（32 tokens）作为行动”的策略在中文数据集上取得了最高的准确率82.40%。此外，为了进一步增强模型的表现，Marco-o1引入了一个自我反思机制，鼓励模型重新审视自己的推理步骤。通过添加提示词“Wait! Maybe I made some mistakes! I need to rethink from scratch.”，模型能够在发现潜在错误后重新评估其推理路径，从而提高复杂问题解决的能力。\n",
    "\n",
    "- **多样化行动策略**：为了优化推理效率，Marco-o1还探索了不同的行动粒度策略。例如，初始阶段使用“步骤作为行动”，随后尝试将这些步骤细分为更小的单位（如32或64 tokens），称为“mini-step”。这种细粒度的探索方式使得模型能够更加细致地评估各种推理路径，提高了找到正确答案的概率。实验结果显示，这种策略在减少单独猜测次数时表现出色，尤其是在处理复杂问题时。\n",
    "\n",
    "通过以上方法，Marco-o1不仅能够在标准答案明确的学科中表现出色，而且在没有明确标准或奖励难以量化的领域也展现出了潜力。MCTS与LLM的结合，使得模型能够高效地探索解决方案空间，并在实际应用中取得显著的性能提升。\n",
    "\n",
    "\n",
    "#### 2.2 奖励函数\n",
    "\n",
    "奖励函数定义了当采取某一行动后，环境给予代理的反馈（正面或负面）。在MCTS中，奖励评分R被用来评估和选择有潜力的路径。奖励函数的设计直接影响模型的学习效果和性能。例如，在Marco-o1中，奖励是基于每个token的置信度分数计算得出的整体奖励评分。这种机制确保了模型倾向于选择那些具有较高置信度的推理路径，进而提高了找到正确答案的概率。\n",
    "\n",
    "#### 2.3 价值函数\n",
    "\n",
    "价值函数估计从当前状态开始遵循某一策略所能获得的预期回报。在MCTS中，这通常通过计算所有tokens的置信度分数的平均值得出整体奖励评分v。这个平均值充当了一种奖励信号，用于评价推理路径的质量。较高的v值意味着更自信且可能准确的推理路径。通过这种方式，价值函数帮助指导搜索过程，使其更加集中于高价值的推理路径上。\n",
    "\n",
    "此外，为了进一步提升模型的表现，Marco-o1还引入了不同的行动粒度策略（如“步骤作为行动”、“mini-step作为行动”），并通过自我反思机制鼓励模型重新审视自己的推理步骤，从而提高复杂问题解决能力。实验表明，这些策略在MGSM数据集上的表现优于基线模型，并展示了MCTS在减少单独猜测次数时的优势。\n",
    "\n",
    "![数据构建](./image_o1/intro.jpg \"数据构建\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Marco-o1训练流程\n",
    "\n",
    "#### 3.1 训练数据准备\n",
    "\n",
    "为了增强Marco-o1模型的推理能力，marco o1采用了监督式精调（Supervised Fine-Tuning, SFT）策略，并使用了多种数据集。具体包括：\n",
    "\n",
    "- **Open-O1 CoT 数据集（过滤版）**：通过对原始Open-O1项目的CoT数据集进行启发式和质量过滤处理，确保数据集的质量。这种处理方式使得模型能够有效地采用结构化的推理模式。\n",
    "  \n",
    "- **Marco-o1 CoT 数据集（合成版）**：利用MCTS生成复杂推理路径，从而增强模型的推理能力。该数据集有助于模型学习如何构建复杂的推理链路。\n",
    "\n",
    "- **Marco Instruction 数据集**：考虑到指令跟随能力在执行复杂任务中的关键作用，marco o1整合了一套指令跟随数据。这保证了模型在广泛的任务中保持有效性和通用性，同时显著提升了其推理技巧。\n",
    "\n",
    "这些数据集总共包含60,266个样本，分别为：\n",
    "- Open-O1 CoT 数据集（过滤版）：45,125个样本\n",
    "- Marco-o1 CoT 数据集（合成版）：10,000个样本\n",
    "- Marco Instruction 数据集：5,141个样本\n",
    "\n",
    "#### 3.2 树状思考路径构建\n",
    "\n",
    "为了扩展解决方案空间并提升Marco-o1模型的推理能力，marco o1将大型语言模型（LLMs）与蒙特卡洛树搜索（Monte Carlo Tree Search, MCTS）相结合：\n",
    "\n",
    "- **节点作为推理状态**：在MCTS框架中，每个节点代表问题解决过程中的一个推理状态。\n",
    "  \n",
    "- **动作作为LLM输出**：从某个节点出发的可能动作即为LLM生成的输出。这些输出表示推理链中的潜在步骤或子步骤。\n",
    "\n",
    "- **展开和奖励计算**：在展开阶段，LLM会继续推理直到达到终止状态，并根据所采取的行动计算出相应的奖励得分R。这个奖励评分用于评估并选择有前景的路径，从而引导搜索朝向更自信、更可靠的推理链发展。\n",
    "\n",
    "此外，通过不同粒度的动作选择策略（如“步骤作为行动”、“mini-step作为行动”），进一步增强了模型探索复杂推理路径的能力。\n",
    "\n",
    "#### 3.3 反馈循环与权重更新\n",
    "\n",
    "为了促进模型自我反思并提高解决问题的能力，marco o1在推理过程中引入了一个反馈循环机制：\n",
    "\n",
    "- **自我反思机制**：通过添加提示词“Wait! Maybe I made some mistakes! I need to rethink from scratch.”来促使模型自我反思和重新评估其推理步骤。这种方法允许模型识别并纠正潜在错误，提高了对困难问题的解答准确性。\n",
    "  \n",
    "- **权重更新**：基于奖励信号和反馈信息，模型可以调整其内部参数以优化性能。例如，在实验中发现，通过增加自我反思环节，约有一半原本无法正确解答的问题得到了正确解决。\n",
    "\n",
    "#### 3.4 模型性能评估与改进\n",
    "\n",
    "为了评估Marco-o1模型的性能，marco o1在MGSM（Mathematical Generalization and Solution Modeling）数据集上进行了测试，包括英文和中文版本的数据集。主要结果如下：\n",
    "\n",
    "- **实验设置**：基于Qwen2-7B-Instruct模型，marco o1使用自定义的训练数据进行SFT，创建了Marco-o1-CoT。然后，在MCTS框架下应用了不同的动作粒度策略，包括“步骤作为行动”、“mini-step（64 tokens）作为行动”和“mini-step（32 tokens）作为行动”。\n",
    "\n",
    "- **实验结果**：Marco-o1-MCTS（step）在MGSM-en数据集上的准确率达到了90.40%，而在MGSM-zh数据集上达到了80.00%。相比之下，“mini-step（32 tokens）作为行动”的策略在MGSM-zh数据集上取得了最高的准确率82.40%。此外，marco o1还使用Test@N指标评估了模型在有限猜测次数下的表现，结果显示MCTS在较少猜测次数的情况下表现出色。\n",
    "\n",
    "未来的工作将集中在进一步优化奖励模型（Outcome Reward Modeling, ORM 和 Process Reward Modeling, PRM），减少随机性，并通过强化学习技术进一步提升决策制定过程，最终增强Marco-o1解决复杂现实世界任务的能力。 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 实例分析\n",
    "\n",
    "为了更好地理解Marco-o1模型在实际应用中的表现，marco o1可以通过几个具体的实例来展示其推理能力、解决复杂问题的能力以及在多语言环境下的应用效果。\n",
    "\n",
    "#### 实例一：经典问题的推理\n",
    "\n",
    "**问题**: \"How many ‘r’s are in ‘strawberry’?\"\n",
    "\n",
    "**Marco-o1的推理过程**:\n",
    "- Marco-o1首先通过Chain-of-Thought (CoT) 方法进行思考，逐步解析问题。\n",
    "- 在MCTS框架下，模型探索了多个可能的推理路径。例如，它会考虑单词“strawberry”中每个字母的位置和出现次数。\n",
    "- 最终，模型给出了正确的答案：“strawberry”中有两个‘r’。\n",
    "\n",
    "值得注意的是，在这个过程中，虽然模型正确地计算出了答案，但它并未明确提及最后一个字母‘y’。这表明模型有时会跳过显而易见的步骤，类似于人类在解决问题时的行为。尽管如此，这种略过并不会影响最终答案的准确性。\n",
    "\n",
    "\n",
    "\n",
    "![经典问题](./image_o1/strawberry.jpg \"草莓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### o1 结论\n",
    "\n",
    "通过上述实例分析，marco o1可以得出以下结论：\n",
    "\n",
    "1. **推理能力**：Marco-o1能够有效地利用CoT方法和MCTS技术进行复杂的推理，即使在某些情况下略过了显而易见的步骤，也不影响最终答案的准确性。\n",
    "   \n",
    "2. **性能提升**：相比于基线模型Qwen2-7B-Instruct，Marco-o1在多种配置下都展现了更高的准确率，尤其是在中文数据集上，采用细粒度的动作策略进一步提升了模型的表现。\n",
    "   \n",
    "3. **翻译能力**：在处理口语化表达和复杂句子结构时，Marco-o1展现出优于现有翻译工具的能力，能够生成更加自然和准确的翻译结果。\n",
    "\n",
    "综上所述，Marco-o1不仅在标准任务上表现出色，而且在开放性问题和多语言应用领域也展现出了巨大的潜力。未来的工作将继续优化奖励模型，减少随机性，并通过强化学习技术进一步提升决策制定过程，从而增强Marco-o1解决复杂现实世界任务的能力。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
